* 概要
ここではローカルで行う学習の知見をまとめていきます

* リンク
+ [[ローカルの学習入門]]
+ [[HyperNetwork]]
+ [[DreamBooth]]
+ [[DreamArtist]]
+ [[TextualInversion]]
+ [[Dreambooth-LoRA]]

* 追加学習(広義のFine-tuning)でなにができる？
- 特定のキャラを正確に生成する
- 新たな概念を追加する
- 既存の概念を上書きする
- トッピング感覚で簡単に使用できる(DreamboothとFine-tuning以外)
2024年現在はLoRAがおすすめ。軽量、高速、高性能。

* それぞれの特徴
** TextualInversion
Embedding(単語と画像を関連付ける辞書のようなもの)を調整する。
- 学習が遅い
- 再現度は普通
- Negative Promptに適用できる
- モデルが知らないものには効果なし

** HyperNetwork
Hypernetworkというネットワークがモデルのウェイトを調整する。
完全上位互換といえる[[Dreambooth-LoRA]]に取って代わられた。多分もう誰も使ってない。
- 学習がやや遅い
- 画風を緩く変える程度の効果
- 設定が難しく、Dying Reluといった問題がある

** Dreambooth
モデルのウェイト自体を調整する。
- 再現度が高い
- checkpointが出力される？
- VRAM消費が多い

** LoRA(Low-Rank Adaptation)
Dreamboothから派生。ウェイトの差分を出力する。軽量、高性能、省メモリなため現在主流となっている。
- 再現度が高い
-- Dreamboothには劣る。
- 学習が速い
- モデルにマージせずに使える(厳密にはマージが必要。使用時にバックエンド側が自動でマージする)
- 設定項目が非常に多いので初見だと難しいかも

*** DoRA(Weight-Decomposed Low-Rank Adaptation)
方向ベクトルをファインチューンすることでLoRAの精度と安定性を改善するらしい。
https://arxiv.org/abs/2402.09353

LyCORISに実装された。
LyCORISでnetwork_argsにdora_wd=Trueを指定すると使える。
使用するには1111の1.9.0以降が必要。

** Fine-tuning(Native Fine-tuning)
モデルのウェイトを直接変更する。
- 最高精度
- 要求スペックも最高レベル
-- 多くのウェイトがA100 80G以上のGPUで学習しているが、工夫すればRTX 4090でも動作する
- 大規模学習向け
- Checkpointが出力される