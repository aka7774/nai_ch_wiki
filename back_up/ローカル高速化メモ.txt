#contents

* 高速化オプションの利用

stable diffusionに用意されているxformersというオプションを利用する。
理論上、このオプションを付けてるときと付けてないときで絵が変わるらしいが
少なくともアスカプロンプトでは明確な違いを確認できず、演算時間が2割程度早くなる。
(明確な違いが出る条件がわかる方がいたらここに新章作って記録していってほしい)

検証ページ作ったので記録はこちらへ
→「[[xformersの検証]]」

** 対応GPU

- NVIDIA
- GeForce 1000番台〜3000番台(4000番台は後述)
- GeForce 900番台以前でも動くけど逆効果だったという報告あり

** 方法

stable-diffusion-webuiディレクトリ直下にあるwebui-user.batを修正する。

6行目修正前
> set COMMANDLINE_ARGS=

6行目修正後
> set COMMANDLINE_ARGS= --xformers

** 利用するライブラリの更新
2023/01/23時点の最新版(7ff1ef77dd22f7b38612f91b389237a5dbef2474)で本体に取り込まれた
旧バージョンのtorchとxformersを使用している場合はアップグレードを促すアナウンスメッセージが表示される
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/1sa2Wev7W4.png)

コマンドラインオプションに再インストールオプションを追加して起動すると更新される
> COMMANDLINE_ARGS= --reinstall-torch --reinstall-xformers ~~

アップデート完了した場合、WebUIの下部の表示が以下のようになる
(torch・xformers欄)
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/xh_WFZyBHE.png)

***RTX4000シリーズを使っている場合
標準でインストールされるcudnn関係のDLLが古い(4000シリーズ未対応)為、対応版(cudnn8.7.0)に置き換える

+https://developer.nvidia.com/rdp/cudnn-download より Local Installer for Windows (Zip) をダウンロードする~~※メールアドレス登録が必要かもしれない
+ダウンロードしたzipファイル(cudnn-windows-x86_64-8.7.0.84_cuda11-archive.zip)を展開し、binフォルダ内の7ファイルを取り出す
+stable-diffusion-main\venv\Lib\site-packages\torch\lib 内に上書きコピーする


[+]以前の方法
4090で高速化する方法。3060でもほんのちょっとだけ早くなったとの報告あり。

- 更新手順(Windows用)
1.エクスプローラーでstable-diffusion-webui/venv/Scriptsフォルダを開き、右クリック→ターミナルで開く(多分Win10ではPowershellで開く)でPowershellを開く
2.以下のコマンドを実行
> .\Activate.ps1
3.以下のコマンドを実行
> pip install -U -I --no-deps torch==1.12.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116
4.https://pomf2.lain.la/f/5u34v576.7zをDLして中身を「stable-diffusion-webui\venv\Lib\site-packages\torch\lib」にコピーする
5.以下のコマンドを実行
> pip install -U -I --no-deps torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116
5.Powershellウィンドウは閉じて、webuiフォルダ直下のwebui-user.batを開き、set COMMANDLINE_ARGS=の後ろに--xformers --opt-channelslastを追加して保存する

ソース:なんJNVA部★84 
http://fate.5ch.net/test/read.cgi/liveuranus/1667387353/
[+]
> 265 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ fb72-iO6U)[sage] 投稿日：2022/11/02(水) 23:51:01.19 ID:n0RTOjsJ0 [5/6] ~~
> >>239>>240 ~~
> 俺も2週間ぐらい同じ感じだったけどxformersオプション入れるだけじゃ多分駄目なんよ ~~
> これから4090買う人のために書いておく こっちはドライバは最新 Win10 CPUは5900X MEM32G ~~
> webuiのvenv内に入ってから(stable-diffusion-webui\venv\Scripts\activateで入れる) ~~
> pip install -U -I --no-deps torch==1.12.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116 ~~
> https://pomf2.lain.la/f/5u34v576.7z ~~
> ↑のファイルをstable-diffusion-webui\venv\Lib\site-packages\torch\lib ~~
> にコピペ ~~
> pip install -U -I --no-deps torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116 ~~
>  ~~
> 266 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ fb72-iO6U)[sage] 投稿日：2022/11/02(水) 23:51:28.93 ID:n0RTOjsJ0 [6/6] ~~
> (続き) ~~
> 起動オプションに追加 ~~
> --xformers --opt-channelslast ~~
> これで18it/sぐらい出るようになった ~~
> Windows ディスプレイ設定→グラフィックの設定→GPUアクセラレータによるGPUスケジューリングをOFFで再起動する ~~
> これで24it/s出るようになった うまくいったら報告頼む 環境壊れたらすまんvenv消してくれ ~~

[END]
* torchのバージョンとcudaのdllを入れ替える
4090が主だけど、3090でも早くなった報告あり。
自分の環境では2倍速近く早くなった。
https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/2449#issuecomment-1320800317
[END]

* torchを2.0にする
生成が5%以上速くなるが、''いくつかの機能が動作しなくなる可能性があるため非推奨''
Linuxであればさらに高速化するが、モデル、解像度、Batch sizeの変更の度にコンパイルでかなり待たされるのでやる価値は低い。
(txt2img,img2img,TI,HNは動作確認済。DBは未確認)
↓に更新方法が書いてある。
https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/6932
※TorchとAccelerateはvenvと通常環境の両方にインストールするように

** 補足
- パッケージ名について
Installセクションステップ3のpip3はtritonのパッケージ名が変わっているため失敗する。代わりに以下のコマンドを実行する。
> pip3 install --pre torch torchvision torchaudio pytorch-triton --extra-index-url https://download.pytorch.org/whl/nightly/cu118 --force


- Windowsの補足事項
WindowsではIntallセクションのステップ5がうまくいかない。ステップ4まで進めたら、gitでxformersをクローンしてビルドする必要あり。
[[ここの手順>>https://michyo.net/sempetit/install-xformers-windows/]]の「xFormers のダウンロード」まで進めた後、
xformersフォルダ内で以下のコマンドを実行する。
> python setup.py build
ビルドされるのでしばらく待つ。その後xformersフォルダ内で以下のコマンドを実行する。
> python setup.py bdist_wheel
その後xfomers\dist\にwhlファイルができるので、それをvenv/Scriptsにコピーしてvenv側のpythonでpip install ファイル名.whlでインストールする。
インストール後、venv\Lib\site-packages\tritonフォルダを消去する。ついでにグローバル環境のpythonからaccelerate、torch、torchvisionはアンインストールしたほうがいいかもしれない。

- Linuxの補足事項
torch.compile()を利用するとdynamoのエラーで生成ができないため、stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\util.pyの113-114行目を次のコードで置き換える。
> return CheckpointFunction.apply(func, len(inputs), *inputs, *params)

※Windowsは非対応なのでtorch.compile()があっても速くならない

* VAEをckptに内蔵する

1111に標準で入っているCheckpoint Mergerでもできるようになっている
マージ対象Aに内蔵先モデルを指定して、Interpolation Method を No interpolation 指定
Bake in VAEで内蔵するVAEを選択してマージする

[+]以前の方法
116スレ559

Checkpoint Mergerでマージすると色が薄くなる問題、Merge Blocvk Weightedで解決できそう

Checkpoint Merger のMultiplierで指定してた値をMerge Block Weightedの IN00〜OUT11まで全部同じ値にして、base_alphaとM00を0にする(=ModelA側に寄せる)と発色がよくなる 
[+]
https://i.imgur.com/80TODwE.png
[END]

出てくる絵は微妙に変わるけど発色よくなってVAEが必要なくなっただけでも満足や

↓のX/Yは上から
- Checkpoint Mergerでマージしたもの
- Merge Blocvk Weighted で全部↑のMultiplierと同じ値を設定 0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3
- Merge Blocvk Weighted でbase_alphaとM00に0を設定 0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3
[+]
https://i.imgur.com/7chOcgA.jpg
https://i.imgur.com/Q6p1jJI.jpg
[END]
[END]

* safetensors変換

1111に標準で入っているCheckpoint Mergerでもできるようになっている
マージ対象Aに変換したいモデルを指定して、Interpolation Method を No interpolation 指定
Checkpoint formatをsafetensorにしてマージする

[+]以前の方法
116スレ612

>>559法とsafetensors変換を併用したらハローアスカ5秒短縮できたやで！

1-1. 混ぜたいvaeを有効にしておく
1-2. Merge Block Weightedを開く
1-3. Model AとModel Bに同じckptを指定する
1-4. Output Model Nameも何か入れておくと便利
1-5. Run Merge

2. できたckptをsafetensorsに変換(方法は下記)

3-1. できたsafetensorsを選ぶ
3-2. vaeをNoneにする

ハローアスカ
ckpt+vae 42.89
safetensors 37.87
多用するモデルで作っとけば普段使いもいけるでー 
[END]

** 変換方法いろいろ

- Filerを使う [[Extensions_URL]]
- Pythonを使う https://pastebin.com/ijApuS6b
- Colabを使う(今回はまわりくどいけど) [[ローカルの「ツール」]]
* Exensionsの退避

しばらく使わないときは Dreambooth Extension を削除する

起動時間が劇的に変わる
UIからオフにするだけではダメ
フォルダごと別の場所に退避させとくとか、いっそバッサリ消すとか

* Stepsを減らす

出来るだけ少ないStepsでも期待通りの絵が出る方法を模索する。
Euler a以外(収束するサンプラー)で再現できないか試す。
DPM++ 2M Karrasは15Stepsでもそれなりに映えるのでおすすめ。

* RamDiskを使う

1111全部RamDiskに突っ込んで高速化するのはおすすめしない。
必要RAMのわりに恩恵がほとんど無いから。

でもマージなら恩恵あるかも。
短時間で大量の読み書きを繰り返すから。
高速化というよりSSD消耗を抑える意味のほうが大きいかも。
混ぜるモデルと出来たモデルを保存する容量が確保できれば使える。

ImDisk Toolkit が使いやすい。
https://sourceforge.net/projects/imdisk-toolkit/

stable-diffusion-webui\models\Stable-diffusionにジャンクションをはるか、
コマンドラインオプションで--ckpt-dirを指定して使う(こっちのが便利かも)

* WSL2で使う

[[1111_WSL2]]

* Linuxに入れる

仮想化ではなく生で挿入れる
Windowsと比べて多少高速化するらしい・・・？
虎の子のゲーミングPCでは厳しいやね
サブ機とかお古になったら検討してもいいかも
なおインストールが簡単かは謎

* venvを作り直す

Windows再インストール並みの最終手段。
最新の1111に必要なものしか入らなくなるので軽くなる、かも。
Extension試しまくってると肥大化するので月イチくらいでやるといいかも。

* GPUを買い替える

{{{give me money}}}












