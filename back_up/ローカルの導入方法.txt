#contents

*概要
ローカル環境の導入ガイドです

-- &size(15){[[画像付きガイドpdfを作りました。>>https://image01.seesaawiki.jp/n/h/nai_ch/Bh8T7jBTQz.C.pdf]](Windows用)}
必要なソフトのインストール方法とモデルダウンロードについても記載しています。

*リファレンス
- https://rentry.org/voldy

*導入

- 説明読んでも全く理解できない人は「A1111 WebUI Easy Installer and Launcher」を試すといいかも。

** 1. Python 3.10をインストールする
[[https://www.python.org/ftp/python/3.10.9/python-3.10.9-amd64.exe]]
&color(#ff0000){3.11は入れても動かないから入れんな!!}

「python-3.10.x-amd64.exe」がダウンロードされるので、ダブルクリックで開く。
このとき、Add to PATH にチェックをつけてインストールすること。
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/H089Tt3hem.png)

&color(#ff0000){インストール終わったらPC再起動、絶対に!!}

** 2. Gitをインストールする

入れておかないと色々エラーが出たりして厄介。

[[https://git-scm.com/downloads]]
64-bit Git for Windows Setup. を選ぶ。

インストールするときは、「Windowsエクスプローラの統合 - Git Bash」のチェックボックスをオンにするのがおすすめ。

** 3. 1111本体のダウンロード

以下の手段から好きなものを選んでWebUIのデータをダウンロードしてきます。
��WebUIをZIPでダウンロードする：お試しで環境を構築したい人向け
��Github Desktopをインストールする：アプデを行いながら使っていきたい人向け：&#128304;おすすめ!
��Gitを使う：アプデしたり差分を確認したりバージョンを戻したりとなんでもしたい人向け

***��WebUIをZIPでダウンロードする場合
GithubリポジトリからZipでダウンロードするかんたんな方法。アプデとかめんどくさいし、バージョン戻しもできないのでお試し環境構築用として推奨。
+ 以下のURLアクセス ~~ AUTOMATIC1111/stable-diffusion-webui: Stable Diffusion web UI - https://github.com/AUTOMATIC1111/stable-diffusion-webui
+ Code <> →Download ZIP　でダウンロードします
+ 好きなところに配置
+ 完了

***��Github Desktopをインストールする場合：&#128304;おすすめ!
グラフィックインタフェースで操作できるGitです。
黒い画面をみなくてすみます。アプデが簡単にできる環境が作れるけど、バージョン戻しには別途Gitをインストールする必要があります。

+ Github Desktopをインストールする
+ File　→　Clone Repository
+ タブ「URL」に設定後、以下を記載~~
=|BOX|
https://github.com/AUTOMATIC1111/stable-diffusion-webui
||=
+ Local Pathに配置したい場所を記載してCloneを押す
+ 完了

&ref(https://image01.seesaawiki.jp/n/h/nai_ch/A2FTwb_lRZ.jpg,450)

***��Gitを使う場合
なんでもできる。さいつよ。

1. エクスプローラーとかでインストールしたいディレクトリを開く
2. 任意の場所を右クリックし、「Git Bash here」を選択します
3. 黒い画面が出たらディレクトリのパスが表示されていることを確認します
4. 次のコマンドを打ちリポジトリをダウンロードします
=|BOX|
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
||=

**4：NovelAIモデルのダウンロード
''情報提供、テスト、研究の自由のために掲載します。''
結果が気に入ったら、[[サブスクリプションを検討してください>https://novelai.net/register]]

次のマグネットリンクからモデルをダウンロードします。
トレントクライアント(qTorrent, Bitcomet等)がない場合はインストールしておきます。
=|BOX|
magnet:?xt=urn:btih:5bde442da86265b670a3e5ea3163afad2c6f8ecc
||=

モデルの総容量は50GB超ですが、必要なデータは5GBほどです。
/stableckptのみを選択し、その他は選択解除します。
※オプション：.ptの拡張子をもつHyperNetwork用のmoduleが/modulesにあるので任意でダウンロードします。

**5：リネーム
ダウンロードしたモデルを次のようにリネームします
animevae.pt >> nai.vae.pt
config.yaml >> nai.yaml
model.ckpt>> nai.ckpt

2022/11/22追記
いつごろからかvaeの読み込ませ方が変更になっている。
拡張子はptでファイル名どうでもいいので、models/vaeの下にファイルを格納し、
WEB UIを起動後、Settingタブ、[Stable Diffusion]-[SD VAE]の項目で
先ほど格納したファイルを選択、Apply Settingボタンを押す。


**6：配置
以下のディレクトリにモデルを配置します。
/stable-diffusion-webui/models/Stable-diffusion

**7.起動確認

ここまでの手順がうまくいってれば起動するはず。

''「webui-user.bat」をダブルクリックでWebUIを起動させます。''
図：これね
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/y4M3qrylYT.jpg)

**8(※オプション)：環境設定
[[ローカルのwebui-user.bat]]に移動しました。

ここまで完了したら[[「動作確認：Hello Asuka」>#helloasuka]] へ進みます。

* A1111 WebUI Easy Installer and Launcher

https://github.com/EmpireMediaScience/A1111-Web-UI-Installer

CG板で使ってみた人がいいかもって言ってた。
スレでも技術部でも誰も試してないので副作用とかは不明。
一般論としては既にインストール済みのPythonやGitがあるとエラーの原因になりうる。
上記の方法でダメだったら試してみるのも手なのかも。
使ってみた人いたら感想書いてね。

*※番外編：導入(WSL2)｜Linux環境でAutomatic1111を導入する

※上記のWindows版の人は関係ないので飛ばします
[[1111_WSL2]]に移動しました。

&aname(helloasuka){}
*動作確認：Hello Asuka
お疲れ様でした！これで出力する準備が整いました。
次はNovelAI のデフォルト設定での出力と一致しているかのテストを行います。

''''

以下の数値をUIに入力して「Generate」をクリックします。
参考画像と出力画像が一致していたら環境構築が成功しています。
→出力した画像が一致していない場合：一般的な "Hello Asuka" エラーのトラブルシューティング (Euler) - Imgur - https://imgur.com/a/DCYJCSX

- サンプラー：Euler (Euler Aではない)
- 28 Steps
- CFG Scale：12
- 解像度: 512x512
- Seed: 2870305590
- ポジティブプロンプト欄に「masterpiece, best quality, masterpiece, asuka langley sitting cross legged on a chair」
- ネガティブプロンプト欄に「lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name」
- Ignore last layers of CLIP modelを「2」にする
- (Euler-Aも一致させたい場合、ETA Noise Seed Deltaを「31337」にする)

&ref(https://image02.seesaawiki.jp/n/h/nai_ch/0ki5ejUnR6.png)
図：PNGにメタデータが付属したHello Asuka。PNG infoにドラッグ&ドロップするとtext2imgに渡せます

** ※注意
- プロンプトを正確にコピーしたことを再確認してください！
- lowvram や xformers などの最適化を使用している場合、わずかな違いが見られる場合がありますが、それでも 95% 類似しているはずです。

図：GPU によるおおよそのレンダリング時間 (50 ステップ)
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/8lYrJdmZvs.png,660)

* トラブルシューティング
**RTX4090で画像生成した際、速度が遅い問題を解決する
・Stable Diffusion外の設定
Windowsの設定→グラフィックからGPUスケジューリングをオフ
ブラウザ等のハードウェアアクセラレートをオフ
　→discordもハードウェアアクセラレート設定があるので、必要であればオフ
NVIDIAコントロールパネルの3D設定の管理から電源設定をパフォーマンス優先に変更
　→電源消費が気になるならPythonだけ変更すればよい

・xformersの対応しているtorchバージョンを確認
結局xformersが動く動かないの差は大きいので、これがちゃんと動作する環境を作る
下記githubで最新バージョンのwhlファイル名を確認
　https://github.com/C43H66N12O12S2/stable-diffusion-webui/releases
たとえば
　xformers-0.0.14.dev0-cp310-cp310-win_amd64.whl
なら、cp310の記載があるため、Pyhon3.10に対応している
かつ、タグ名がtorch13なので、torch1.3に最適化されている
（torchはズレてても動きそう）

・パッケージ更新
1. venvに入る
Stable Diffusionが起動しているなら落とす
コマンドプロンプトを起動し、stable-diffusion-webuiと同階層まで移動
下記コマンドを実行
　stable-diffusion-webui\venv\Scripts\activate

2. パッケージを確認
下記コマンドを実行
　pip list
コマンドの結果、torchが1.13ならパッケージ更新は不要
　e.g) torch                   1.13.1+cu116

3. パッケージ更新
セットアップツールをアップデート
　python -m pip install --upgrade pip setuptools
torchインストール
　pip3 install torch==1.13.1+cu116 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116
別バージョンがあってもアンインストール→インストールしてくれるので気にしない

4. 起動確認
試しにStable Diffusionを起動してみる
xformersでエラーが出た場合、手動でインストールする
確認したgithubからwhlを落としてきてカレントに配置
下記コマンドを実行
　pip install xformers-0.0.14.dev0-cp310-cp310-win_amd64.whl

5. ライブラリ更新
Stable Diffusionを落とす
cuDNNをダウンロード
　https://developer.download.nvidia.com/compute/redist/cudnn/v8.7.0/local_installers/11.8/
githubでは8.6でやってる人がいたので、気になるなら8.6を落とす
階層を上がっていけば別バージョンがある
ダウンロードしたファイルのbinフォルダ内にあるファイルをtorch\libに上書き
　stable-diffusion-webui\venv\Lib\site-packages\torch\lib

6. webui-user.bat編集
下記内容に書き換え
　set COMMANDLINE_ARGS=--xformers --opt-channelslast
githubでは下記オプションも人気の模様
　--force-enable-xformers
ちゃんと動く環境があるならつけてもつけなくても一緒
つけてエラーが出るならxformersが動く環境が出来ていないとわかるので、
つけるほうが人気があるんじゃないかな

7. パフォーマンスチェック
アスカテストを実施
ここ↓を見る
Time taken: 3.05s Torch active/reserved: 2518/2684 MiB, Sys VRAM: 5358/24564 MiB (21.81%)

参考
[[RTX 4090 performance &#183; Issue #2449 &#183; AUTOMATIC1111/stable-diffusion-webui &#183; GitHub>>https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/2449]]
// ** RTX 4090などが遅い
// 　※注※　RTX4090はローカルNAIデフォ環境では速度出てません
// 　webuiのvenv内に入ってから(stable-diffusion-webui\venv\Scripts\activateで入れる)
// pip install -U -I --no-deps torch==1.12.1+cu116 --extra-index-url ttps://download.pytorch.org/whl/cu116
// ttps://pomf2.lain.la/f/5u34v576.7z
// ↑のファイルをstable-diffusion-webui\venv\Lib\site-packages\torch\lib
// にコピペ
// pip install -U -I --no-deps torchvision==0.13.1+cu116 --extra-index-url ttps://download.pytorch.org/whl/cu116
// (続き)
// 　起動オプションに追加　--xformers --opt-channelslast
// これで18it/sぐらい出るようになった
// Windows ディスプレイ設定→グラフィックの設定→GPUアクセラレータによるGPUスケジューリングをOFFで再起動する
// これで24it/s出るようになった

**gtx16xxで必要な設定
　gtx16xxでは半精度浮動小数点数が扱えないためそのままでは黒や緑の絵しかでない。オプション追加が必要。また、メモリがやや少なめ用設定も追加要
  webui-user.batに
=|BOX|
COMMANDLINE_ARGS=--precision full --no-half --no-half-vae --medvram
||=
　を加える
**その他本家のトラブルシューティングの訳(機械翻訳)
- フォルダーのパスにスペースがないことを確認する
- フラグを使用しようとしたときに launch.py&#8203;&#8203; エラー、認識されない引数が発生した場合は、webui-user.bat で完全な相対パスを使用してみてください。
例：--ckptCOMMANDLINE_ARGS= --ckpt ./models/Stable-diffusion/nai.ckpt
- 「私はgitで更新するためにPullして、何かが壊れた!」当然のことながら、多くの新機能が導入されているため、不安定になる可能性があります。[[手順に従って以前のビルドに戻します>https://rentry.org/git_retard]]。
- インストール中に&#160;winerror&#160;が発生する場合、または何かを壊して最初から再インストールしたい場合は、次のディレクトリを削除して、もう一度やり直してください。`venvrepositories`
- Pythonがエラーとして見つからない場合は、webui-user.batでPATHを手動で設定する必要があります。
　　1. python.exeのパスをShift+右クリックでコピー
　　2. webui-user.batを編集→　PYTHON= にコピーしたパスを追加します。※(""は保持)
- (img2img)RuntimeError:テンソルのサイズが一致しなければならない場合、入力画像の解像度を変更する必要があります
- 実行できる最新の[CUDAツールキット](https://developer.nvidia.com/cuda-11.3.0-download-archive?target_os=Windows&target_arch=x86_64)とGPUドライバがあることを確認してください
- トーチがGPUを使用できない場合は、代わりに[Python 3.7](https://www.python.org/downloads/release/python-370/)をダウンロードする必要があります
- 起動時に 'Git'がコマンドとして認識されない場合は、次の操作を行います:launch.py 編集で始まるすべての行を削除して保存します`git_clone`
- あなたのバージョンのPythonがPATHにない場合(または別のバージョンがPATHにある場合)、[webui.settings.bat](http://webui.settings.bat/)フォルダに行セットPYTHON=pythonを追加して、Python実行可能ファイルへのフルパスを言います:Pythonではこれを行うことができますが、gitの場合はできません。`/stable-diffusion-webuiset PYTHON=B:\soft\Python310\python.exe`
- インストーラはPython仮想環境を作成するので、インストール前にインストールされていたモジュールがあれば、インストールされたモジュールはシステムインストールには影響しません。
- 仮想環境の作成を防ぎ、システムのPythonを使用するには、webuiを編集し.bat setを`VENV_DIR=venvset VENV_DIR=`
- webui.bat は、Python 3.10.6 と特に互換性のあるモジュールのバージョンをリストするファイル から要件をインストールします。別のバージョンのPython用にインストールすることを選択した場合は、webuiを編集すると、.bat=REQS_FILEを設定する代わりに.txt=要件を設定することが役立つかもしREQS_FILEません(ただし、推奨バージョンのPythonを使用することをお勧めしますrequirements_versions.txt)。`requirements_versions.txt`
- 生成された画像の代わりに緑/黒の出力を取得する場合は、半精度浮動小数点数をサポートしていないカードがあります(16xxカードの既知の問題):edit webui-user.bat -追加したい他のフラグと一緒に6行目を変更する.vaeファイルを使用している場合は、残念ながら、モデルはVRAMではるかに多くのスペースを占有しますしたがって、それ`COMMANDLINE_ARGS=--precision full --no-half-no-half-vae-medvram`
- あなたの出力がごちゃごちゃした虹の混乱である場合、あなたのイメージの解像度は低すぎます
- CFGレベルが高すぎると色の歪みも発生し、CFGは5〜15
- 古いシステムでは、次のように変更する必要があります。`cudatoolkit=11.3cudatoolkit=9.0`
- インストールが C: ドライブにあることを確認します。
- このガイドは、安定した拡散には cuda コアが必要なため、NVIDIA GPU&#160;*専用*に設計されています。AMDユーザーは[このガイド](https://rentry.org/ayymd-stable-diffustion-v1_4-guide)をお試しください

* Tips

- WebUI 内でダウンロードした .ckpt ファイルをすばやく切り替えることができます。
- ベースSDとは異なり、NovelAIは歪みなく最大**768x768**の画像をネイティブに生成できます
- それ以外の場合、SDで512x512よりも大幅に大きい画像を生成する場合は、最良の結果を得るため必ずチェックしてください&#160;Highres, fix&#160;。そうしないと、「複製」歪みが現れ始める可能性があります (複数の顔、腕など)。ノイズ除去強度：denoising strengthを下げると最適に機能するようです (私は 0.5 を使用しました)
- 利用可能な修正があっても、NovelAI以外のモデルは512x画像でトレーニングされているため、最も正確な結果を得るために512x512で生成することをお勧めします
- ワイフモデルと通常の.ckptには独自の長所と短所があります。waifu .ckptで行われたアニメ以外のプロンプはアニメのスタイル化に偏り、別のモデルとマージしない限り、現実的な顔や人々をより困難にします
- トレーニング時に引数や**引数を使用しないでください**!結果は非常に劣るでしょう`-medvram-lowvram`
- nai.yaml は、NovelAI の結果で 1:1 を達成するために必要ではないかもしれません。
- キーワードの周囲に( )を使用して強度を高め、[ ] を使用して強度を下げます。
- 他のサンプラーとは異なり、k_euler_aは低ステップから高品質の結果を生成することができます。
- プロンプトを**スタイルとして保存**を使用すると、プロンプトを簡単に選択可能な出力として保存できます。最初のスタイルを保存すると、Rollの左側に選択するボックスが表示され、選択することができます。プロンプトはアクセスすることで削除できます(これは、本当に良い画像を生成し、さまざまな被写体で繰り返し使用したい組み合わせを見つけた場合に便利です)。`styles.csv`
- 右側の出力タブからimg2imgにお気に入りの結果をドラッグ**して、**さらに反復することができます
- **k_euler_a**と**k_dpm_2_a**のサンプラーは、同じシード&プロンプトから大きく異なる、より複雑な結果をもたらしますが、それらの結果はステップ全体で一貫していません。他のサンプラーは、より多くのステップでより予測可能な線形改良を提供します
- 生成された各結果のシードは、再訪する場合に出力ファイル名にあります
- img2imgで生成された画像と同じキーワードを使用すると、興味深いバリアントが生成されます
- プロンプトは*1*次元で少なくとも512ピクセル、または絶対最小の384x384正方形にすることをお勧めします。
- CLIP インテロゲーターは多くのスペース (8 GB) を占有します。頻繁に使用する予定がない場合は選択しないでください。
- 興味深い出力のためにimg2imgで低強度(0.3-0.4)+高CFGを試してみてください
- プロンプトで日本語の Unicode 文字を使用できます。


* バージョンを戻す方法
アプデしておかしなっても大丈夫やで

** git checkoutを使う方法
参考：(英文)：Git revert guide - [[https://rentry.org/git_retard]]

** クリーンインストール
+ リソースのダウンロードとかは省いて導入ガイドにそってWebUIを再インストールする。~~ ※フォルダは「StableDiffusion_WebUI_v2」とか名前つけて新しく作ってリポジトリをクローンするんやで
+ もとのディレクトリ*に置いてあった.ckptやvae,nai.yamlを同じディレクトリにコピペする ~~*場所：/stable-diffusion-webui/models/Stable-diffusion
+ 完了










