#contents

* モデル

広義では、HypernetworkやLoraで作成したファイルなども含まれるが、
ここではいわゆるCheckpointの話をする。

** まとめ

- 生成に使うのは fp16, pruned, safetensors を満たすファイルが良い。

** Stable Diffusionのバージョン
*** SD1
SD1.5: https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5
- U-Netアーキテクチャ
- 860M(8.6億)パラメータ
- そのまま使える。
- 軽量だが低性能
- 文章は全く生成できない

*** SD2
SD2.1: https://huggingface.co/stabilityai/stable-diffusion-2-1
- U-Netアーキテクチャ
- 865M(8.65億)パラメータ
- 文章を正しく生成できない
- 使うためには同名のyamlファイルを設置する必要がある。
- 大抵はモデルの配布元が配っている。
-- 無い場合は SD2.xのyamlを使ってみるとか。

*** SDXL
SDXL Base 1.0: https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0
- U-Netアーキテクチャ
- 2.6B(26億)パラメータ
- BaseとRefinerの二種類が存在する
- そのまま使える。
- 文章を正しく生成できない

*** SD3.0
https://huggingface.co/stabilityai/stable-diffusion-3-medium
- DiTアーキテクチャ
- Medium(2.5B)のみ
- (DiTモデル全般に言えることだが)破綻が少なく、線を真っすぐ引ける。
- 表現規制がきつく解剖がおかしくなる欠陥あり
- 文章を正しく生成できる

*** SD3.5
Large: https://huggingface.co/stabilityai/stable-diffusion-3.5-large
Medium: https://huggingface.co/stabilityai/stable-diffusion-3.5-medium
- DiTアーキテクチャ
- Large(8.1B)とMedium(2.6B)の二種類がある
- 使うには、モデル本体に加えてCLIP L/G、SD3 VAEが必要。T5XXLは任意
- 規制の緩和とSD3.0の問題を解消
- 文章を正しく生成できる

** ほかのText-to-Imageモデル

*** FLUX.1
dev: https://huggingface.co/black-forest-labs/FLUX.1-dev
schnell: https://huggingface.co/black-forest-labs/FLUX.1-schnell
- DiTアーキテクチャ
- DevとSchnellの二種類がある
- 文章を正しく生成できる
- 蒸留モデル(Fine-tuningが困難らしい)
- オープンなモデルの中では最大級のパラメータ数(12B)。
- それゆえに非常に重い

*** AuraFlow
https://huggingface.co/fal/AuraFlow
- DiTアーキテクチャ
- 現在開発中
- 開発中のものが公開されているが最近更新なし
- 文章を正しく生成できる

*** Sana
https://huggingface.co/Efficient-Large-Model/Sana_1600M_1024px
- DiTアーキテクチャ
- 軽量なことが売り
- リリースされた(ComfyUIで使うにはカスタムノードが必要)
- 文章を正しく生成できる?
- 商用利用禁止(研究目的の使用を意図している?)

** predictionの種類
※間違っている可能性あり。間違っていたら修正してください。

ノイズ予測アルゴリズムの種類。
v-predictionだからといって劇的に性能が上がるわけではない。わかりやすい変化はZero Terminal SNRを併用することで色の精度が上がる程度。
*** ε-prediction / epsilon-prediction
SD1とSDXLのデフォルト
画像のノイズ部分を予測する。
SN比=0(純粋なノイズ)では機能しない。
全体が明るい/暗い/原色が強い状況でグレー寄りになるため、単色背景やシルエットなどの表現が苦手。これはNoise offsetやMultires noiseで緩和可

*** v-prediction
SD2と一部のSDXLモデル(NovelAI Diffusion V3、NoobAI-XL)が使用
ノイズ除去前と除去後の差分を予測する。
SN比=0(純粋なノイズ)でも機能する
Zero Terminal SNRを併用することで全体が明るい/暗い状況でグレー寄りになる問題を解消できる。単色背景やシルエットなどの表現が改善する。
ほかにも安定性が改善するらしい
低めのGuidance Scaleで運用できる(大体5以下)
とあるモデルの影響で勘違いしている人が一定数いるが、これは''高速化する技術ではない''。多分DMD2という高速化LoRAの効果。

ちなみに、VはVelocityの頭文字でありν(ニュー)ではない。

Zero Terminal SNR(ZTSNR)はSN比=0であるべき状況で0にならない欠陥を修正するもの。

** v-predictionモデルの使い方
2024年11月27日時点の情報です。
*** AUTOMATIC1111
webuiのディレクトリ直下で次のコマンドを実行する。
 git checkout -b dev origin/dev 
あるいは、Github DesktopでFile->Add local repositoryで1111のフォルダを選択してリポジトリを追加した後、Current branchでorigin/devを選択する。
You have changed...と聞かれたらBring my changesを選択してswitch branchを押す。
あとはいつも通りwebuiを使用する。

*** Forge/ComfyUI
最新版にアプデする。

*** 1111/Forgeでノイズ製造機/真っ黒になる、またはmainブランチの1111で使う
次のリンクからsd_xl_v.yamlをwebui/models/Stable-diffusionにDLする。
https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/dev/configs/sd_xl_v.yaml
DLしたyamlファイルを使用するcheckpointと同じ名称に変更する。

必要に応じて、Settings>Sampler parametersにあるNoise schedule for samplingをZero Terminal SNRにする。

** インペイント専用モデル

inpaint.ckptは普通のcheckpointとは違うらしい。

** ハッシュ

[[Model hashとsha256の対応表はここ>sha256]]

- Model hash(shorthash)はファイルの一部のみを対象とするため衝突が頻発している
- 2023-01-15の更新でとうとうModel hashが10桁の完全なsha256に更新された
-- 新旧の見分け方はたぶん桁数だけ
-- VAEとHypernetworkに対応していないのは実用上(まだ)問題が出ていないからだと思われる
- 完全なファイルのsha256を取ることで衝突回避は可能
-- https://github.com/aka7774/sd_filer
-- https://github.com/aka7774/sd_infotext_ex
-- https://github.com/aka7774/sd_infotexts
** ファイル形式

拡張子で判別する。

*** .ckpt

- checkpointの略。
- チクポチではない。が、チクポチが出るかどうかはこいつ次第。
- ロード時にPythonのコードを実行できるため安全とは言い切れない
-- まれにウィルスソフトが誤検知を起こして騒ぎになっていたりする
- 狭義のモデルではないファイル(VAEとか)にもこの拡張子が使われることがあるので注意

*** safetensors
- Hugging Face提唱の形式
- ロード時にPythonのコードを実行できないので安全
- 読み込みも速くなる(はず)
- NMKDでは対応していない

** 精度

あくまで数値の精度であって、見た目の綺麗さや絵の細かさに直結するわけではない。

*** fp32(単精度浮動小数点数)
- floating pointの略。A1111系でfullとかいう言葉が出てきたら大抵これのこと。コンピュータの世界ではfloatと呼ぶ場合はこれ。
- 1ビットの符号と8ビットの指数部と23ビットの仮数部
- 現行のハードウェアはすべて対応
- 高精度だが計算量が多い
- 生成AIでは重い割にfp16とあまりかわらない

*** fp16/float16(半精度浮動小数点数)
- 生成AIで主流の精度
- floating pointの略。halfとかいう言葉が出てきたら大抵これのこと。
- 1ビットの符号と5ビットの指数部と10ビットの仮数部
- 処理が速い
- 容量が半分で済む
- IntelとNVIDIAのGPUで対応している(AMDはRDNA3以降で対応？)
- ダイナミックレンジが狭いためオーバーフローによるNaN演算を起こしやすい

*** bf16/bfloat16
- 1ビットの符号と8ビットの指数部と7ビットの仮数部
- fp32と指数部が一緒になる（ダイナミックレンジが広い代わりに仮数部が減ってるので小数点以下の表現力はfp16より少し落ちる）
- IntelとNVIDIAのGPUで対応している(AMDはRDNA3以降で対応？)
- fp16よりNaN演算を起こしづらい

*** fp8(float8_e4m3fn)
- 1ビットの符号と4ビットの指数部と3ビットの仮数部(ほかにもある)
- fp16の半分のメモリ使用量
- だが精度も落ちる
- Torchが自動でキャストするので非対応のGPUでも動作する。
- NVIDIAのRTX4000以降であればそのまま動いて多少速くなる・・・はずがほとんどのソフトがfp8演算に非対応でfp16にアップキャストするのでむしろ遅くなる。

*** NormalFloat4(LinearNF4)
- 量子化をすることで精度低下を抑える？

[+] 古い情報
SDXLはpruned,fp16がデフォルトです。左の状態でSD1なら2.13GB(1.98GiB)、SDXLなら6.94GB(6.46GiB)前後になる。
** ema(SD1)

- Exponential Moving Average(指数移動平均)の略
- モデルのトレーニング中に、トレーニングしたパラメータの移動平均を維持すると有益らしい([[TensorFlow API>https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage]])

- どっちが学習向きなの？
- 容量は変わらんやつがあるけどなんなん？
- LoRA学習ではなくてもいい

*** emaあり
- モデルにトレーニング中のemaが付いている

*** emaなし(no-ema)

- 容量が小さくなるの？

** prune(SD1)

- 生成に不要なデータを削除することで容量を削減すること
- ファイル名に pruned をつけて一緒に配布されていることがある
- 学習時には prune してないファイルがいいの？ 大差ないの？
- LoRA学習ではprunedでもいい
- SDXL以降は元から不要なデータが含まれていないので関係なし。
[END]

* VAE

- 数が少ないので横着せずにドロップダウンから選択したほうがいい
-- Quicksetting listにsd_vaeを追加する
- Checkpointに内蔵されているものを上書きする

* モデル作成

モデルファイルを得られる方法

- Full Fine-tuning
- DreamboothやLoRAのマージ
- checkpoint同士のマージ

** マージ
- [[Checkpoint Merger>ローカルのマージ]]
- [[層別マージ>階層マージ]]

[+] 古い情報(2022)
標準Checkpoint Mergerにバグがあり、Add Differenceを使うとモデルが壊れていた。
n番目のトークンが無視されたり効果が弱まったりする。nは不定(1や76以外もありうる)
これは2023-01-15に修正された。(層別マージニキがプルリク送ってくれた)
それ以前に作られたマージモデルはほぼバグの影響を受けていると思われるので要修正。

詳しい説明と修正方法はこちら。
https://note.com/bbcmc/n/n12c05bf109cc
[END]

* モデル配布

** 配布方法

- [[HuggingFace]] Modelsがおすすめ

** 配布ファイル
- 学習・推論共にfp16, pruned, safetensorsでよい。
- ファイル名には日本語やスペースが無いほうがトラブルが減るかも。

*** 作成方法
- https://github.com/arenatemp/stable-diffusion-webui-model-toolkit
-- モデルのpruneや変換ができる
-- 更新停止。一部のVAE焼き込み済みのcheckpointを読み込めない。


