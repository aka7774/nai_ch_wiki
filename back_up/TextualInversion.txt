*概要
Textual Inversion &#183; AUTOMATIC1111/stable-diffusion-webui Wiki - https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Textual-Inversion

TIとは……
 TI(Textual Inversion)とは、短縮詠唱みたいなものです。
 自分の任意の画像を読み込ませると、その画像内に存在する特徴をモデルが知っている範囲でまとめて学習して一つのファイルにしてくれるものです。
 なので、元々のモデルが知らないことは学習できません。
 画風の再現などに優れているらしいです。
 Textual Inversionとは？ - としあきdiffusion Wiki* - https://wikiwiki.jp/sd_toshiaki/Textual%20Inversion%E3%81%A8%E3%81%AF%EF%BC%9F

AUTOMATIC1111(ローカル版)において使うときは拡張子が.ptのファイルをどっかから入手して/embeddingsディレクトリに配置し、プロンプトでそのファイル名を使用します(これを機能させるためにプログラムを再起動する必要はありません)。
基本的にファイル名が呼び出しキーとなるため、ファイル名を変更しても機能する。

学習元と違うモデルでも使用できるが、そのモデルが知っている要素で生成するものと思われるので、再現性が低くなるかもしれないし、逆に上がる可能性もある？
ポーズとかならだいたいどのモデルでも応用がきくはず。

*使用方法
TIファイルを次のフォルダにコピー
>stable-diffusion-webui\embeddings~~
画面のGenerateボタンの下の&#127924;ボタンを押し、Textual Inversion タブから使いたいTIファイルを選択
又はプロンプトに直接TIファイル名(拡張子.ptを除いたもの)を入力

**使用時の注意点
SD1系で作られたTIファイルはSD2系のモデルでは使用出来ない
逆もまた同じ


*学習
学習手順はまだ記載されていません。
とりあえずとしあき拡散を貼っとく↓
Textual inversion - としあきdiffusion Wiki* - https://wikiwiki.jp/sd_toshiaki/Textual%20inversion


**Initialization text
画像の特徴を指定する初期テキスト。学習してほしいタグを書く。以下引用
たとえば "zzzz1234" という名前の１ベクトル（１トークン）の embedding で初期テキスト "tree" を指定したとする。トレーニングなしでそれを "a zzzz1234 by monet" というプロンプトで使うと、その出力結果は "a tree by monet" と同じになる。

そこに学習画像を使用する事でどんなtreeを学んでいくかが変わってくる。
なので学習画像に含まれる特徴及びモデルで認識できるワードが望ましい。
逆に余計なワードや複数の意味を持つワードを入れると望まぬ学習をしてしまう可能性がある。
また学習元モデル以外のモデルで使用する際、モデルによって認識できるワードが異なるため出力結果も変わってくるはず。


**Number of vectors per token
作成するptファイルのtoken数。どれだけの情報を埋め込むかを指定する。Shondoit氏曰く
「多すぎると柔軟性に欠けます。少なすぎると細部が失われる可能性があります。通常、1〜4個で十分です。それ以上だと、他のプロンプトを圧倒し始めます。」
とのこと。複雑な服装や装飾のキャラの再現性を高めたい場合は増やしていくといいのかもしれない。
学習画像、学習率、ステップ数との兼ね合いも考慮する必要はある。

**Learning rate
学習速度。高すぎる値を設定すると embedding が壊れる。デフォの「0.005(5e-3) 」は高すぎるらしい。複数の学習率を指定することもできる。
Batch size：１回の学習に使う画像枚数。これを上げると、VRAM を余計に使い計算速度も落ちるが、精度が上がる。(chatGPTに訊くと逆の事を言われる…)
Dataset directory：学習に使う画像が入ったディレクトリ。画像のアスペクト比は１：１である必要がある。

*応用
**手を修復する：bad_prompt
TextualInversionで悪い手の形を学習させて、Embeddingでネガティブプロンプトとして使うことで正しい手の形を生成するやつです。
→[[大量検証結果]]に検証結果を掲載しました
