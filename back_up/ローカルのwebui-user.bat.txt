* 概要

このファイルを実行するんやで(webui.batではない)
以下はこのファイルを編集する話。

#contents

* うまく動かないとき

webui.batで起動すると、webui-user.batで設定した内容をすべて無視して起動することが出来る。
もしそれで起動するならwebui-user.batに書いた内容が原因と思われる。

* PYTHON

普通は空でいい。
PATHの通ってないPython.exeを使いたければフルパスで指定することができる。

* GIT

空を推奨。
PATHの通ってないGITを指定しても動かない。(バグだと思う)

* VENV

空を推奨。webui直下にvenvを作る。
この場所を変更したい時に入れる。

* COMMANDLINE_ARGS

set COMMANDLINE_ARGS=の右に目的のパラメータを入力します
複数ある時は半角スペースで区切ります。

 set COMMANDLINE_ARGS=--xformers --opt-channelslast

https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings

以下はよく使うオプションのみ紹介。

** --xformers (高速化/VRAM消費減)

おすすめ。
WindowsではPython 3.10が必要っぽい(3.9だとエラーが出る)
Colabではcondaで入れると入れやすい。
出力画像が少しだけ変わると言われているがエビデンスなし。

出力の比較をしたので詳細はこちらへ↓
[[xformersの検証]]

** --opt-channelslast (高速化)

4000番台で効果あり。3000番台でもちょっと効果あり。
2000番台だと効果なし？ Linuxだと効果あり。

先に以下の設定をやる。

コマンドプロンプトを起動
stable-diffusion-webui\venv\Scripts\activate.bat を実行
=|BOX|
pip install -U -I --no-deps torch==1.12.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116
||=

=|BOX|
https://pomf2.lain.la/f/5u34v576.7z
||=
このファイルをstable-diffusion-webui\venv\Lib\site-packages\torch\lib
にコピペ

=|BOX|
pip install -U -I --no-deps torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116
||=
** --no-half-vae (画像真っ黒対策)

VAEを使っている時、たまに画像が真っ黒になる問題を修正する。
fp16ではなくfp32を使う。
VRAM不足だけでなく、Anything+VAEの環境とかで真っ黒になりがち。

** --no-half (16XXの高速化)

以前は1650、1660、1660Tiで画像が必ず真っ黒になってしまう問題があり、
その対策としてこのオプションを用いていた。
今はこのオプションが無くても真っ黒にならなくなったが速度が低下するため、
引き続きこのオプションを付けたほうが良さそう(環境によるのかも)

意味としては、モデルでfp16ではなくfp32を使う。
半精度浮動小数点数(fp16)はハードウェアに搭載されているのだが、
cudaの新しいバージョンでは機能しなくなってしまっている(直らんのか?)
 --precision full も一緒に使う事になっているが、実は無くても動く。

fp16が動く環境で使うと余計にVRAMを使うので要注意。

** --medvram もしくは --lowvram (VRAMの少ないGPUでの実行)

VRAMの少ないGPUでは設定の変更が必要な場合があります。
これらのパラメータは、より大きな画像やバッチサイズを作成したい通常のユーザーにも役立ちます
いくつかの変更により、VRAM使用量を大幅に削減することが可能です。

4GBのVRAMがあり、512x512(またはそれ以上)の画像を作成する場合：--medvram
2GBのVRAMの場合：--lowvram
これらのいずれかで「メモリ不足」エラーが発生している場合は、次の引数を追加します：--always-batch-cond-uncond --opt-split-attention

VRAMが足りている環境で使うと速度が落ちるので要注意。

** --ckpt-dir

モデルの保存先を指定する。
デフォルトは models/Stable-diffusion
マージ沼をRamDiskやHDDで遊ぶお供に。

** --gradio-img2img-tool color-sketch

わざわざ他のソフトで編集するのが面倒な人は起動引数にこれを足して再起動するとimg2imgの画像編集にカラーパレットがつく
&color(#808080){スポイトツールもあるから肌の色を取ってちょっと服を塗りつぶして脱がすとかならこれで十分 }
スポイトツールは確認したけど見当たらない。(環境による?)
** --share --gradio-auth user:password (Colabなどクラウド用)

--shareでインターネットごしにアクセス出来るURLを作成する。
--gradio-authで使用するためのユーザー名とパスワードを設定する。
userとpasswordは任意に変更する。

** --listen --enable-insecure-extension-access (LAN用)

--listenで自分のPC以外からのアクセスを受け付ける。
--enable-insecure-extension-accessで、自分のPC以外からのアクセス時にExtensionsのインストールを許可する。
用途に応じて--shareと使い分けると良さそう。
WiFiの繋がったスマホでポチポチしたいだけならこれで十分。

** --skip-torch-cuda-test (GPUのかわりにCPUを使う(非推奨))

CPUがfp16をサポートしていない場合エラーが出るので、
 --no-half --no-half-vae
も追加で設定する。

3060比で100倍くらい時間かかるようになるけど動く。

** --autolaunch (自動的にブラウザを立ち上げる)

既定のブラウザで1111が開く。

http://127.0.0.1:7860/
をブラウザにコピペする手間が省ける。

** --reinstall-xformers (xformersの再インストール)

10xxシリーズ(Pascal)以降のCPUを使っているなら
 --reinstall-xformers --xformers
と指定することで xformers を再インストールできる。
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Troubleshooting#cuda-error-no-kernel-image-is-available-for-execution-on-the-device-after-enabling-xformers

** --disable-nan-check
NaNチェックを無効にして生成時に出るNansExceptionで画像生成が止まらないようにする。
おそらく従来どおりの黒画像が出るようになると思う。

** (削除) --deepdanbooru

img2imgでDeepdanbooruを使う。画像からDanbooruタグを推定する機能。
標準機能になったのでコマンドラインオプションは不要になりました。


* PYTORCH_CUDA_ALLOC_CONF

VRAM不足の時に使えそうだけど最適な値はよくわからん
https://pytorch.org/docs/stable/notes/cuda.html#memory-management

108スレの176
=||
結局
・batファイルに　set PYTORCH_CUDA_ALLOC_CONF=garbage_collection_threshold:0.6,max_split_size_mb:24 を追加
・ブラウザのハードウェアアクセサレータをオフ
・PC再起動
でtrainはじめて今ブンブン回ってるで。 
||=

* (隠し) ACCELERATE

 SET ACCELERATE="True"

と入れると、accelerateを使う。

まだ実力のほどはわからないが、
そのうちfp16/fp32に起因するエラーが減ったり、
マルチCPUに対応したりするのかも知れない。



