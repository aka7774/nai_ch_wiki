#contents
*概要
ローカルで使えるStable Diffusion周りのリソースデータの情報をまとめるところです。

&#128317;：ダウンロードリンク

*掲載方針
%%網羅は/sdmodelsなどに任せるとして、以下のようなものを載せる感じがいいかもしれない%%
%%+スレで話題になったもの%%
%%+特に有用なもの%%
sdmodelの更新が滞りがちになったので適当に掲載していい気がする



*リソース(一覧)
+Civitai | Every model in one place｜https://civitai.com/　~~モデルアップロードプラットフォーム。見やすくてよき
+https://rentry.org/sdmodels ~~ここ見ときゃいい感はある。膨大な量のリンク集
+Models - Hugging Face - https://huggingface.co/models?pipeline_tag=text-to-image&sort=modified
+/hdg/ Stable Diffusion Models Cookbook - https://rentry.org/hdgrecipes#g-anons-unnamed-mix-e93c3bf7 ~~海外ニキによる様々なマージモデルの一覧
+https://rentry.org/hdgfaq ~~スレでよく話題に出るCondom Belt(Embed)とか各種有用Embed＆HyperNetwork等

* データセット

** Pixiv

- haor/pixiv-yandere &#183; Datasets at Hugging Face - https://huggingface.co/datasets/haor/pixiv-yandere
- haor/pixiv_month_top50 &#183; Datasets at Hugging Face - https://huggingface.co/datasets/haor/pixiv_month_top50



*モデル

- URLのコピーは赤丸を右クリック
- URLに resolve が入ってるのが正しい

[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/Sxek2yNsj0-s.jpg)>https://image02.seesaawiki.jp/n/h/nai_ch/Sxek2yNsj0.jpg]]

** Instagram
さまざまなInstagramアカウント(主に日本語)の合計1.2mの画像で約1.6エポックからトレーニングされています。モデルのトレーニングが不足しているため、そのパフォーマンスはわずかです。パフォーマンスを向上させるために、モデルを混在させることをお勧めします。
&#128317;instagram-latest-plus-clip-v6e1_50000.safetensors｜cafeai/cafe-instagram-sd-1-5-v6 &#183; Hugging Face - https://huggingface.co/cafeai/cafe-instagram-sd-1-5-v6


** EVT（ピクシブ学習モデル)

*** Evt_V3
EVT_V2を元にして、35467枚の画像を使用して微調整を行ったモデル
&#128317;haor/Evt_V3 &#183; Hugging Face - https://huggingface.co/haor/Evt_V3

*** Evt_V2
15,000枚の画像(7,700枚の反転)を用いて追加学習したモデル
&#128317;haor/Evt_V2 &#183; Hugging Face - https://huggingface.co/haor/Evt_V2

** ACertain

*** ACertainModel 
- JosephusCheung/ACertainModel &#183; Hugging Face - https://huggingface.co/JosephusCheung/ACertainModel
▼このモデル is 何
要約しちゃえばAnything-3.0ベースの亜種
AnythingV3はかわいい女の子を生成する用途に最適化されすぎてる問題をどうにかしたかったっぽい

▼詳細
 Anything-3.0などコミュニティで人気のあるモデルを使って、1プロンプトから自動生成した大量の画像を学習セットに加え、さらに1年以内に手動で選んだdanbooru画像を加えて、ネイティブ学習を実施しました。（中略）著作権コンプライアンスと技術実験のために、少数のアーティスト画像から直接トレーニングされました。コミュニティで人気のあるいくつかの拡散モデルから生成された写真を使用して、Dreamboothでトレーニングされました。チェックポイントは、安定した拡散モデルの重みで初期化され、その後、V100 32GBで2K GPU時間、A100 40GBで600 GPU時間、512Pの動的アスペクト比解像度で微調整され、テキスト反転とハイパーネットワークを備えたコミュニティで人気のあるいくつかの拡散モデルからの教師なし自動生成画像が一定の比率で調整されました。xformersと8ビット最適化に関するいくつかのトリックを知っていますが、品質と安定性を向上させるためにそれらのどれも使用しませんでした。最大15のブランチが同時にトレーニングされ、約20,000ステップごとにチェリーピッキングが行われます。
とのこと。

*** ACertainThing 
- JosephusCheung/ACertainThing &#183; Hugging Face - https://huggingface.co/JosephusCheung/ACertainThing
▼このモデル is 何
ACertainModelのもっとAnythingV3してるモデル

▼詳細
AnythingV3は人間の画像や特定のディテール(certain details)を生成する用途に最適化されている。逆に言えばそうではないモチーフを生成する場合に過剰にオーバーフィットしている。
だけどAnythingは人気だからDreambooth(LoRA統合のアイデア)で作成され、ACertainModelで初期化されたAnything3.0のACertainバージョンを作ったよ、とのこと。
 このモデルは画像生成でより良い結果をもたらすかもしれませんが、それは2つの大きな問題に基づいて構築されています。第一に、それは常にあなたのプロンプトに忠実であるとは限りません。それは無関係な詳細を追加し、時にはこれらの詳細は非常に均質化されます。第二に、これはAnything3.0と同様に不安定でオーバーフィットしたモデルであり、さらなるトレーニングには適していません。


** Elysium
アニメモデルのElysium_Anime_V2.ckptが良さそう
Elysium_Anime_V1.ckpt｜セミリアル系
Elysium_Anime_V2.ckpt｜アニメ系
Elysium_V1.ckpt｜実写系

&#128317;hesw23168/SD-Elysium-Model at main - https://huggingface.co/hesw23168/SD-Elysium-Model/tree/main

モデルごとの比較表
[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/5jC0_D0iZy-s.jpg)>https://image02.seesaawiki.jp/n/h/nai_ch/5jC0_D0iZy.jpg]]
リファレンス：二次元絵・アニメモデルが次々と登場 - MarkdownとBullet Journal - https://programmingforever.hatenablog.com/entry/2022/11/20/171658

なおVaeは以下のように推奨されています。''※.ckpt拡張子で配布されているので、~~~.ptにリネームしてmodels/VAEフォルダに配置します。''
- (General model): Clip skip 1, VAE: 'vae-ft-mse-840000' from StabilityAI ：https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main
Sampler: DPM++ 2M Karras
- (Anime model): Clip skip 1 or 2, VAE: 'kl-f8-anime2.ckpt' from Waifu Diffusion：https://huggingface.co/hakurei/waifu-diffusion-v1-4/tree/main/vae
Sampler: DPM++ 2M Karras

** EimisAnimeDiffusion
&#128317;eimiss/EimisAnimeDiffusion_1.0v &#183; Hugging Face - https://huggingface.co/eimiss/EimisAnimeDiffusion_1.0v
高品質で詳細なアニメ画像でトレーニングされたモデル


** Gape
&#128317;(閲覧注意)Gaping/Large Insertion model - https://rentry.org/gapemodel
Danbooruにある極端にNSFWなコンテンツのみを学習させたモデル。
一見すると特殊な人にしか必要ないようにみえるが、NSFWコンテンツが検閲されたり学習していないモデルとマージすることで局部描写の補完に使える有用モデル
参考：[[ローカルのマージ]]


** Anything-V3.0
Anime model
Info https://www.bilibili.com/read/cv19603218
&#128317;Linaqruf/anything-v3.0 at main - https://huggingface.co/Linaqruf/anything-v3.0/tree/main
&#128304;：Anything-V3.0-pruned.ckptがおすすめ
※：なお容量削減版(たいてい名前に「pruned」がついている)は学習時におけるデータを削除したモデルデータとのことです。
出力時には問題ありませんが、学習系の作業に使う場合は非推奨です。


** NAI
要Torrentクライアントソフト
&#128317;
=|BOX|
magnet:?xt=urn:btih:5bde442da86265b670a3e5ea3163afad2c6f8ecc
||=
ソース：--GUIDE-- - https://rentry.org/voldy#-novelai-setup-

*マージモデル
→[[ローカルのマージ>ローカルのマージ#content_8]]に移動させました。

* VAE
&aname(resource_vae)
Anything, NAIに同梱されているもの以外に、以下のvaeがある。
拡張子が.ckptなので、.ptに変えてmodels/VAEフォルダに置くことで認識可能

| kl-f8-anime.vae.pt | https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt |
| kl-f8-anime2.vae.pt | https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt |
| autoencoder_fix_kl-f8-trinart_characters.vae.pt | https://huggingface.co/naclbit/trinart_derrida_characters_v2_stable_diffusion/resolve/main/autoencoder_fix_kl-f8-trinart_characters.ckpt |
| vae-ft-mse-840000-ema-pruned.vae.pt | https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt |

----

* HyperNetwork
ローカル部│[[HyperNetwork]]

** 騎乗位SEX用HN
どんだけ騎乗位の呪文設定しても斜め構図と仰け反る頻度が高すぎるから作ったイチャラブ騎乗位SEX用HN
[[詳細ページ：騎乗位SEX用HN]]

** 韓国HyperNetworkコレクション
&#128317; &#44277;&#50976;&#46108; hypernet, embedding &#47784;&#51020; (&#49368;&#54540; 有) - AI&#44536;&#47548; &#54617;&#49845; &#52292;&#45328; - https://arca.live/b/hypernetworks/60940948?category=%EA%B3%B5%EC%9C%A0&p=1
韓国で掲載されている、絵師の絵柄の再現を目的としたとてつもない量のHypernetworkのコレクション
個々にダウンロードできるほかまとめてダウンロードできるMegaリンクが一応ある(ただしフリーだと大抵途中で制限くらってしぬ)
Jdownloader等を使ってこっちでダウンロードするんだ　→　Link scrape: &#128317;https://pastebin.com/p0F4k98y

→''huggingfaceにコレクションを置きました。''
&#128317;https://huggingface.co/WarriorMama777/HyperNetworkCollection_v2/tree/main
HyperNetwork
まとめてダウンロードすることができます。※Git、またはGithubDesktopでクローンリポジトリしてください。

----

** 128スレ184 SD着ぐるみパジャマ部
https://huggingface.co/gyungyun/mist-sd/tree/main
https://majinai.art/i/2UnRCMI.webp
&ref(https://imgur.com/nfnfsaP.png,200) &ref(https://imgur.com/CVaJ4eK.png,200) &ref(https://imgur.com/sSjW0K4.png,200)
>hn公開したから使ってみてや~~

* TextualInversion
ローカル部[[TextualInversion]]

** 手の補正TI

&#128317;Nerfgun3/bad_prompt &#183; Datasets at Hugging Face - https://huggingface.co/datasets/Nerfgun3/bad_prompt
TextualInversionで悪い手の形を学習させて、Embeddingでネガティブプロンプトとして使うことで正しい手の形を生成するやつ。
効果ありそう。
検証はローカル部のページ[[TextualInversion]]に書いたで

** Finding embeddings online

- huggingface concepts library - a lot of different embeddings, but
-- https://cyberes.github.io/stable-diffusion-textual-inversion-models/
- 16777216c - NSFW, anime artist styles by a mysterious stranger.
-- https://gitlab.com/16777216c/stable-diffusion-embeddings
- cattoroboto - some anime embeddings by anon.
-- https://gitlab.com/cattoroboto/waifu-diffusion-embeds
- viper1 - NSFW, furry girls.
-- https://gitgud.io/viper1/stable-diffusion-embeddings
- anon's embeddings - NSFW, anime artists.
-- https://mega.nz/folder/7k0R2arB#5_u6PYfdn-ZS7sRdoecD2A
- rentry - a page with links to embeddings from many sources.
-- https://rentry.org/embeddings
* 学習系リソース
** 透明正則化画像
512x512、768x768、1024x1024の透明画像詰め合わせ　各1000枚ずつ
https://image02.seesaawiki.jp/n/h/nai_ch/UUBObtbfCe.zip



