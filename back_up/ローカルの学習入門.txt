新しいLoRAノートブックはこちら→[[kohya_train_network_simple]]
&color(#ff0000){このページの内容は残念ながら古いので手順通りに試してもうまく動かないようです。}
&size(20){現在のLoRA学習法は[[Dreambooth-LoRA>Dreambooth-LoRA]]を参照。}

画像生成は経験済みだが、まだ学習をやったことない人が対象。

#contents

* 学習方法の違い
=|BOX|
698 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ 0154-0d8E)[sage] 投稿日：2023/01/09(月) 19:11:42.17 ID:OMJT1FQ70 [4/5]
HNとDBとTIとかの違いがいまいちわからんくなってきたわ
||=
=|BOX|
740 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ 9943-tb1I)[] 投稿日：2023/01/09(月) 19:58:06.59 ID:RzPG3voj0 [13/16]
>>698
キーワードを書いて、それが各トークンに分割される。各トークンはそれぞれ768個の重み＝特徴の強弱が設定されている。
モデルは、現在の画像（最初はノイズ）とそのトークンの重みを与えられて、画像から少しノイズを取り除こうとすることを繰り返して絵を作る。
モデルの形自体は決まっているが、モデル自体が持っているパラメータによって、画像のどんな特徴を重視（圧縮）して、どういう風に復元（展開）するかが変わる。

TI：768×数〜数十トークン分の重みを割り出すことで、期待する特徴を備えたキーワードを作る
どんなの特徴成分の組み合わせでターゲット画像が再現できるかを学習する。
だから分かりやすい特徴や属性の組み合わせで再現できる物に向いている。

HN：重みをモデルに伝える部分に入り込んで、期待する画像をモデルが作りやすいように変換する
特徴成分全体を特定のパターンで変形する。
だから特徴全体を揺れ動かす必要があるような、絵柄の学習に向いてるし、特徴自体の強化や矯正もできるので、物の学習もできる。
||=
=|BOX|
746 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ 9943-tb1I)[sage] 投稿日：2023/01/09(月) 20:00:44.89 ID:RzPG3voj0 [14/16]
>>698　>>740 の続き
DB：モデル自体のパラメータを学習する。
TIやHNはあくまでテキストから特徴を作り出す部分を改善するもの。
つまりできる限りそのモデルの力を引き出すことはできても、そもそも元からそのモデルが作ることが困難な絵は作れない。
DBならモデルのパラメータ自身を学習するのでその制限を超えられる。（もちろん、SDの仕組みとモデルの形自体からくる得意不得意からは逃れられない）

例えば、部品メーカーが、幾万とある珍しい部品の画像を製品番号から出したいとする。
そうなると、まずそういう珍しい画像を精密に描画できるだけの能力がモデルにないかもしれないし、
製品番号のトークンから、適切な素材の重みにHNで変換しようとしても、
よくあるプロンプトから逸脱しているので、とても深く大きいHNが必要になりそうなことが予想される。
そういう場合はモデルを作ったほうが良い。
他にも、そのモデルが弱い特徴を持った画像を追加学習させることで、上手く行けばその要素を強化したりもできる。
||=
それぞれの学習方法や詳細は個別ページにて

* 学習方法の選択

TI, DB, HN, DA, Loraなど。
どれがいいかは目的に応じて変わるので、当面は全部やって比較検討するのがいい。
1111以外を使う方法もあるが、1111を使えば全部できる。

ここでは1111を使って、Lora(DB)とHNを試してみた。
用意した環境は次の2つ。

- VRAM 8GBのNVIDIA GPUを搭載したローカルPC
- 無料Colab

細かい調整は省き、再現性のある手順を示す。

* (解説)正則化画像について

[+]
本来の意味的には、
「Class Prompt」は「girl」で、
「Instance Prompt」は「shikoku metan」になる。

よって、正則化画像としては、「girl」でありながら、
「shikoku metan」ではない画像を用意することで、
「shikoku metan」の特徴が具体的にどの部分を示すかを、
データセット画像と正則化画像の差分で示すという仕組みのはず。

きちんと用意するなら、「1girl」だけの画像生成を行うなどの方法が考えられる。
背景の影響も受けるので、simple backgroundにして、Katanukiを使って・・・。

しかし、正則化画像の用意は大変であり、うまくいかない事も多かった。
「Instance Prompt」も他の名詞につられない独立した名前(昔で言うsks、今は非推奨)が良いという話があり、
ここでも「skkmtn」に変えているのだが、
「Class Promptも意味不明な文字にしよう」という流れがあったりして定まらなかった。

そんな中で「ただの透明画像を正則化画像に指定するとなぜか結果が良くなる」流派が現れた。
研究自体の試行回数が少ないので確かとは言えないが、掲載の手順ではこの流儀を採用している。
無意味だと考えるなら、toukaを指定しなければ正則化画像なしで動作する。
[END]

* LoRA(四国めたん)

Dreamboothのオプションとして利用可能。
DB比で高速、生成されるファイルも小さい。
完成度についてはDBに匹敵するほどはある。現在主要のファインチューニングとなっている。

- 解像度512
- 所要時間はローカル(2070)だと15分程度、Colabだと全部で1〜2時間くらい
- 実用的(着せ替えなどをして遊べる)

Colabでは解像度768で動作することも確認済み。

追記

- --test-loraは指定しなくても良くなった
- ckptは自分でGenerateするまでは出力されなくなった
- 2022-12-13アップデートで設定項目が変わった
- NAI VRAM 8GBでも動作することを確認した
- 最小限の設定項目で実施する(ひとまずデフォルト値を信じる)

** リンク
- 公式リポジトリ│https://github.com/cloneofsimo/lora
- webで使える&#129303;のloraツール│https://huggingface.co/spaces/ysharma/Low-rank-Adaptation

dreambooth使わないから外してて知らなかったけどすでにLORA実装してるらしいじゃん！
Commits見ると8日にはもう取り入れてるぞ
引用：ふたばより

** ねらい

- Colabは早いと3時間程度でGPUが使用停止になるので学習時間の短縮も図る
- できれば一回のセッションで学習を完了させたい
- Drive容量も含めて無料で済ませたい

** 1. Colabの起動

- Colab [[入門用Notebook]]

無料ColabだとNAIはなぜか動かなかった。アップデートで直った可能性はある。(後述)
K80になったことは無いけどT4が引けてるか一応確認するといいかも。

** 1. ローカルの起動

Extensions から Dreambooth をインストールする

** 2. 画像の用意

Colabだと1111の起動に15分+ダウンロード時間ぶんかかるので待ってる間にやる。

ダウンロード
- https://image02.seesaawiki.jp/n/h/nai_ch/aQEovutlvq.zip skkmtn.zipにリネームする
- https://image02.seesaawiki.jp/n/h/nai_ch/MHIWw0HVJD.zip touka.zipにリネームする

中身は学習用データセット14枚
- https://zunko.jp/con_illust.html
- 16枚からビーチチェアとデフォルメを除いた

解像度768版
[+]
中身を解凍して1つに混ぜてskkmtn.zipとして再圧縮してください(5MB制限のため)
https://image01.seesaawiki.jp/n/h/nai_ch/CTlFvCz0og.zip
https://image02.seesaawiki.jp/n/h/nai_ch/BH7XXOAncb.zip
透過画像200枚
https://image02.seesaawiki.jp/n/h/nai_ch/lh1xkGmvts.zip
[END]

** 3. 画像のアップロード

ここからは1111の起動後にやる。

- あると便利なExtension(入門用Notebookでは自動インストール)
-- Image Browser
-- Filer
--- https://github.com/aka7774/sd_filer

- Filerのimagesに2つのzipをドロップする
-- あるいは webui直下にzipファイル名のディレクトリを作りzipの中身を展開する
- Image BrowserのOthersで skkmtn と touka を選択する
-- 画像が見えることを確認する
** 4. モデルファイル作成

「Dreambooth」タブを開いた後、真ん中の「Create Model」タブが開かれていること確認する。

- Name: skkmtn
- Source Checkpoint: Anything-V3.0-pruned-fp16.ckpt
-- ローカルだと animefull-final-pruned.ckpt でも動くかも

以前の設定
[+]
- Scheduler: pndm
[END]

「Create」ボタンを押す。

[+]
Colab で animefull-final-pruned.ckpt が止まる例
=||
Loading model from checkpoint.
Loading checkpoint...
v1 model loaded.
Creating scheduler...
Converting unet...
Converting vae...
Converting text encoder...
^C
||=

このまま強引にTrainまで進めても結局エラーで動かない。

=||
Returning result: Exception training model: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/stable-diffusion-webui/models/dreambooth/skkmtn/working/tokenizer'. Use `repo_type` argument if needed.
||=
[END]

** 5．パラメーター設定

左の「Model」ドロップダウンに「skkmtn」が表示される。
真ん中の「Parameters」タブを押す。

明記されていない項目は初期値のまま。

Settings
- 変更なし

以前の設定
[+]
Settings
- Training Steps Per Image (Epochs): 100
- Max Training Steps: 1400
- Learning Rate: 1e-3
- Resolution: 512
- Apply Horizontal Flip: オフ

Learning Rateは不当に高いかも。この辺の研究参加者が増えることに期待。

Training Steps Per Image (Epochs)はデフォルト値が100になった。
Learning Rateは3つに分かれて、Lora関係は0.002になった。

Apply Horizontal Flipをオフにするのは左右非対称のキャラをDBする名残なので、左右逆になってもいいキャラではオンでも良さげ。
[END]

Advanced
- Use LORA: オン

- Use 8bit Adam: オン
- Mixed Precision: fp16
- Memory Attention: xformers

これはVRAM節約と高速化のために設定していると思うのでお好みで。
つけないとVRAM 8GBでは動かないし、時間は倍近くかかるようになる。

以前の設定
[+]
- Train Text Encoder: オフ

Train Text Encoderはオンだとうまくいかない報告がいくつかあり。
やはりこれは不具合だったらしく修正されたらしい。

[END]

** 6. コンセプト設定

- Classification Dataset Directory: touka
- Dataset directory: skkmtn
- Instance Prompt: skkmtn

Instance Tokenと間違えないように。
Class Promptも入れたほうが良さそうとか色々あるけどまずは最低限で。
もしもVRAMが足りなくてエラーになるのならtoukaは外すことが出来る。

&color(#ff0000){Instance promptはOptionalではなく、入れないとUnable lbuild Concents.エラーが出る。}

** 7. Trainボタンを押す

ローカル2070だと10分程度で終わる。
Colabでも1時間以内には終わるはず。

** 8. ptファイルの合体

左側の「Lora Model」から使いたいptファイルを指定する。

現在の「Stable Diffusion checkpoint」の選択に関係なく、「4. モデルファイル作成」の時に指定したckptがベースになる。
なので別のckptにLoraを適用することは出来ないはず。

Trainによって以下の6つのファイルが出来ているはず。
ここでは「skkmtn_1400.pt」を選択する。

skkmtn_1000.pt
skkmtn_1000_txt.pt
skkmtn_1400.pt　←これ
skkmtn_1400_txt.pt
skkmtn_500.pt
skkmtn_500_txt.pt

「Generate Ckpt」ボタンを押す

** 9. 動作確認

「Generate Ckpt」が完了してから「Stable Diffusion checkpoint」を更新すると、「skkmtn_1400_lora.ckpt」が追加されている。

- プロンプトを skkmtn にして実行

 masterpiece, best quality,1girl,skkmtn

[[&ref(https://image01.seesaawiki.jp/n/h/nai_ch/V9yqhtWOWZ-s.png)>https://image01.seesaawiki.jp/n/h/nai_ch/V9yqhtWOWZ.png]]

- うまくいってればワードを追加する

 masterpiece, best quality,1girl,skkmtn,school costume

[[&ref(https://image01.seesaawiki.jp/n/h/nai_ch/FMxCu3WqiN-s.png)>https://image01.seesaawiki.jp/n/h/nai_ch/FMxCu3WqiN.png]]

 masterpiece, best quality,1girl,skkmtn,nude

[[&ref(https://image01.seesaawiki.jp/n/h/nai_ch/pPhbIXuQrz-s.png)>https://image01.seesaawiki.jp/n/h/nai_ch/pPhbIXuQrz.png]]

(過学習だと思ったらLearning Rateを下げて再挑戦)

** 10. ptファイルのダウンロード

models/lora にファイルが出来ている。
Colabだと消えてしまうのでsd_filerを使ってダウンロードする。(ほかの方法でも良い)

- 「Filer」タブの「Loras」タブの「Active」タブで欲しいものにチェックを入れて「Download」
- 容量が少ないので「Select All」でも大丈夫
- ダウンロードリンクが表示されるのでクリックする

ダウンロードしたファイルは models/lora に設置すれば「Lora Model」の一覧に表示される。
sd_filerを使ってアップロードすることも出来る。

** 11. 学習の再開

再開できていないバグがあるのではないかという話だったけど最新でどうなってるか不明。

models/dreambooth/skkmtn を保存しておけば続きから学習できる。
skkmtn_1400_lora.ckpt ファイルに対して追いLoraすることもできる。(意味的には異なるはず)

* Hypernetwork(四国めたん)

108スレの571、572、575、576を参考にした。

モデルは skkmtn_1400_lora.ckpt を選択。

** 1. ファイルの用意

画像はLoraと一緒。

以下の内容だけが記載されたファイルを
C:\stable-diffusion-webui\textual_inversion_templates\mb1f.txt (どこでもいい)に保存
=|BOX|
masterpiece, best quality, 1girl, face
||=

** 2. ptファイル作成

「Train」タブを開いた後、「Create hypernetwork」タブを開きます。

- Name: skkmtn
- Enter hypernetwork layer structure: 1, 2, 2, 1
- Select activation function of hypernetwork. Recommended : Swish / Linear(none): mish

** 3. Train

「Train」タブを開く

- Hypernetwork: skkmtn.pt を選択
- Hypernetwork Learning rate: 0.00001(デフォルト)
- Dataset directory: skkmtn
- Prompt template file: C:\stable-diffusion-webui\textual_inversion_templates\mb1f.txt (用意したもの)
- Gradient accumulatelion steps: 14
- Max steps: 182
- shuffle tags by "," when creating prompts: オン
- Choose latent sampling method: deterministic

スレでの指定は180だったが、14の倍数できりよく182とした。
プレビュー画像を出すとVRAM不足で落ちるので注意。(今回は500以下だから関係ない)

30分ちょっとかかる。

** 4. 動作確認

- ptが出来上がっているはずなので、通常通り Hypernetwork のプルダウンから選ぶ
- Generate

 masterpiece, best quality, masterpiece, skkmtn

[[&ref(https://image01.seesaawiki.jp/n/h/nai_ch/_2uxhE4HZW-s.png)>https://image01.seesaawiki.jp/n/h/nai_ch/_2uxhE4HZW.png]]

 masterpiece, best quality, 1girl, face, skkmtn

[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/5U0aplLM7z-s.png)>https://image02.seesaawiki.jp/n/h/nai_ch/5U0aplLM7z.png]]

 masterpiece, best quality, 1girl, skkmtn, bikini

[[&ref(https://image01.seesaawiki.jp/n/h/nai_ch/8LEogCNweQ-s.png)>https://image01.seesaawiki.jp/n/h/nai_ch/8LEogCNweQ.png]]

旧バージョン
[+]
* 学習元画像の準備

- ハローアスカをして10枚の画像を生成する
- 「C:\helloasuka」の中に入れる

プロンプトに「helloasuka」を入れることで学習を確認する。
(学習前はハローアスカは出てこない)

** 学習の事前準備(省略)

- 何らかの方法で背景を透過させてから白背景にする
-- Photoshopとか、Ralpha(フリーソフト)とか
-- Webアプリもあるけどあんまり精度が良くないっぽい

* Dreambooth

** 自分のPC

- 画像生成までの環境構築ができていることが前提。
- Windows
- 1111を最新にする。

*** インストール

- Extensions から Dreambooth をインストールする
- stable-diffusion-webui\venv\Scripts\Activate.ps1 (もしくはbat) を開く
 pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116
- 1111を一度終了して起動しなおす

** 無料版Colab

NAIleakの自動インストールコマンドはここに書けないので入門ではAnything v3を使う。

+ https://www.python.jp/train/experience/colab.html
+ https://www.python.jp/train/experience/exec-python1.html
+ HuggingFaceのトークンを手に入れる https://huggingface.co/settings/tokens
+ 「1+1」のかわりに[[入門用Notebook]]の内容をコピペして実行
+ gradioのshare URLがログの下のほうに書いてあるのでブラウザで開く
+ パスワードは左の{x}ってとこ押したら書いてある

入門が終わったらNotebookは本格的なものに乗り換えたり、
自分でカスタマイズして使うとええやでー

** 1. モデルファイル作成

「Dreambooth」タブを開いた後、「Create Model」タブを開きます。

- Name: helloasuka
- Source Checkpoint: ハローアスカに使ったモデルのckpt
- Scheduler: ddim

「Model」が「helloasuka」になってればたぶんOK。

** 2．トレーニング設定

「Train Model」タブを開く。

「Training Wizard(Person)」ボタンを押してもいいしデフォルト値のままでもいい。

Settings
- Dataset directory: C:\helloasuka
-- Colabなら /content/stable-diffusion-webui/outputs/txt2img-images を指定するとか
-- 左側のファイルアイコンで、フォルダを作ったり画像をアップロードできる
- Save Checkpoint Frequency: 0
- Save Preview(s) Frequency: 0
- Instance prompt: helloasuka

&color(#ff0000){Instance promptはOptionalではなく、入れないとUnable lbuild Concents.エラーが出る。}

Advanced
- Auto-Adjust(WIP) ボタンを押す

CPUでやる場合
- Use CPU Only (SLOW): オン
- Use 8bit Adam: オフ
- Mixed Precision: no
- 1000Stepsで12.5時間かかった(4700U)

** 3. 動作確認

- ckptが出来上がっているはずなので、通常通り Stable Diffusion checkpoint のプルダウンから選ぶ
- プロンプトを helloasuka にして実行(影響を確認)
-- うまくいってればワードを追加する(入門では良い変化にならないかも)
- プロンプトを 1girl など helloasuka 以外にして実行(影響されていないことを確認)

* Hypernetwork

実はCPUでも動く。100倍くらい時間がかかる。

** インストール

*** CPUで動かす場合

 set COMMANDLINE_ARGS=--skip-torch-cuda-test --no-half --no-half-vae
xformersをオフにしないといけないかも。
&color(#ff0000){RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same}が出るため。

** 1. ptファイル作成

「Train」タブを開いた後、「Create hypernetwork」タブを開きます。

- Name: helloasuka
- Enter hypernetwork layer structure: 1,1
- Select activation function of hypernetwork. Recommended : Swish / Linear(none): relu
- あとはいじらない

** 2. Train

「Train」タブの中の「Train」タブを開く

- Hypernetwork: helloasuka.pt を選択
- Hypernetwork Learning rate: 0.0005
- Dataset directory: C:\helloasuka
- Prompt template file: C:\****\stable-diffusion-webui\textual_inversion_templates\hypernetwork.txt
- Max steps: 1000
- Save an image to log directory every N steps, 0 to disable: 1500
- Save a copy of embedding to log directory every N steps, 0 to disable: 1500

生成中に画像を作るには追加のVRAMが必要。
VRAM 8GBの環境で生成するとCUDA out of memoryが出て終わり。

Save a copy〜を0にするとエラーが起きる。1500ならエラーは起きなかった。
&color(#ff0000){FileNotFoundError: [Errno 2] No such file or directory: 'textual_inversion\\2022-11-18\\helloasuka\\hypernetwork_loss.csv'}

** 3. 動作確認

- ptが出来上がっているはずなので、通常通り Hypernetwork のプルダウンから選ぶ
- Generate (入門ではプロンプトによらず影響してしまっているかも)

*** HN適用の一例

masterpiece, best quality, masterpiece, helloasuka
Seed: 3506376363
[[&ref(https://image01.seesaawiki.jp/n/h/nai_ch/Z685SlIIqs-s.png)>https://image01.seesaawiki.jp/n/h/nai_ch/Z685SlIIqs.png]]

* Embedding

挑戦者求む

* Dream Artist

挑戦者求む
[END]





