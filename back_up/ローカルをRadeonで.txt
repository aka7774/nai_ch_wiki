ローカルを様々な環境で動かす情報

まとめ
- Pythonのバージョンは 3.9 3.10 の両対応が良さそう。
- 3.10ではcondaとpipの併用が一応可能そう。

#contents

* Linux

- %%Ubuntu 20.04(22.04でも動くがコンパイルが必要そう)%%
- %%Python 3.9+conda xformersか、Python+pip(xformersなし)か、Python+pip+xformersコンパイルかの3択%%
- Ubuntu 22.04
- Python 3.10.6
-- 3.10.10はコンパイル必要
- Windows環境よりも多少速くなるらしい
- ゲーム機を兼用するならデュアルブートが必要

* WSL2

- Ubuntu 22.04
- Python 3.10.6
-- 3.10.10はコンパイル必要
- デュアルブートは不要になる
- 仮想化による速度低下よりもLinuxによる速度向上の恩恵のほうが上っぽい
- Windows 10と11で使い方が違う。前提となるバージョンがある

* Radeon

PyTorch-DirectMLが楽なので速度的に不利でもそっちを使うようになってきたのかも(エアプ)

- https://gist.github.com/reid3333/541fab0eb29d4c9558de748ef91a8238
- 1111
- Python 3.10.10
- torch 1.13.1

** 検証記録

- VRAMを512MBしか割り当てられないiGPUではブルスクで動かない(4700U)
- G型番でもRadeonのドライバが当たらない環境がある(GeForce搭載だとダメ?)

[+]

* Radeon(Linux)

- https://hub.docker.com/r/rocm/pytorch/tags
- Linux
- Python 3.7(3.8に出来る?)
- PyTorch 1.12.1
- Docker
- xformersは言及なし

安くて省電力でVRAM多くて良さげな、RX 7900 XTX、7900 XTでの学習を夢見て

** ローカル版の導入

*** Linux+ROCm
1. https://dolls.tokyo/howto-stablediffusion-on-amdradeon/ 
「stable-diffusionのインストール」の直前まで読み、2.へ

2. dockerコンテナ内のPythonをアップデートする
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs#updating-python-version-inside-docker

3. https://dolls.tokyo/howto-install-amd-sdwebui/

4.NovelAIの再現
https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/2017

エラーが出たときの対処（英語）
https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/783
https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/1220

** 学習環境の構築

情報求む

* Radeon(Windows onnx)

- https://dolls.tokyo/howto-amd-sd-win/
- Onnx
- SD1.4(1111の対応可否は不明)
- Pythonは3.10
- pip
- xformersは言及なし
- 重いらしい

[END]

* Intel ARC A770

- https://github.com/rahulunair/stable_diffusion_arc
- SD1.5(1111の対応可否は不明)
- Pythonは3.9
- condaとpipを併用
- xformersは言及なし

* Apple M1

** PyTorch

- 1111
- CoreMLより速いらしい?

** CoreML

- https://github.com/apple/ml-stable-diffusion
- SD2.0/1.4/1.5
- 1111での対応検討は「PyTorchで良くない?」説が出ている
-- https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/5309
- Pythonは3.8
- condaとpipを併用
- xformersは言及なし
- iPad Proで38秒なので1060くらいか?

* iOS

- 動作原理はM1のと同じっぽい
- CoreML3対応機種である必要がある(iOS13以降かつiPhone 11以降っぽい)
- メモリ4GB以上?
- 配布アプリの仕様による(1111そのものは無い)
- アプリユーザーによる改造は恐らく不可能
- 画像を小さくして数分程度

* Android

- 話題になってないがいくつかアプリはある様子
- CoreMLのようなMLKitというものがある

* Intel CPU(OpenVINO)

- https://github.com/bes-dev/stable_diffusion.openvino
- SD1.4(1111の対応可否は不明)
- Docker
- python:3.9.9
- pip
- 生成時間は分単位
- Ryzenでも動くっぽい?

* (参考) Colab

- Python 3.9.16 (2023-03-09から)
- miniconda Python 3.10.10
- pip Python 3.10.10
- xformers 0.14はcondaかPythonのバージョンに対応するwhlが必要
- xformers 0.16はpipでインストール可能(だがkohyaでは避けられることも)

* (参考) paperspace

- Python 3.9らしい(伝聞)

* (参考) Windows

- Python 3.10.10
- Python+pip+xformers
