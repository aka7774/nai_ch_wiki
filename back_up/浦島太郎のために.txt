&ref(https://image01.seesaawiki.jp/n/h/nai_ch/PE97wdqgIk.png,800)
&size(12){浦島イラスト｜参考プロンプト：https://majinai.art/ja/i/LmVqyND}

* はじめに
新技術とか流行りとか歴史とかをメモしておくページ
具体的なノウハウとかは専用ページに書いて、ここは紹介程度に。
上の奴ほど新しいという感じで編集していってください。

[+]編集にあたってのお約束
- 嘘松はあかん
事実だけを掲載する。うわさなら裏をとってからや
- ポジティブな話題をメインに
革新的な技術やスレで話題になったおもしろい出来事などを優先して掲載する
技術的なことならネガティブな話題でもOK
例：「●●が使えなくなった」とか「●●が実は壊れていた」等
- お気持ち表明にならないようにする
ある程度自由な作風がゆるされてるけど個人のお気持ちが混ざってないか推敲してから編集しよう

※改定の提案はこちら：[[運用方針など>https://seesaawiki.jp/nai_ch/bbs/39146/l50]]
[END]

2023年以前の出来事は[[こちら>https://seesaawiki.jp/nai_ch/d/%b8%c5%bb%f6%b5%ad]]
* とりあえず最新の環境を教えてクレメンス
2025年1月更新
「そんな性癖で大丈夫か？」
**「大丈夫だ、問題ない」
WebUI:[[reForge>https://github.com/Panchovix/stable-diffusion-webui-reForge]]
[[EasyReforge>https://github.com/Zuntan03/EasyReforge]]を使ってワンクリックでインストールできる。日本語で丁寧に解説されているのでわかりやすい。

Model:[[NoobAI-XL (NAI-XL)>https://civitai.com/models/833294/noobai-xl-nai-xl]]
**「一番いいのを頼む」
WebUI:[[ComfyUI>https://github.com/comfyanonymous/ComfyUI]]
[[Stability Matrix>https://github.com/LykosAI/StabilityMatrix]]を使って簡単にインストールできる。[[EasyHunyuanVideo>https://github.com/Zuntan03/EasyHunyuanVideo]]で動画の生成もできるで
おそらく出来ることは一番多いが複雑な外観に眩暈する人を量産している
RTX5000シリーズは2025年2月18日時点でPytorchに対応するバージョンがないCUDA12.8以降にしか対応していないため、AUTOMATIC1111及びその派生であるForge、Reforgeでの構築は不可能
したがって現時点ではComfyUIを導入するしかない
RTX5000シリーズが買えた幸せ者は下記リンクの最新版をインストール(上記リンクの安定版では構築不可能)
https://github.com/comfyanonymous/ComfyUI/discussions/6643

[[ワークフロー集>https://github.com/comfyanonymous/ComfyUI_examples]]
[[Wiki>https://comfyui-wiki.com/ja/comfyui-nodes]]

Model:
[[NoobAI-XL (NAI-XL)>https://civitai.com/models/833294/noobai-xl-nai-xl]]
FLUX.1([[ワークフロー>https://comfyanonymous.github.io/ComfyUI_examples/flux/]])
・https://huggingface.co/black-forest-labs/FLUX.1-dev/tree/main
・https://huggingface.co/city96/FLUX.1-dev-gguf/tree/main
* 目次

#contents
*2025年

**2025-03-02 EasyWanVideoが公開される
https://github.com/Zuntan03/EasyWanVideo
Zuntan氏によるEasyシリーズで、WanVideoを使った動画生成の環境がセットアップされる。

**2025-03-01 NovelAI Diffusion v4が正式リリースされる
https://novelai.net/
公開直後の様子では、プロンプトの効き方がv3から変わり、思い通りの画像を出力できないと感じるユーザーが多い模様。SMEAやバイブストランスファーが実装されていないことも一因か。
**2025-02-20 NVIDIA GeForce RTX 5070Tiが発売される
5090/5080を買えた人がほとんどいない上4000シリーズも品薄な中、23時に発売開始。

**2025-02-11 Illustrious XL 1.0が公開される
https://civitai.com/models/1232765
当初はモデルをダウンロードできず、CivitaiやTensor.art、PixAIといったWebサービス上でのみ画像を生成できる形式だったが、多くの批判の声を受けてか翌12日には10ドル支払うとダウンロードできるようになった。

**2025-01-30 NVIDIA GeForce RTX 5090/5080が発売される
予約抽選サイトは混雑でほとんど閲覧できず、実店舗での抽選販売では大勢が殺到し店舗近隣の幼稚園に侵入する人が現れるなど混乱が見られた。
また初期出荷の台数はきわめて少なく、次期出荷は数か月後とみられる上にいくつかのメーカーは値上げを発表している。
なお、RTX5080及び5090は2025年2月13日時点でPytorchに対応するバージョンがないCUDA12.8以降にしか対応していないため、2025年2月13日時点現在ではEasyReforgeでの構築が不可能。
回避策・アップデートがあったら追記願います。
ComfyUIはhttps://github.com/comfyanonymous/ComfyUI/discussions/6643 から50x0対応版をダウンロードできる。

**2025-01-28 Animagine XL 4.0が公開
Hugging Face: https://huggingface.co/cagliostrolab/animagine-xl-4.0
ブログ: https://cagliostrolab.net/posts/animagine-xl-v4-release
ローカルでSDXLが普及するきっかけとなったAnimagine-XLの新バージョンがリリースされた。
データセットが前バージョンから大幅に拡張されており、2025年1月7日までのデータを学習しているとのこと。
エッチなのも対応。
プロンプト関連の変更として新たにスコアタグが追加された。
今後、V4の改良とSD3.5ベースのAnimaestroの開発を進めるとのこと。

**2025-01-10 動画生成の波
動画生成の流れが最近きている
[[lora>https://civitai.com/models/1094156/titty-drop-hunyuan-video-lora?modelVersionId=124322]]でこんなのが作れるで
[+]エロ注意、クリックで展開
[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/nmlNj47glR-s.gif)>https://image02.seesaawiki.jp/n/h/nai_ch/nmlNj47glR.gif]]
[END]

https://fate.5ch.net/test/read.cgi/liveuranus/1736004270/626

正直解説するほど詳しくないがとりあえず備忘録程度に情報をメモしとくで

・動画生成モデル[[HunyuanVideo>https://github.com/Tencent/HunyuanVideo]]の簡単インストーラー
[[EasyHunyuanVideo>https://github.com/Zuntan03/EasyHunyuanVideo]]

なんJNVA部★498 https://fate.5ch.net/test/read.cgi/liveuranus/1736173877/28
=|BOX|
28警備員[Lv.48][N武][N防] (ﾜｯﾁｮｲ abb2-bDSa)垢版 | 大砲2025/01/07(火) 00:09:53.83ID:hvUOYtbR020
https://github.com/Zuntan03/EasyHunyuanVideo
https://yyy.wpx.jp/EasyHunyuanVideo/Sample/ThisIsFine_Toga.mp4 (音注意)
サンイチ！師走は立て込んどったんやが正月休みでEasyHunyuanVideoを用意したで

FastVideo, SageAttention, TeaCacheの併用でGeforce RTX 3060 12GBでもそこそこ高速＆省VRAMや
日本語プロンプトの英訳・LLMやTIPOでのプロンプト補完（イマイチ）・自動＆手動モザイク・アップスケール・フレーム補間・MMAudio音声に対応してあるで

NSFWサンプルは追々追加予定や
||=

・HunyuanVideo用のLoRA学習スクリプト
[[musubi-tuner>https://github.com/kohya-ss/musubi-tuner]]

https://x.com/kohya_tech/status/1874057372609765615
[[&ref(https://image01.seesaawiki.jp/n/h/nai_ch/gYQ09Xg5D_-s.png)>https://image01.seesaawiki.jp/n/h/nai_ch/gYQ09Xg5D_.png]]

・有志の解説
[[HunyuanVideo用キャラクタLoRA作成の手順>https://rentry.co/howtousemusubituner]]

なんJNVA部★498 https://fate.5ch.net/test/read.cgi/liveuranus/1736173877/404
=|BOX|
404今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった 警備員[Lv.5][芽] (ﾜｯﾁｮｲ d3da-WhgO)垢版 | 大砲2025/01/07(火) 16:42:00.55ID:p/D/DW+T04
>>28より前の年明けからずっとHunyuanVideoをいじっていたので、Geforce 3060での
アニメキャラクタ学習LoRAの作り方に関してまとめた文書を作ったよ

rentry.co/howtousemusubituner

基本的にはmusubi-tunerのREADME.ja.mdそのままだけど、タグ付けや学習画像枚数等の
データセットの作成と学習設定に関してはこの設定でうまくいくはず
ダメだったらごめんね
||=

・musubi-tunerのGUI
[[Hunyuan Video Lora Trainning with GUI in Windows>https://civitai.com/articles/10335]]
**2025-01-08 パルリアス作者ニキ、店じまいを宣言
- 当該の書き込み：https://fate.5ch.net/test/read.cgi/liveuranus/1736173877/836
=|BOX|
836 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった ハンター[Lv.331][UR武][SR防][苗] (ｵｯﾍﾟｹ Sr4d-u+6e)[sage] 投稿日：2025/01/08(水) 17:33:04.31 ID:SXtJ11Ptr
>>830
ファー
速攻で転載されて草
まぁv5は正直失敗作やから転載されてもそこまでという感じではあるけど
ちな経過報告するといちおうシビタイに削除依頼は出したがそもそも返事ないな。ほったらかしやわ
それと本人がモデルをアップしてアーカイブ化してても転載はできてしまうようなので運営が対処する以外に対処法はなさそう
いちおう別モデルベースのv5亜種みたいなのは作ってたけどまた転載されそうで面倒くさそうやからパルパルは店じまいということで…すまんでみんな
||=

**2025-01-07 NVIDIAからGeForce RTX5000シリーズが発表される
Blackwell世代のGPUがNVIDIAから発表された。DLSS、Tensorコア、レイトレーシングコア、NVENC、NVDEC、メモリなどがそれぞれ新しい世代にバージョンアップしている。
https://www.nvidia.com/ja-jp/geforce/graphics-cards/50-series/
- GeForce RTX 5090…\393,800より、VRAM32GB、メモリ帯域幅1,792GB/sec
- GeForce RTX 5080…\198,800より、VRAM16GB、メモリ帯域幅960GB/sec
- GeForce RTX 5070 Ti…\148,800より、VRAM16GB、メモリ帯域幅896GB/sec
- GeForce RTX 5070…\108,800より、VRAM12GB、メモリ帯域幅672GB/sec
- （参考）GeForce RTX 4090…VRAM24GB、メモリ帯域幅1,008GB/sec
**2025-01-04 パルリアスv5が公開される
人気モデルのパルリアスにv5が登場、スレが大いに盛り上がった。
公開を告知する書き込み：https://fate.5ch.net/test/read.cgi/liveuranus/1735778359/544
公開場所のURL：https://huggingface.co/paruparu95483/paruparu_illustrious/tree/main
*2024年
**2024-12-28 スクリプト攻撃が行われる
数ヶ月ぶりにスクリプトによる攻撃が行われた。どんぐり大砲の有効化と、書き込み可能レベルを3に上げる対処が行われた。

**2024-12-22 NoobAI-XL 1.0(v-prediction版)が公開される
v-predictionとZero Terminal SNRを使用することで明暗と色の表現が改善したもの。
上記の技術については[[Models>Models]]を参照
- https://civitai.com/models/833294

**2024-12-21 NovelAI Anime Diffusion V4 &#8212; Curated Previewがリリースされる
https://blog.novelai.net/novelai-anime-diffusion-v4-curated-preview%E3%81%AE%E3%81%94%E7%B4%B9%E4%BB%8B-2549111172ae
マルチキャラクタープロンプト、アクションタグ、英語の自然言語理解の向上などが実装された。

**2024-12-09 外部記事による2024画像生成AIまとめ
外部記事 
[[新清士の「メタバース・プレゼンス」 第87回 画像生成AIの進化が早すぎる　2024年に起きたことまとめ>https://ascii.jp/elem/000/004/239/4239726/]]
[[2024年生成AIの進歩まとめ>https://zenn.dev/sakasegawa/articles/eb27e30085174f]]
スレとは関係ないが、2024年の画像生成AIに関する情報がコンパクトにまとめられているので、浦島が読むのにちょうど良い。
編注：ついこのまえ2023年のこの項目を追加したと思ったのに、もう一年経ってる。こわい

**2024-12-06 無断転載された画像を使わず学習されたモデル「Emi 3」が公開される
https://huggingface.co/aipicasso/emi-3
> Emi 3 (Ethereal master of illustration 3) は、 オプトアウト済みモデルStable Diffusion 3.5 Largeをベースに AI Picasso社が開発したAIアートに特化した画像生成AIです。 このモデルの特徴として、Danbooruなどにある無断転載画像を追加に学習していないことがあげられます。

**2024-12-03 Huggingfaceにアップロード容量の制限が設けられる
今まで容量無制限でモデルのアップロードが可能ということで多くのユーザーを集めていたHuggingFaceだったが、ついに容量制限がかけられた。
無課金ユーザーは500GB、課金ユーザーは1TBとのこと。
いつかこうなると身構えていたユーザーもいた一方、TB単位で有益なモデルをアップロードしていた複数のユーザーが上限にヒットするなど混乱も見られた。
(2024-12-11) その後、利用実態（upしたモデルが実際に使われているかなど）に合わせて追加ストレージ枠の付与などが行われつつ、現時点ではprivateリポジトリはfreeで100GB、proで1TB+従量課金、publicリポジトリはほぼ無制限、という形に[[収まった>https://huggingface.co/docs/hub/storage-limits]]
**2024-11-27 ComfyUIのデスクトップ版が一般公開される
クローズドベータテストが行われていたComfyUIのデスクトップアプリ版がベータテストを終え、[[一般公開された>https://blog.comfy.org/open-sourcing-v1-desktop/]]。
ダウンロードは https://github.com/Comfy-Org/desktop から

**2024-11-26 ControlNetと画像編集ソフトを使った透視メガネが流行する
着衣と脱衣の画像を用意して画像編集ソフトに読み込み、クリッピングマスクとメガネの枠を重ねて移動すると透視しているように見える手法が紹介された。
- 発端となった投稿　https://fate.5ch.net/test/read.cgi/liveuranus/1732613695/16
- メイキング解説　https://fate.5ch.net/test/read.cgi/liveuranus/1732613695/662
- ComfyUIのワークフロー　https://fate.5ch.net/test/read.cgi/liveuranus/1732613695/886
- 解説画像の紹介　https://fate.5ch.net/test/read.cgi/liveuranus/1732724442/126

**2024-11-24 最近Huggingfaceで公開されたモデル
https://fate.5ch.net/test/read.cgi/liveuranus/1732449618/116 をもとにしている。
※時限公開のモデルも含む。スレで要望すると再公開されることがある

-11/10 [[paruparu_illustrious>https://huggingface.co/paruparu95483/paruparu_illustrious/tree/main]]（https://fate.5ch.net/test/read.cgi/liveuranus/1731170779/530）
-11/14 [[Illustrious_Models_AsumaXL>https://huggingface.co/Qnuk/Illustrious_Models_AsumaXL/tree/main]]（https://fate.5ch.net/test/read.cgi/liveuranus/1731470180/548）
-11/23 [[NONAMEmix_v1>https://huggingface.co/Emanon14/NONAMEmix_v1]]（https://fate.5ch.net/test/read.cgi/liveuranus/1732317496/558）
-12/_2 [[HarmoniqMix_ePred_v1.x>https://huggingface.co/hybskgks28275/HarmoniqMix_ePred_v1.x]]（https://fate.5ch.net/test/read.cgi/liveuranus/1733042745/261）
-12/_5 [[momizi_Noob>https://huggingface.co/KKTT8823/momizi_Noob/tree/main]]（https://fate.5ch.net/test/read.cgi/liveuranus/1733367072/220）
-12/10 [[HarmoniqMix_vPred_v2.x>https://huggingface.co/hybskgks28275/HarmoniqMix_vPred_v2.x]]（https://fate.5ch.net/test/read.cgi/liveuranus/1733671394/639）
-12/14 [[NONAMEmix-Vpred>https://huggingface.co/Emanon14/NONAMEmix-Vpred]]（https://fate.5ch.net/test/read.cgi/liveuranus/1734063723/583）
**2024-11-16 EasyReforgeが公開される
- https://fate.5ch.net/test/read.cgi/liveuranus/1731593689/687
- https://github.com/Zuntan03/EasyReforge
「NoobAiのEps&V-PredをreForgeで簡単＆高速にお手軽生成する」プログラム。必要なモデルやデータをまとめてダウンロードするほか、便利な機能拡張も自動でインストールされる。

**2024-11-15 スレの勢いが非常に高まる
11月15日頃からスレへの書き込みの量が増えてくる。新しいモデルの公開が相次いだほかV-Pred、[[TIPO>https://github.com/KohakuBlueleaf/z-tipo-extension]]、DMD2、CAMEといった技術の話題、[[EasyReforge>https://github.com/Zuntan03/EasyReforge]]の公開、椅子談義などさまざまなトピックが入り乱れて流れが速くなった。

**2024-11-03 NoobAI 1.0が公開される
- https://civitai.com/models/833294
アーリーアクセス版、0.5、0.75が公開されていたNoobAIの完成版となる1.0が公開された。
今後はv-predictionバージョンや専用ControlNetを開発するとのこと。


** 2024-10-30 Stable Diffusion 3.5 Mediumが公開
リポジトリ: https://huggingface.co/stabilityai/stable-diffusion-3.5-medium
SD3.5のパラメータ数25億のMediumがリリースされた。
Largeと異なりMMDiT-Xアーキテクチャを採用しており、複数の解像度の対応と全体的な一貫性を改善しているとのこと。

** 2024-10-22 Stable Diffusion 3.5 Largeが公開
ブログ: https://ja.stability.ai/blog/introducing-stable-diffusion-3-5
SD3.0のいくつかの問題に対処し、品質が向上したSD3の新バージョン。
現時点でパラメータ数8BのLargeのみ公開。パラメータ数2.5BのMediumは10月29日公開予定。

**2024-10-11 negpipがFLUX.1に対応
ネガティブプロンプトより強力に要素を排除できるWebUI/Forge用拡張機能の「Negpip」がFLUX.1にも対応した。これにより、ネガティブプロンプトを使えないFLUX.1でも実質的にネガティブプロンプトの指定が可能になった。
現在Automatic1111 WebUIはFLUX.1を扱えないため、Forge（v2.0〜）にのみ恩恵がある。

- Negpipiのレポジトリ… https://github.com/hako-mikan/sd-webui-negpip （「拡張機能（Extensions）」タブ−「拡張機能リスト（Available）」タブ−「読込（Load from:）」ボタン−検索欄に「negpip」と入力すると拡張機能一覧が絞り込まれ、「インストール（Install）」ボタンからインストールできる）
- 技術解説…「NegPiPの仕組みとFLUX対応」 https://note.com/hakomikan/n/n19dfd2cfabbc

**2024-10-08 NoobAI-XLのアーリーアクセス版が公開される
- https://civitai.com/models/833294
[[Illustrious>illustrious_xl_01tips]]の派生モデル。キャラクターの表現などが強化されている。

**2024-09-30 Illustrious XL v0.1が正式に公開される
https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0
リークの影響で9月21日ごろからアーリーアクセス版として公開されていた。
SDXLモデルでイラストに非常に強い。
詳細は[[illustrious_xl_01tips]]に。
**2024-09-07 ebara_ponyのリポジトリが消滅
突如としてHugging Faceのアカウントごと消えた。これによりすべてのebara_ponyは入手できなくなった。
数日後にCivitaiで全バージョンが公開されたが、アップしたのが本人なのかは不明。（名前からして転載だとは思うが…）

**2024-08-23 NovelAI Diffusion v1が公開される
[[https://blog.novelai.net/novelai-diffusion-v1-weights-release-jp-01d7fbad6fd7]]
 モデルは、当初のCreativeML Open RAIL-Mライセンスとクリエイティブ・コモンズBY-NC-SA 4.0ライセンスの両方の条件を適用するデュアルライセンスに基づいて公開されます。これにより、上記条件のもとで適切に帰属され配布される限り、非商用目的での利用、再配布、二次的著作物の作成が可能です。

**2024-08-23 ebara_pony_3が公開される
%%tps://huggingface.co/tsukihara/xl_model%% ※リンク切れ
「最近使ってるやつ」「やっぱり眩しい。なんでやろな」「4thtail使ってるんで諸々はそっち見てもろて(https://civitai.com/models/282341/4th-tail-animehentai)」との作者コメント。

**2024-08-14 Grok-2がFLUX.1を採用する
X（旧Twitter）が提供するLLM、Grok-2にFLUX.1による画像生成が搭載された。
どのバージョンなのかは公表されていない。
https://x.ai/blog/grok-2


**2024-08-11 Forgeが大幅に機能強化される

https://github.com/lllyasviel/stable-diffusion-webui-forge

FLUX.1への対応などさまざまな機能が強化された。代わりに動作しなくなった拡張機能もある模様。
FLUX.1のcheckpointは[[flux1-schnell-bnb-nf4.safetensors>https://huggingface.co/silveroxides/flux1-nf4-weights/blob/main/flux1-schnell-bnb-nf4.safetensors]]の使用が推奨されているほか、[[flux1-dev-fp8.safetensors>https://huggingface.co/lllyasviel/flux1_dev/blob/main/flux1-dev-fp8.safetensors]]も使用できる。

**2024-08-01 Black Forest Labsにより画像生成AIモデル「FLUX.1」発表
Stable Diffusionの元開発者が設立したベンチャー企業Black Forest Labsが、画像生成AIモデル「FLUX.1」を発表した。
API経由での有料画像生成に加え、ライセンスにより使用可能範囲が分かれたモデルデータも同日に公開し、Huggingfaceからダウンロードできる。公開日時点ではComfyUIで画像生成が可能。
なお、パラメータ数が12Bもあるため推論には大容量のVRAM(12GB以上?)が必要。
https://blackforestlabs.ai/announcing-black-forest-labs/
https://huggingface.co/black-forest-labs
日本語での記事 https://ascii.jp/elem/000/004/213/4213683/
ComfyUIでの使用法(8/2追記) https://comfyanonymous.github.io/ComfyUI_examples/flux/
Zuntan03(各種easyインストーラの作者)によるインストール用バッチファイル(8/7追記) https://x.com/Zuntan03/status/1820046015023722617
詳細は[[FLUX1tips]]に。

**2024-07-24 Euler SMEAなどいくつかの新サンプラーが話題に挙がる
[[reForge>https://github.com/Panchovix/stable-diffusion-webui-reForge]]や、[[EasySdxlWebUi>https://github.com/Zuntan03/EasySdxlWebUi]]に採用された新サンプラーが話題に挙がっていた。
オリジナルA1111 WebUIやForge(ただしオリジナルA1111では出力結果がReForgeやForgeと変わってしまい綺麗ではない、またEuler SMEAのみADetailerに対応していない)で使用したい場合は、Extensionとして以下のリポジトリからインストールすると使用可能

https://github.com/licyk/advanced_euler_sampler_extension

**2024-07-23 CivitaiがSD3の禁止を解除
Civitaiはライセンスなどの懸念によりSD3のモデルやLoRAの公開を禁止としていたが、解決されたとして禁止を解除した。
だがライセンスを取得しない方針のためCivitai上ではSD3を使用しての生成はできない。
https://civitai.com/articles/6221/sd3-unbanned-community-decision-on-its-future-at-civitai

**2024-07-18 AI Reviewersが流行
https://ai-reviewers.onrender.com/

画像を読み込ませるとAIのキャラクターがその内容を審査し点数をつけてくれる。

**2024-07-09 Paints-UNDO公開
ControlNetやstable-diffusion-webui-forgeの作者lllyasvielにより、Paints-UNDOという完成絵からその画像の描画シーケンスを出力するモデルおよび、シーケンスを動画として保存するコードが公開された。
詳細はリポジトリ参照
https://github.com/lllyasviel/Paints-UNDO

READMEではAnacondaでのインストール方法が記載されているが、WindowsのPython3.10.XのCuda環境下で動かしたい場合の手順は以下の通り(3.11は確認していない、3.12はpytorchの対応状況の問題で十中八九2024/7/10現在は動かない)

インストールしたいディレクトリへ移動し
=|BOX|
git clone https://github.com/lllyasviel/Paints-UNDO.git
cd Paints-UNDO
python -m venv venv
.\venv\scripts\activate
pip install xformers
pip install -r requirements.txt
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu121
python gradio_app.py
||=

２回目以降起動したいときは
=|BOX|
.\venv\scripts\activate
python gradio_app.py
||=

動画を作成すると、最後にffprobeが見つからないというエラーが出るが、resultsディレクトリ内にmp4ファイルが生成されている。

**2024-07-08 PonyでのLoRA学習時スコアタグの使用について
PonyでLoRAを学習する際に、学習画像のタグにスコアタグ(score_9_upなど)を入れることで学習効率を上げる方法が話題に上る。
[[PonyDiffusionV6XLTips>PonyDiffusionV6XLTips#content_8_12]]へいくつかレスを抜粋した。

**2024-07-07 可能な限りA1111の変更点を取り込んだforgeのフォークが公開される
https://github.com/Panchovix/stable-diffusion-webui-reForge
[[I've forked Forge and updated (the most I could) to upstream dev A1111 changes!>https://www.reddit.com/r/StableDiffusion/comments/1dxbadd/ive_forked_forge_and_updated_the_most_i_could_to/]]（フォークしたPanchovix氏による詳細が記載されたredditスレッド）
> Forgeが5ヶ月間アップデートされなかった後、A1111からの重要なアップデートや小さなパフォーマンスアップデートがたくさん欠けていたので、必要であれば、より使いやすく、より時代に合うようにアップデートすべきだと判断しました。（DeepLによる翻訳）
とのことで、DoRAサポートやスケジューラの分離など、forgeの更新が停滞していた時期にA1111に入った大小の変更が適用されている（個人的にはavifのサポートが嬉しい）。ただしSD3対応などは含まれていない。導入方法などの詳細は上記redditを参照すると良いだろう。

**2024-07-06 Stability AIがSD3のライセンスを変更
https://stability.ai/news/license-update
日本語: https://ja.stability.ai/blog/license-update
Stability AIはSD3 Mediumを"Stability AI Community License"という新しいライセンスのもと公開することにした。
 Our new Community License is now free for research, non-commercial, and commercial use. You only need a paid Enterprise license if your yearly revenues exceed USD$1M and you use Stability AI models in commercial products or services. 
年間の収入が100万ドル(日本円で約1.5億円)未満であれば研究、非商用、商用問わず無料で使用できる。

また、SD3 Mediumで見られる特定の条件で人体が破綻する現象を対処するとのこと。

**2024-06-26 Open Model Initiativeが発足
画像・動画・音声生成のためのオープンライセンスAIモデルの開発を推進することを目的にしたプロジェクトであるOpen Model Initiativeが発足した。発足メンバーはInvoke、ComfyOrg、Civitai。LAIONもメンバーだったが参加しないことになった。
続報で新たなメンバーが発表され、その中にはPony Diffusionの開発者であるAstraliteHeart氏もいる。

発表：https://www.reddit.com/r/StableDiffusion/comments/1do5gvz/the_open_model_initiative_invoke_comfy_org/
続報：https://www.reddit.com/r/StableDiffusion/comments/1dp2as9/update_and_faq_on_the_open_model_initiative_your/

**2024-06-20 スレ発の手書きフォントが公開される
購入(500円)：https://tiananmen-square.booth.pm/items/5848321
現在はmegaのダウンロードリンクは削除されておりboothでの有料販売となっています。

https://fate.5ch.net/test/read.cgi/liveuranus/1718722445/774
=|BOX|
774: 警備員[Lv.42] (ﾜｯﾁｮｲ 1acc-Fyfa) sage 2024/06/20(木) 22:40:00.63 ID:1zaStuBA0 
https://mega.nz/file/gJ1DmS5b#s5FpmhxfKujG4ST8hKQ_hN8UTJGJfvuXybWoOXc9ufY

自作の手描き文字フォントを公開するで
インスコしたらフォント名は「そこになければない」で出てくるはずや
自分が使うために制作したフォントやからそう大したモンでもないからそこは堪忍やで
ひらがな、カタカナのみ対応
テンキーに「あ」「は」「ん」のバリエーション
+-*/にハート
小文字英aiueoに濁音つきのアイウエオ
https://i.imgur.com/ajoC51a.jpeg
||=
https://fate.5ch.net/test/read.cgi/liveuranus/1718722445/776
=|BOX|
776: 警備員[Lv.42] (ﾜｯﾁｮｲ 1acc-Fyfa) sage 2024/06/20(木) 22:44:28.07 ID:1zaStuBA0 
>>774
商用利用OKやから基本好きに使ってくれてええで。
フォント自体の再配布や販売のみ禁止でたのむで
このフォントが売りに出されるときはワイが売るときだけや
||=
https://fate.5ch.net/test/read.cgi/liveuranus/1718944727/158
=|BOX|
158: 警備員[Lv.43] (ﾜｯﾁｮｲ 1a56-Fyfa) sage 2024/06/21(金) 22:07:34.16 ID:iyTJupHe0 
https://i.imgur.com/iSzRGU4.jpeg

https://tiananmen-square.booth.pm/items/5848321

自作手描きフォント、
伸ばし棒とかハートマークとか縦書きで横になる文字をちょっと調整したから
改めておいておくで。

しばらくしたら有料にするかもしれんでそれより前にダウンロードしておいてな
||=

**2024-06-19 ComfyUI、独立した団体を設立すると宣言
当該ポスト：https://x.com/ComfyUI/status/1803109283263029616
公式サイト：https://www.comfy.org/

ComfyUIの作者であるcomfyanonymous氏はStabilityAIを退社、SwarmUIの作者のmcmonkey4eva氏などとともに「Comfy Org」を設立した。オープンソースのAIツールを発展させ民主化することを目標としている。
**2024-06-18 CivitaiでSD3モデルおよび派生データの公開が一時停止
SD3に関するライセンス(特に商用ライセンスの範囲)が不明瞭なことから、将来的なモデルの保全やライセンス料請求の有無などの安全を確認できるまで、
CivitaiでSD3に関するモデル及び派生データ(LoraやControlNetなどのSD3をベースにした学習結果も含む)の公開が一時的に停止された。
https://civitai.com/articles/5732
もしすでにSD3に関する学習を計画している人は、本項目記載時点においてCivitaiで公開できないので要注意

**2024-06-13 Ponyは7の前に6.9を作ることに
SD3をベースにPony Diffusion V7を作る予定だったが、
SD3の商用ライセンスが曖昧なことなどを理由に、SDXLがベースのV6.9を作ると発表した。
詳しくは　https://civitai.com/articles/5671/towards-pony-diffusion-v7-i-mean-v69
//6月13日時点の状況を説明したものであることに注意。

//Pony Diffusionの作者は情勢を考慮して、予定していたSD3での学習を取りやめ、改めてXLでの新バージョンを作ることを発表した。
//https://civitai.com/articles/5671/towards-pony-diffusion-v7-i-mean-v69

//%%これを機に、PixArt SigmaやLumina-T2Xなど他の画像AIモデルを活用する提案もなされている模様。%%
//%%-PixArt Sigma%%
//%%https://github.com/PixArt-alpha/PixArt-sigma%%
//%%-Lumina-T2X%%
//%%https://github.com/Alpha-VLLM/Lumina-T2X%%
//
**2024-06-12 Stable Diffusion 3が一般公開
リポジトリ: https://huggingface.co/stabilityai/stable-diffusion-3-medium
ブログ: https://ja.stability.ai/blog/stable-diffusion-3-medium
デモページ：https://huggingface.co/spaces/stabilityai/stable-diffusion-3-medium
StabilityAIが開発するStable Diffusionの最新版が公開された。今回公開されたのはパラメータ数20億のMedium。
従来のSDより破綻が減少し、プロンプトへの忠実度が改善した。また文字を正しく生成できるようになった。
現在対応しているWebUIはComfyUIと1111のwebui。またモデルのダウンロードにはHuggingfaceのユーザー登録が必要。

//性能について書かれていたがお気持ちだったので削除

-''現時点での最も簡単なローカル導入方法''
ディレクトリからsd3_medium_incl_clips_t5xxlfp8.safetensors（VRAM8GBモデル）をダウンロードし、ComfyUIのcheckpointに入れる。
「comfy_example_workflows」からサンプルワークフローの「sd3_medium_example_workflow_basic.json」をダウンロードし、ComfyUIで読み込む。
ワークフローの「TripleClipLoader」の接続を外し、「LoadCheckpoint」（モデル選択欄）から直接「ClipTextEncode」（プロンプト入力欄）にClipの出力を繋ぎなおす。
**2024-06-10 ComfyUIのカスタムノード「Comfy_LLMVISION」にキーロガーが仕込まれていたとの報告

詳細は[[画像生成ソフトウェア「ComfyUI」のノードにキーロガーが仕込まれていたことが発覚、クレジットカード情報やパスワードなど全ての入力が筒抜けに - GIGAZINE>https://gigazine.net/news/20240611-comfyui-llmvision-malware/]]などを参照のこと。

**2024-06-09 Forgeが実験的リポジトリに変更されるとのアナウンス

https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/801

（以下は機械翻訳、強調は引用者による）

====
フォージユーザーの皆さん、

[[今日、アップストリーム sd-webui>https://github.com/AUTOMATIC1111/stable-diffusion-webui]]の開発ブランチでは、パフォーマンスに関する多くの進捗が更新されました。以前のボトルネックの多くは解決されるはずです。[[ここ>https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/166]]で説明したように、大多数のユーザーにはアップストリーム webui に戻すことをお勧めします (webui の開発ブランチを直接使用するか、開発ブランチがメインにマージされるまで待機します)。

同時に、Forge の多くの機能 (unet-patcher や最新のメモリ管理など) は、現在の WebUI のエコシステムに実装するにはコストがかかりすぎると考えられています。

その後、Forge は、主に統合コストのかかる機能をテストするための実験的なリポジトリになります。Gradio 4 で実験し、LRU プロセス スケジューリングと pickle ベースのプロセス通信に基づく huggingface space のゼロ GPU メモリ管理のローカル GPU バージョンの実装を、次のバージョンの Forge に追加します。これにより、Forge に「Forge Space」(Gradio 4 SDK @spaces.GPU 名前空間に基づく) という新しいタブと、「LLM」という別のタブが追加されます。

''これらのアップデートにより、ほぼすべての拡張機能が壊れる可能性があるため、実稼働環境のすべてのユーザーには、日常使用ではアップストリームの WebUI に戻すことをお勧めします。''

gradio の LLM インターフェイスとストリーミング システム、イメージ エディターとディスプレイにおける最近の進歩、および Gradio SDK のゼロ GPU 計算管理システムのシームレスな統合に関して、アップストリームの検討や適応には Gradio 4 のフィードバックと拡張も必要であるため、少数のユーザーをここに残して Gradio 4 をテストするよう招待します。

最後に、''Forge ユーザーに今すぐファイルのバックアップを取ることを推奨します'' (または、可能であればアップストリームの WebUI に戻すだけです)。このアナウンスに気付かずに誤って Forge を更新した場合、このアナウンス前の最後のコミットは[[29be1da>https://github.com/lllyasviel/stable-diffusion-webui-forge/commit/29be1da7cf2b5dccfc70fbdd33eb35c56a31ffb7]]です。
====

**2024-06-06 シード値の固定とHires.fixやAdetailerのオンを連動させる拡張機能が公開される
https://github.com/Takenoko3333/sd-webui-reuse-seed-plus

開発のいきさつは以下。

[[なんJNVA部★402/260>https://fate.5ch.net/test/read.cgi/liveuranus/1717517250/260]]
=|BOX|
260 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ 6938-l7CW)[sage] 投稿日：2024/06/05(水) 18:28:30.55 ID:4POD0XU60
SDのWebUIでプロンプトいじりながら適当に出力して
良いSEED見つけたら固定してhires.FixとAdetailerのチェック入れてるんやが
毎回外したり付けたりSEED固定したりランダムにするのが面倒なんやが
ボタン一発でやる方法とかない？
||=

[[なんJNVA部★402/631>https://fate.5ch.net/test/read.cgi/liveuranus/1717517250/631]]
=|BOX|
631 名前： 警備員[Lv.30] (ﾜｯﾁｮｲ 4ac3-M/1B)[sage] 投稿日：2024/06/06(木) 15:44:42.87 ID:UNK+HALX0
>>382
できたで
https://github.com/Takenoko3333/sd-webui-reuse-seed-plus
ワンボタンでやりたかったけどHires.fixの挙動が複雑だったから
連動をチェックボタンで切り替える方式にした
詳しくはgithubの説明を読んでくれ
連動の組み合わせは多岐に渡るしワンボタン化等追々改修していく予定
リクエストがあればどうぞ
||=

続いて、[[生成ボタンを分割して&#127922;、&#9851;、+1ボタンを追加するJavaScript>https://seesaawiki.jp/nai_ch/d/%b5%a1%c7%bd%a4%c4%a4%ad%a4%ce%c0%b8%c0%ae%a5%dc%a5%bf%a5%f3%a4%f2%c4%c9%b2%c3%a4%b9%a4%eb%ca%fd%cb%a1]]を機能拡張化するリクエストが出された。

[[なんJNVA部★403/177>https://fate.5ch.net/test/read.cgi/liveuranus/1717745571/177]]
=|BOX|
177 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ 86a4-6Hk5)[] 投稿日：2024/06/07(金) 22:16:52.73 ID:vd08XaSL0
>>146
その勢いでこれも拡張機能にしてほしい
https://seesaawiki.jp/nai_ch/d/%b5%a1%c7%bd%a4%c4%a4%ad%a4%ce%c0%b8%c0%ae%a5%dc%a5%bf%a5%f3%a4%f2%c4%c9%b2%c3%a4%b9%a4%eb%ca%fd%cb%a1
ビッグウェーブが来ているわけじゃ全然ないけど
||=

[[なんJNVA部★403/523>https://fate.5ch.net/test/read.cgi/liveuranus/1717745571/523]]
=|BOX|
523 名前： 警備員[Lv.32] (ﾜｯﾁｮｲ 4ac3-M/1B)[sage] 投稿日：2024/06/08(土) 22:47:02.79 ID:t6FS3GUu0
sd-webui-reuse-seed-plus に機能を追加しました！（v0.2.0）
https://github.com/Takenoko3333/sd-webui-reuse-seed-plus
txt2img, img2img の画面に三つの機能付き生成ボタンを追加します。
Hires.fix のオン/オフに連動して他の機能のオン/オフを切り替えます。
https://files.catbox.moe/13c29a.png https://files.catbox.moe/pnm6wi.png

生成ボタンについて
リクエストに応じて過去スレで紹介されていたブックマークレットを改修して機能拡張に組み込みました。
||=
https://files.catbox.moe/13c29a.png https://files.catbox.moe/pnm6wi.png
**2024-06-05 謎漫画が流行する
Animagine3.1に現場猫LoRAを組み合わせ、コマ割りされたマンガのような画像を出力するのが流行。「謎漫画」と呼ばれた。
-現場猫LoRA https://civitai.com/models/350606/shigotonekogenbaneko-style-sdxl-or
--Pony用 https://civitai.com/models/502133/shigotonekogenbaneko-style-ponyor

[[なんJNVA部★402/252>https://fate.5ch.net/test/read.cgi/liveuranus/1717517250/252]]
====
252 名前： 警備員[Lv.34] (ﾜｯﾁｮｲ beee-WQ8n)[] 投稿日：2024/06/05(水) 17:54:13.15 ID:xEbGq8Wl0
謎まんが
&ref(https://files.catbox.moe/y8kymd.png,350) &ref(https://files.catbox.moe/7o22ay.png,350)

　>>115
そやでー、猫loraのウェイト上げると猫寄り、下げるとキャラ寄り
プロンプト入ってるからよかったら好きなキャラでどうぞやで
ワイこの2日、AIの狂気ネタにSAN値削られてゼロなんで
もうロリ幼女作成に戻るわ・・・
====

補助スクリプトや作り方など詳しい情報は[[謎漫画>nazomanga]]を参照のこと。
**2024-06-03 SD3のリリース日発表
%%https://x.com/StabilityAI/status/1797462536117444794%%
%%Stable Diffusion 3の一般公開が6月12日（米国時間）になることが発表された。%%
%%まずはパラメータ数が少ない軽量モデルをリリースし、次いで重量モデルもリリースしていく予定だという。%%
6/13追記：日本時間の6月12日午後10時ごろに一般公開された。

%%https://civitai.com/articles/5069%%
%%Pony Diffusionも次期バージョンのSD3ベースでの学習に向けて準備を進めているという。%%
6/13追記：ライセンスに不明な点が多いためSD3での学習は当分見送るらしい。
**2024-05-31 Omostが公開される

ControlNetやFooocus、Forgeの開発で知られるlllyasviel氏が対話型AIを用いて画像を生成する「Omost」を公開した。

https://github.com/lllyasviel/Omost

PCにインストールしなくても、huggingface上のデモページで試すこともできる。

https://huggingface.co/spaces/lllyasviel/Omost

**2024-05-31 画像からプロンプトを推測するツールなどが公開される

なんJNVA部★400 
https://fate.5ch.net/test/read.cgi/liveuranus/1716953974/544

-手持ちの画像からプロンプトを推測するツール https://huggingface.co/spaces/John6666/wd-tagger-transformers
-上のに加えてエロプロンプトを生成するツール https://huggingface.co/spaces/John6666/danbooru-tags-transformer-v2-with-wd-tagger
-普通のDanbooruタグをポニー用のe621タグに変換するツール https://huggingface.co/spaces/John6666/danbooru-to-e621

いずれもインストールは必要なく、huggingfaceのスペース上で利用できる。

「[[適当にパクって改造したもんなんで誰でも好きに適当にパクって改造したってやー>https://fate.5ch.net/test/read.cgi/liveuranus/1716953974/551]]」とのこと。

**2024-05-19 3x3x3mixXLが公開される
https://civitai.com/models/464044

Pony系列のモデルが弱いとされる背景の描き込みが強化されているのが特徴。

https://fate.5ch.net/test/read.cgi/liveuranus/1716088224/204

=|BOX|
3x3x3mixXL作成してみたンゴ
typeA~C混ぜてみたんやが正直色んな要素が薄まってごちゃまぜになっとるから却って使いにくいかもしれん…
あとマージを繰り返した代償か全身入る構図だと顔が崩れやすいのでADtailerでつかったほうがいいかもやで！
||=

**2024-05-12 ebara_pony_2が公開される
https://huggingface.co/tsukihara/xl_model

https://fate.5ch.net/test/read.cgi/liveuranus/1715346628/625

=|BOX|
625: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 6106-txKt) sage 2024/05/12(日) 17:25:40.46 ID:jCfcGQrA0 
https://files.catbox.moe/mil0up.jpgし
https://huggingface.co/tsukihara/xl_model
タレ目抑えたモデルわよ
ちょっとロリすぎるかもしれんけどまあええかで公開わよ
||=

変更点については「まぁ強いて言うなら構図…？わからんワイは雰囲気でマージしとる」「1.5のときみたいに「バージョンアップ！」って訳じゃなくて単に絵柄が違うって感じ」とも。（ https://fate.5ch.net/test/read.cgi/liveuranus/1715346628/642 ）

翌日2.1が公開された。「肌が流石に眩しすぎたので若干オリジナルponyに近くした。自分らで好きに調整してくんろ」とのこと。
**2024-05-08 URLを含む書き込みで「もう余所でやってください。」と言われるケースが続出

=||
一定の長さ以上の文章
URL
||=
だと「もう余所でやってください。」になり、
=||
URL
文章
||=
ならば書き込めるとの報告が相次いだ。

**2024-05-08 ic-lightが公開される

ControlNetやFooocus、Forgeの開発で知られるlllyasviel氏が画像のライティングを変更する[[ic-light>https://github.com/lllyasviel/IC-Light]]を公開した。

**2024-04-27 cnlllite-anystyleが流行する
4/22に公開された、画像の構図を維持したまま衣装やキャラなど他の要素を変更できるControlnetモデル、cnlllite-anystyleが流行した。
詳しくは[[ControlNet>ControlNet]]をご覧ください

**2024-04-23 Hyper-SD公開
https://hyper-sd.github.io/
LCMやSDXL-Lightningのような低STEPで生成を完了する技術に、新たな手法としてHyper-SDが公開された
上述の既存手法よりも生成物の精度が良いとされ、実際にスレ★386でも使用された画像が貼られているので参考にすると良い
https://fate.5ch.net/test/read.cgi/liveuranus/1713700458/

導入方法は、公式サイトからリンクされているHuggingFaceでLoRAとしてダウンロードできる
SD1.5用とSDXL用があるので、用途に合わせてダウンロードする
使用時は、LCM LoRAと同じようにプロンプト内で呼び出せば良い

設定例 Hyper-SDXL-8steps-lora.safetensorsの場合
ステップ:8　サンプリング:Euler a  SGM Uniform(Uniformでもいける)　CFG:Animagine系は1〜2、Pony系は3〜3.5くらい

※注意 SDXL用のsafetensorが誤ってSD1.5用として内部に記載されているため、WebUIデフォルト設定でSDXLモデルを読み込んでいるとLoRAリストに表示されない
　設定からExtra Networks(追加のネットワーク)ページにあるAlways show all networks on the Lora page(otherwise, those detected as for incompatible version of Stable Diffusion will be hidden)にチェックを入れると表示されるので、LoRAのスパナアイコンから設定をSDXLに変更すると良い

***2024/5/1追記 CFGスケール5〜8に対応したモデル公開
4/30に、CFGスケール5〜8に対応したモデルが公開された。これを使用すると、HyperSD使用時と不使用時でCFGスケールを調整する必要が無くなる。

**2024-04-18 Stable Diffusion 3のAPIが公開される
https://ja.stability.ai/blog/stable-diffusion-3-api
現時点では有料。
早速課金して試した人もいるが「あまりクオリティの向上は感じられない」とのこと。
ただし公開されたのは開発途上のモデルとの情報もあり、現時点でSD3の実力の明確な評価を下せる段階にはない。

**2024-04-16 Adobe Premiere ProへのSoraの実装が発表
https://news.adobe.com/news/news-details/2024/Adobe-previews-breakthrough-AI-innovations-to-advance-professional-video-workflows-within-Adobe-Premiere-Pro/
https://gigazine.net/news/20240416-adobe-premiere-pro-with-ai-firefly/
動画編集ソフト「Adobe Premiere Pro」に、「Sora」をはじめとする複数の動画生成AIモデルが2024年後半をめどに実装予定であることが発表された。
今後ますます一般人も高性能な動画AIを使えるようになっていくことが期待される。

**2024-04-12 なんJNVA部★382 どんぐりシステム有効化される
かねてよりスクリプト荒らしに見舞われていた5chで、その対策として開発されたどんぐりシステムが、本スレ382で強制有効化された。
ただし、これにより未対応ブラウザ民がスレに書き込めなくなる問題が発生するため、今後も有効化を続けるかどうかは議論が必要である。
どのくらい書き込めないユーザーがいるか把握のためにも、該当者はテンプレの避難所に報告してほしい。

**2024-03-23 Stability AIの主要メンバーが退社
https://stability.ai/news/stabilityai-announcement
CEOのEmad Mostaque氏をはじめとする従来のStability AIの開発メンバーの大部分が退社していることが明らかになった。
%%これによりSDのサポート体制やSD3のリリースに影響が生じるかどうかは現時点では不明。%%
SD3がオープンソースでリリースされることは確定している模様。
**2024-03-18 Animagine XL 3.1がリリース
https://huggingface.co/cagliostrolab/animagine-xl-3.1
https://cagliostrolab.net/posts/animagine-xl-v31-release
Linaqurf氏らがAnimagine XL 3.0の後継の「Animagine XL 3.1」を公開した。
3.0で出なかった多くのアニメキャラが出せるようになった。
Quality tagsの仕様が変更されたことに注意。Aesthetic Tagsも追加された。
-参考：[[animagine31tips]]
**2024-03-14 釈迦に説法構文

初出は以下のスレ

なんJNVA部★361
https://fate.5ch.net/test/read.cgi/liveuranus/1710310864/

581: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 12e8-xhpr) sage 2024/03/14(木) 09:20:02.25 ''&color(#ff0000){ID:QawQpn3/0}'' 
RTX 2000 Adaが販売されるらしいけどこのスレ的にはどうなんや
こいつもPCIe4x8らしいからRTX4060 16GBのちょっと上っていう感じ？

582: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 7e66-UCxz) sage 2024/03/14(木) 09:26:02.88 ID:Uav7afoj0 
＞＞581
最大消費電力が70WだからガチでAI以外での用途は絶望的だし恐らくパフォーマンスがいいわけでもない
24時間生成し続けるけど電気代が気になるって人じゃなきゃ価値無いんやないか

584: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 12e8-xhpr) sage 2024/03/14(木) 09:29:29.97 ''&color(#ff0000){ID:QawQpn3/0}''
＞＞582
見解サンガツや
つうことは学習ずっと回したい人とか二枚目三枚目を安く積み重ねたい人むけやろかこれ

587: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 2e3e-gl2Z) sage 2024/03/14(木) 09:40:29.78 ID:MzzNXCG/0 
＞＞584
ttps://i.imgur.com/O14NCsP.jpeg
端子構成がこんな感じなあたり、3~4枚の複数モニター環境構築したい人向けというか、それ以外の一般ユーザーにはただただ使いにくいグラボでしかないと思う

591: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 12e8-xhpr) sage 2024/03/14(木) 10:11:45.54 ''&color(#ff0000){ID:QawQpn3/0}''
＞＞587
&size(18){''んなことはわかってる釈迦に説法や''}
Kohakuニキなんかも3090を4積みとかやってるから、学習にマルチGPUって意味あるんかなと思って
推論の場合は別々のインスタンスになってしまうからあまり意味ないのはわかってんやけど

592: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ a2bb-On+R) sage 2024/03/14(木) 10:12:33.69 ID:jyi7Ntuv0 
＞＞591
お前が釈迦だったのか…

594: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 7ef3-OcrC) sage 2024/03/14(木) 10:14:22.42 ID:FJxL1hfC0 
釈迦に説法を自分側に使う人初めて見たわ


[[釈迦に説法とは>https://dictionary.goo.ne.jp/word/%E9%87%88%E8%BF%A6%E3%81%AB%E8%AA%AC%E6%B3%95/]]
質問の回答を貰っておきながら自分の事を釈迦と称し相手を窘める姿にスレ民の腹筋が悟りを開き、スレは一躍釈迦ブームとなった。
&size(9){ミームとして面白いのは確かだが、元ネタを知らないとただただ失礼なだけである。用法用量には注意しよう}

**2024-03-13 Animagineでも埋め込みタグらしき挙動が判明
Animagineでも、Ponyと同様にランダムな英数字3文字を入れることでスタイルが変化することが判明した。
そもそもXLの標準モデルに備わっている仕様に影響を受けた挙動なのではないかという推測もなされた。

**2024-03-12 本スレに激しいスクリプト爆撃
本スレ(というかなんU)に勢い順で埋め立てるスクリプトが発生し機能不全に陥っている。
以下の避難所に避難しよう。
メイン避難所: https://bbs.3chan.cc/test/read.cgi/liveuranus/1695016803/
サブ避難所: http://bbs.jpnkn.com/test/read.cgi/JNVA/1696574746/

**2024-03-12 Ponyに埋め込まれたタグの研究が盛んに
PonyDiffusionV6XLには、イラストレーターなどのタグが英数字3文字でひそかに埋め込まれていることが判明。なんJNVA部★356 https://fate.5ch.net/test/read.cgi/liveuranus/1710169059/ の中盤からこの話題が急激に増えスレが加速した。スレ終盤にはスクリプト荒らしが来襲しカオスに。
- 参考：[[PonyDiffusionV6XLTips]]
**2024-03-01 sd-forge-layerdiffusionが公開される
LayerDiffusionはControlNetを開発したメンバーが発表したもので、画像生成モデルが透過画像を生成できるようにしたものらしい。
- [[Layer Diffusionについて簡単に解説したツイート>https://twitter.com/sayhi2ai_jp/status/1763032942086099058]]
- [[Layer Diffusionの論文>https://arxiv.org/abs/2402.17113]]
このLayerDiffusionが使える環境がforge向けに公開された（[[sd-forge-layerdiffusion>https://github.com/layerdiffusion/sd-forge-layerdiffusion ]]）
スレ民が使った感想としては以下がよくまとまっているので引用する。
=|BOX|
0027 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ de28-9+AH)
2024/03/02(土) 18:57:42.58ID:g50+9iiw0
まだ試していない奴向けに

・Layer Diffusionは現状ゲームやまんがや雑コラの素材作り向け
・前景とか背景から生成させるのは言うほど解釈力高くない
　どういうのが合うのかとか考えず単純に雑コラしがち
・生成させる場所の指定とかできないので元々あったものを
　完全に隠す感じで生成しがち
・i2iはあと1週間くらいで来るらしい
||=
大きく環境が変化するまで時間はまだ掛かりそうだが、今後に期待したい。
**2024-02-23 sd-danbooru-tags-upsamplerが公開
https://github.com/p1atdev/sd-danbooru-tags-upsampler
LECOの作者であるp1atdev氏が入力されたプロンプトに続くdanbooruタグをLLMが生成するExtensionを公開した。
AIがいい感じにプロンプトを生成してくれるので、プロンプトが思いつかない時やガチャをしたいときに便利。

**2024-02-22 Stable Diffusion 3発表
https://stability.ai/news/stable-diffusion-3
日本語の記事: https://ja.stability.ai/blog/stable-diffusion-3
Stability AIにより、Stable Diffusionの次世代モデル「Stable Diffusion 3」が発表された。
従来のモデルよりもプロンプトの読解力や表現力が大幅に向上し、テキストも正確に出力できるとのこと。
OpenAIの「Sora」と同様の新たな拡散トランスフォーマー技術が使用されているという。
現時点では一般公開されておらず、今後の公開予定や要求スペックなどは不明。
%%Stable Cascadeとは何だったのか%%

**2024-02-22 NovelAIにバイブストランスファー機能が実装される

https://twitter.com/novelaiofficial/status/1760394681274245241

元絵の要素を持つ別の絵を出力する機能。精度の高さにスレが盛り上がる。
**2024-02-20 ComfyUIがStable Cascadeに対応
https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/
ComfyUIがStable Cascadeに対応したことが発表された。
CascadeのモデルをCheckpointフォルダに入れるだけで動作するとのこと。
本スレではVRAM8GBでも動作したことが報告されている。

**2024-02-17 pixivでのAI画像BAN報告相次ぐ
pixivにR18のAI画像を上げたところBANされたことが本スレで相次いで報告される。
利用規約で禁止されている実写ポルノ、他者の偽装、他サイトなどの誘導に引っかかっていると推測されているが詳細は不明。
%%今後はpixivにAI画像を上げるのは避けた方が良いだろう。%%
手描き絵師のBAN報告も多数あるため、最早pixiv運営にしか本当のところはわからない。

**2024-02-16 動画生成AI「Sora」発表
https://openai.com/sora
OpenAIにより動画生成AI「Sora」が発表された。
プロンプトから最長1分間の高解像度動画を生成可能であり、複雑なプロンプトにも対応する。
疑似的な物理シミュレーションが行われているとのことで、従来の生成AIから飛躍的に性能が向上したリアルな映像が話題となった。
なお現時点ではあくまでも技術発表でありモデルの一般公開は行われない。

**2024-02-13 Stable Cascade公開
https://ja.stability.ai/blog/stable-cascade
https://github.com/Stability-AI/StableCascade
Stability AIにより、新たな画像生成モデル「Stable Cascade」が公開された。
SDXLよりも短時間での生成が可能であり、さらにプロンプトの忠実度や画像の美学的品質も向上しているという。
ローカルで動かすにはデフォルトで20GBのVRAMを必要とするが、コードを改変することでより少ないVRAMで動作したとの報告もある。
https://note.com/hakomikan/n/n75f0ee78abf9

**2024-02-12 ZLUDAがリリース
RadeonでCUDAを動かせるようにするラッパーソフトウェアZLUDAがGitHubで突如リリースされた。
https://github.com/vosen/ZLUDA/
元々はAMDで開発していたがこれが流行ると益々CUDAでええやんとなってしまうためプロジェクトが没になり作者が公開するに至った（AMDは2023年10月にnod.ai SHARKを買収している）。
性能としては[[GeekbenchをOpenCL版で動かすよりもほとんど性能が上がる（最大75.34％アップ）>https://github.com/vosen/ZLUDA/raw/master/geekbench.svg]]など、ただ単にソフト互換性があるだけではなく、パフォーマンスメリットまである事が判明した。

2024年6月1日現在、[[Stable Diffusion WebUI AMDGPU（旧Stable Diffusion WebUI DirectML）>https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu]]の--use-zludaオプションや、[[ComfyUIのZLUDAフォーク版>https://github.com/patientx/ComfyUI-Zluda]]を使う事でRadeonでもStable Diffusion系を高速に扱う事が出来るようになっている。

**2024-02-06 stable-diffusion-webui-forgeリリース
ControlNetの作者lllyasvielによる、WebUIのリファクタリング版がリリースされた
https://github.com/lllyasviel/stable-diffusion-webui-forge
低VRAM環境での高速化や使用メモリ削減が見込めるものの、一部Extensionがまだ動かないらしいので上記Githubを要参照

Githubより
 オリジナルのWebUI（1024pxでのSDXL推論）と比較すると、以下のようなスピードアップが期待できます：
-8GB vramのような一般的なGPUを使用する場合、推論速度（it/s）が約30〜45%向上し、GPUメモリピーク（タスクマネージャ）が約700MBから1.3GBに減少し、最大拡散解像度（OOM：VRAM不足…Out Of Memoryしない）が約2倍から3倍に増加し、最大拡散バッチサイズ（OOMしない）が約4倍から6倍に増加します。
-6GB vramのような強力でないGPUを使用する場合、推論速度(it/s)は約60〜75%向上し、GPUメモリピーク(タスクマネージャ)は約800MBから1.5GBに減少し、最大拡散解像度(OOMしない)は約3倍、最大拡散バッチサイズ(OOMしない)は約4倍に増加します。
-24GBのvramを持つ4090のような強力なGPUを使用する場合、推論速度（it/s）が約3〜6%高速化し、GPUメモリピーク（タスクマネージャ）が約1GBから1.4GBに低下し、最大拡散解像度（OOMしない）が約1.6倍になり、最大拡散バッチサイズ（OOMしない）が約2倍になります。
-SDXLにControlNetを使用する場合、ControlNetの最大カウント数（OOMしない）は約2倍になり、SDXL+ControlNetの速度は約30〜45%速くなります。


NVAスレのみなさまの喜びの声
=|BOX|
なんJNVA部★328
 https://fate.5ch.net/test/read.cgi/liveuranus/1707027741/994
 994: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ b73c-jSnV) sage 2024/02/06(火) 13:01:10.84 ID:73PRlTFt0 
 A1111の方は最新やなく1.6.0やがForgeと比較したで
 環境は5900X, RTS4070tis (PL70%)
 魔人の1024x1024 step30を2倍にhiresした結果や
 A1111：https://litter.catbox.moe/xmggsd.png
 Forge：https://litter.catbox.moe/sozkxc.png
 
 使用メモリ量が4GB以上削減されとる上に速度も30秒以上改善されとる
 hiresも速くてこれはすごいわ
 動かん拡張があるらしいのがネックやが、正直適当にポン出しするならComfyUIよりこっちの方がええな
 https://litter.catbox.moe/nt6n0p.jpg

なんJNVA部★329 
 116: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ d7d4-KLri) sage 2024/02/06(火) 15:08:10.66 ID:+EIplyW30 
 4080 VRAM16GBでforgeお試し
 SDXL 1024*1536からの2倍hiresで2048x3072行けて感動した.
 ただhiresなしだとそこまで体感変わらないのと、hiresありでも12GBくらいしかVRAM使ってないのでそこは勿体ないかな. たぶん12GB勢でも2倍行ける
 lora-block-weightはエラー出ないけど効いてないみたいだわ

 132: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 9f2c-by7P) sage 2024/02/06(火) 15:29:23.02 ID:4ViKf5KT0 
 3060ti8Gでも832*1216のhires*2が2分でいけるね
 革命ですわ
||=

**2024-01-19 Pony Diffusion V6 XLが話題になる
https://civitai.com/models/257749/pony-diffusion-v6-xl
スレがAnimagine XL 3.0の話題で持ちきりになる中、数日前にCivitaiにアップロードされていたモデル。
かなり独特なクオリティタグとnegative promptの使用が必要で、上手くチューニングしないとバタ臭い絵が生成されるが、
ハマった場合の質の高さにスレは盛り上がった。特にNSFWが優秀。
loraの学習モデルとしても優秀で、Animagineよりも特殊性癖への理解が強い(小並)
クオリティタグ、negative promptはスレで共有された一例を以下に記すが、civitaiのサンプル等から各々探ってほしい。
そして良いものがあればスレで共有してほしい。

クオリティタグ一例
=|BOX|
0229今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ a7b0-OBZN)
2024/01/26(金) 11:50:33.13ID:HD6WR8TC0
ponyちゃん先頭にこれいれとけばええやろ感がすごい
score_9, score_8_up, score_7_up, BREAK source_anime, rating_explicit, best quality, masterpiece, uncensored, 1girl,
||=

negative prompt一例(姫騎士ニキ)

=|BOX|
0077今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ 5f14-zQB7)
2024/01/25(木) 22:47:04.32ID:qJvUoh9O0
>>75
キャラ設定用の奴を抜くと↓やね
Ponyは背景弱いしdepth of fieldとかのネガは抜いて背景ボヤかせたほうがええかもなぁという気もしているわ
censored, mosaic censoring, bar censor ,border, worst quality, low quality, simple background, white background, realistic, sketch ,muscle , normal quality, jpeg artifacts, depth of field, blurry, messy drawing, amateur drawing, lowres, bad anatomy, bad hands, text, error, missing fingers, fewer digits, extra digits,cropped , greyscale, monochrome, source_furry, source_pony, source_cartoon, comic ,source filmmaker,video ,3d
||=

参照：[[PonyDiffusionV6XLTips]]


**2024-01-11 Animagine XL 3.0が公開
https://huggingface.co/cagliostrolab/animagine-xl-3.0
https://cagliostrolab.net/posts/animagine-xl-v3-release/
Linaqurf氏らがSDXLベースのアニメモデル「Animagine XL 3.0」を公開した。
NovelAI V3に迫る性能を誇り、Quality TagsなどもありNAI3に近い感覚で使用できるかも。
これでも[[sd-scriptsの勾配が同期されない不具合で学習がうまくできてない可能性があり>https://cagliostrolab.net/posts/animagine-xl-v3-release#uncontrollable]]、今後の更なる進化に期待できる。

参照：[[AnimagineXL3.0tips]]






































