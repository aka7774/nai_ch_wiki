&ref(https://image01.seesaawiki.jp/n/h/nai_ch/PE97wdqgIk.png,800)
&size(12){浦島イラスト｜参考プロンプト：https://majinai.art/ja/i/LmVqyND}

* はじめに
新技術とか流行りとか歴史とかをメモしておくページ
具体的なノウハウとかは専用ページに書いて、ここは紹介程度に。
上の奴ほど新しいという感じで編集していってください。

[+]編集にあたってのお約束
- 嘘松はあかん
事実だけを掲載する。うわさなら裏をとってからや
- ポジティブな話題をメインに
革新的な技術やスレで話題になったおもしろい出来事などを優先して掲載する
技術的なことならネガティブな話題でもOK
例：「●●が使えなくなった」とか「●●が実は壊れていた」等
- お気持ち表明にならないようにする
ある程度自由な作風がゆるされてるけど個人のお気持ちが混ざってないか推敲してから編集しよう

※改定の提案はこちら：[[運用方針など>https://seesaawiki.jp/nai_ch/bbs/39146/l50]]
[END]

2023年以前の出来事は[[こちら>https://seesaawiki.jp/nai_ch/d/%b8%c5%bb%f6%b5%ad]]
* とりあえず最新の環境を教えてクレメンス
2025年3月9日更新
「そんな性癖で大丈夫か？」

**「大丈夫だ、問題ない」
WebUI:[[reForge>https://github.com/Panchovix/stable-diffusion-webui-reForge]]
[[EasyReforge>https://github.com/Zuntan03/EasyReforge]]を使ってワンクリックでインストールできる。日本語で丁寧に解説されているのでわかりやすい。
RTX5000シリーズはCUDAの対応バージョンが12.8以降のみで、PyTorchが非対応だった。のちにPyTorchのnightly buildにCUDA12.8対応版がリリースされ、いわゆるWebUI（AUTOMATIC1111及びその派生であるForge、Reforge）でもローカル画像生成環境の構築が可能になった（EasyReforgeは5000シリーズでも自動的に最適なPyTorchをインストールしてくれる）

Model:[[NoobAI-XL (NAI-XL)>https://civitai.com/models/833294/noobai-xl-nai-xl]]

**「一番いいのを頼む」
WebUI:[[ComfyUI>https://github.com/comfyanonymous/ComfyUI]]
[[Stability Matrix>https://github.com/LykosAI/StabilityMatrix]]を使って簡単にインストールできる。[[EasyHunyuanVideo>https://github.com/Zuntan03/EasyHunyuanVideo]]で動画の生成もできるで
おそらく出来ることは一番多いが複雑な外観に眩暈する人を量産している
どうしてもしんどければ代替UIとして[[SwarmUI>https://github.com/mcmonkeyprojects/SwarmUI]]などを使うのも手か…？なおSwarmUI自体はComfyUIのPortable版の簡易インストーラーも兼ねている(既存の環境を使っても良い)
RTX5000シリーズを買えた幸せ者は下記リンクの最新版をインストール(本稿執筆時、上記リンクの安定版は動作しない)
https://github.com/comfyanonymous/ComfyUI/discussions/6643

[[ワークフロー集>https://github.com/comfyanonymous/ComfyUI_examples]]
[[Wiki>https://comfyui-wiki.com/ja/comfyui-nodes]]
-単にA1111やrefogeの手順を再現したいだけなら出力した画像をドラッグアンドドロップしてやるだけでもWorkflowとして再現してくれたりする

Model:
[[NoobAI-XL (NAI-XL)>https://civitai.com/models/833294/noobai-xl-nai-xl]]
FLUX.1([[ワークフロー>https://comfyanonymous.github.io/ComfyUI_examples/flux/]])
・https://huggingface.co/black-forest-labs/FLUX.1-dev/tree/main
・https://huggingface.co/city96/FLUX.1-dev-gguf/tree/main
* 目次

#contents
*2025年
**2025-11-26 Alibaba、Z-Image-Turboを発表
https://modelscope.cn/models/Tongyi-MAI/Z-Image-Turbo
パラメータ数6Bの画像生成モデル。ベースモデルのZ-Image-Baseと画像編集用のZ-Image-Editも発表された（いずれも公開は近日中）。
ComfyUIが対応。
https://comfyanonymous.github.io/ComfyUI_examples/z_image/
https://huggingface.co/Comfy-Org/z_image_turbo
**2025-11-25 Black Forest Labs、FLUX.2を発表
-FLUX.2[dev]モデルのダウンロード：https://huggingface.co/black-forest-labs/FLUX.2-dev
-FLUX.2の概要：https://bfl.ai/blog/flux-2
-FLUX.2のリリース記事：https://docs.bfl.ai/flux_2/flux2_overview
オープンウェイトモデルはFLUX.2[dev]（32B）とFLUX.2[Klein]（Kleinは近日公開）。
おもな変更点は以下の通り。
-最大10枚の画像を参照可能に（[dev]は最大6枚）
-より詳細な画像を出力
-テキストのレンダリング強化
-プロンプト理解の強化
-現実世界の理解を強化
-最大400万画素（2048×2048など）の解像度で画像を編集可能に
-RGB16進数で色を指定可能に
-構造化されたプロンプトを指定可能に
city96氏によるggufモデル
https://huggingface.co/city96/FLUX.2-dev-gguf/tree/main

**2025-11-21 Google、Nano Banana Proを発表
-[[Nano Banana Proを発表: Gemini 3 Pro Image model from Google DeepMind>https://blog.google/intl/ja-jp/company-news/technology/nano-banana-pro/]]
Nano Bananaと比較して日本語の表現力がアップしたほか、インフォグラフィックの作成、最大14枚の画像をもとにした画像生成、縦横比の自然な変更、色調の変更なども可能。

**2025-11-20 AI生成画像を無断で使用した男が著作権法違反で書類送検される
-[[「AI生成画は著作物」、無断複製の疑いで男を書類送検へ…千葉県警が全国初の摘発 : 読売新聞>https://www.yomiuri.co.jp/national/20251120-OYT1T50016/]]
-[[生成AIで作った画像を無断複製の疑い、27歳男を書類送検…「著作権あり」として初の摘発 : 読売新聞>https://www.yomiuri.co.jp/national/20251120-OYT1T50104/]]
これらの報道を受け、スレではAI生成の画像と著作権についての議論が活発になった。

**2025-10-28 Grok、動画生成のNSFW規制を大幅強化
正式な告知はないが、胸を露出した画像でi2vできなくなった、以前は動画生成された画像が通らなくなったなどの報告が相次いだ。

**2025-10-25 PurpleSmartAI、Pony v7 baseを公開
https://huggingface.co/purplesmartai/pony-v7-base
https://civitai.com/models/1901521
「AuraFlowアーキテクチャをベースにした汎用性の高いキャラクター生成モデル」と紹介している。

**2025-10-14 Civitai、NSFW画像の生成を有料のみに変更
https://civitai.com/articles/20211
これまでは無料でももらえる青BuzzでNSFW画像も生成できていたが方針が変更となった。青Buzzで生成できるのはSFW画像のみとなり、黄Buzzを購入しない限りNSFW画像を生成できなくなった。
クレジットカード会社からの締め付けの結果という噂もある。

**2025-10-13 5ch、どんぐりシステムをサスペンド状態にすると告知
https://asahi.5ch.net/test/read.cgi/newsplus/9240230711/8
=|BOX|
8 ５ちゃんねる ★ 2025/10/13(月) 03:00:00.00 ID:LokiTech
荒らし対策として開発されたユーザー参加型の「どんぐりシステム」ですが、近年では大規模な荒らし行為も沈静化しており、
一方で悪質なハンターによる無差別な大砲機能の乱用が見受けられるようになりました。
これらの状況を踏まえ、新たに「どんぐりゲート」を設けることになりました。

「どんぐりゲート」のデフォルト設定は「false」となり、以後、書き込み制限などの機能はサスペンド状態となります。
大砲（キャノン）機能自体は有効のままですが、その効果は該当する書き込み者に「臭」マークを付けるのみとなり、「書き込み禁止」などの規制は行われません。

今後、再び大規模な荒らし行為が発生したと判断された場合には、「どんぐりゲート」の設定が「true」となり、
どんぐり機能が有効なすべての板でその機能が再開されます。
||=

これによって、なんJNVA部はどんぐりレベルによらず書き込めるようになった。

**2025-10-07 OpenAI、Sora2のAPIを発表
https://platform.openai.com/docs/guides/video-generation
Sora-2とSora-2-Proが用意され、価格は最も安いSora-2が1,280×720ピクセルで1秒0.1ドル。→[[価格表>https://openai.com/ja-JP/api/pricing/]]

**2025-10-06 Grok、動画生成AIを実装
https://grok.com/imagine
画像をアップロードするとすぐに生成が始まり、動画が出力される。二次元絵の動画化が得意でエロ表現も可能。効果音や音楽も自動で挿入される。Sora2と異なりウォーターマークも入らない。
Grokのスマホアプリで年齢認証を行うと、パソコンでもエロ動画を出力できるようになるらしい。

**2025-10-03 音声合成AI「高音（Takane）」、公開終了
https://huggingface.co/spaces/Respair/Takane
自然なイントネーションと感情のこもった音声データを生成でき、エロ声も可能な「Takane」（9月27日リリース）の公開が終了した。作者の[[Soshyant>https://x.com/MystiqCaleid]]氏はTakaneがあくまで技術デモであること、また「サーバーへの大きな負担、そして声優の方々への潜在的な悪用を防ぐため」としている。

**2025-10-01 OpenAI、動画生成AIのSora2を公開
https://openai.com/index/sora-2/
当面は招待制だが、招待コードは簡単に見つかるという話も。
画像やテキストから生成される動画はよく動き、効果音やセリフも自動で追加してくれる。

**2025-09-28 Tencent、HunyuanImage-3.0を発表
https://huggingface.co/tencent/HunyuanImage-3.0
パラメータ数は80Billion、VRAMが3×80GB（4×80GBを推奨）必要という巨大モデル。

**2025-09-22 Alibaba、Qwen-Image-Edit-2509を発表
-告知記事 https://qwen.ai/blog?id=7a90090115ee193ce6a7f619522771dd9696dd93&from=research.latest-advancements-list
-huggingface https://huggingface.co/Qwen/Qwen-Image-Edit-2509
複数の画像の入力をサポート、画像の一貫性の向上、ControlNetへの対応などをうたっている。

**2025-09-16 Comfy Cloudが発表される
-公式サイト https://cloud.comfy.org/
-告知記事 https://blog.comfy.org/p/comfy-cloud
ComfyUIの環境をクラウドで提供する有料サービスが発表された。GPUのないパソコンでもComfyUIで画像や動画を生成できる。クローズドベータとして開始し、のちに正式サービスになる予定。
従来無償で提供されてきたローカル版のComfyUIは、今後も変わらず無償で提供される。

**2025-09-10 Tencent、HunyuanImage-2.1を発表
https://hunyuan.tencent.com/image/en?tabIndex=0
https://huggingface.co/tencent/HunyuanImage-2.1
2K解像度の画像を生成できるほか、中国語と英語のテキストレンダリングを得意とする。
ComfyUIは[[レギュラーモデルに即日対応した>https://github.com/comfyanonymous/ComfyUI/pull/9792]]。

**2025-09-09 ByteDance、SeeDream 4を発表
https://seed.bytedance.com/en/seedream4_0
プロンプトで画像を編集するAIモデル。 https://replicate.com/bytedance/seedream-4 で実際に利用できる（有料）。

**2025-09-03 Stable Diffusion Forge - Neoが公開される
https://github.com/Haoming02/sd-webui-forge-classic/tree/neo
「Forge Classic」を開発していたHaoming02氏が、新たに「Forge Neo」を発表した。Forge Classicはいわゆる旧Forge（v1.x）を最適化し、SD1.xやSDXL向けに開発されていた。Forge NeoはForge 2.xをもとに、最新の技術であるWan2.2やFLUX Kontext、Chromaなどに対応する。

**2025-08-26 Google、nano-Bananaを公開
https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash-image-preview
Googleが「Gemini 2.5 Flash Image」を公開した。nano-Bananaというコードネームでプレビュー公開されていた画像生成AIで、画像の高度な編集が可能。複数の入力画像を組み合わせた画像の出力、画像内の背景の差し替え、画像内の人物の表情変更、入力した人物画像の三面図の出力、アニメ風人物画像のフィギュア写真への変換などを、高度な一貫性を保ちながら行うことができる。LoRAの素材画像を増やすなどにも便利。

**2025-08-24 Panchovix氏、reForgeのリポジトリをアーカイブ化する（のち解除）
https://github.com/Panchovix/stable-diffusion-webui-reForge
2024年6月9日にForgeを実験的なリポジトリにすると作者のIllyasviel氏が宣言した約1ヶ月後、reForgeは2024年7月7日に「可能な限りA1111の変更点を取り込んだforgeのフォーク」として公開された。Forgeやa1111の開発が停滞する中、独自にバージョンアップを続けていた。2025年4月13日にいったん開発終了宣言がなされたあと、7月19日には開発継続のメッセージが投稿され活発にコミットされていた。

3日後の8月27日、本人のメッセージとともにアーカイブ化は解除された。

**2025-08-23 NovelAI、画像生成の新機能として「キャラ参照（Character Reference）」を公開
https://x.com/novelaiofficial/status/1959206266255134834
読み込ませたキャラクター画像をもとに別の画像を生成できる機能がプレビュー版として公開された。FLUX.1 KontextやQwen-Image-Editに近い機能と思われる。

**2025-08-19 Alibaba、Qwen-Image-Editを公開
https://qwenlm.github.io/blog/qwen-image-edit/
画像編集専用のモデル。画風の変更、対象の向きの変更、画像の背景や着ている服の変更、文字の修正などが可能。

**2025-08-04 Alibaba、Qwen-Imageを公開
https://huggingface.co/Qwen/Qwen-Image
画像生成や画像編集の品質の高さのほか、文字の生成（英語と中国語）も得意とアピールしている。ライセンスはApache 2.0。

**2025-08-01 KreaがFLUX.1 Krea [dev]を公開
https://www.krea.ai/
いわゆる「AI風」でない画像を生成することに注力した、FLUX.1 [dev]互換のモデル。
- モデルやGitHubへの[[リンク>https://www.krea.ai/blog/flux-krea-open-source-release]]
ComfyUIは例によって[[即日対応>https://blog.comfy.org/p/flux1-krea-dev-lands-on-comfyui-on]]した。
- [[GGUF版モデル>https://huggingface.co/QuantStack/FLUX.1-Krea-dev-GGUF]]

**2025-07-28 Alibaba、Wan2.2を公開
- https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B
- https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B
- https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B

text to video/image to videoのモデル「Wan2.2」が公開。28日21時（日本時間）に公開すると予告されたこともあり、スレは期待感で盛り上がった。ComfyUIで動作する。
モデルの公開から数時間後にgguf版も公開された。

- https://huggingface.co/QuantStack/Wan2.2-I2V-A14B-GGUF
- https://huggingface.co/QuantStack/Wan2.2-TI2V-5B-GGUF
- https://huggingface.co/QuantStack/Wan2.2-T2V-A14B-GGUF

Zuntan氏によるRTX3060/12GB、メインメモリ64GBでWan2.2 TI2V 5Bを使った動作報告も上がっている。
https://github.com/Zuntan03/SimpleComfyUi#wan22-day-0-support-in-comfyui-%E6%89%8B%E9%A0%86
続いて、VRAM8GB、メインメモリ32GBでもWan2.2で高速に動画を生成できる「EasyWan22」も公開された。
https://github.com/Zuntan03/EasyWan22

**2025-07-22 Neta.art Lab、Neta Luminaを公開
https://huggingface.co/neta-art/Neta-Lumina
アニメスタイルのイラストレーションに強いとするNeta Luminaが公開された。ComfyUIで動作し、VRAMは8GB以上が必要。ライセンスはApache License 2.0で、無制限の商用利用が可能。
プロンプトに英語のほか中国語、日本語も使える。danbooruタグにも対応。

**2025-07-19 stable-diffusion-webui-reForgeの開発継続のお知らせ
https://github.com/Panchovix/stable-diffusion-webui-reForge/discussions/377
今年四月に開発が終了していたが、7月19日、開発者のPanchovix氏は開発を(今のところ)継続すると発表した。

**2025-07-15 xAI、GrokにAIコンパニオン「ani」を実装
aniと会話をし、親密度が上がると衣装が変わるらしい。
当面はiOSのアプリ版Grokにのみ登場するとのこと。
[[なんJNVA部★560>https://fate.5ch.net/test/read.cgi/liveuranus/1752473555/]]の中盤以降はaniの画像が多く投稿された。

**2025-07-08 NovelAI Diffusion V2のモデルが公開される
https://blog.novelai.net/novelai-diffusion-v2-weights-release-b9d5fef5b9a4
ダウンロードはこちらから：https://huggingface.co/NovelAI/nai-anime-v2
ライセンスはCreativeML Open RAIL-Mライセンスとクリエイティブ・コモンズ BY-NC-SA 4.0ライセンスが適用され、利用は非商用目的のみ許可される。

**2025-07-08 Stability AI、7月31日発効の新利用規約を公開。NSFWコンテンツの生成を禁ずる
https://stability.ai/use-policy
Stability AIの技術を使って、未成年者の性的搾取、小児性愛、性行為や性的暴力などのコンテンツを生成することを禁じる利用規約が公開された。7月31日に発効となる。
SDXLまでのモデルはライセンス上新規約が遡及適用されないため影響を受けず、新規約の対象となるのはSD3以降という意見もある。
AI画像生成サービスによる、この規約変更に対するものと思われる反応：
-NovelAI：「新しいNovelAI V4およびV4.5モデルがStable Diffusion、SDXL、FLUX、またはその他のモデルを基盤としていないことを明確にしました」（https://x.com/novelaiofficial/status/1943940953028669936）とし、NovelAI DiffusionはStable Diffusionの規約変更に影響されないと宣言
-TensorArt：NSFWコンテンツの生成や新規公開を禁止（https://tensor.art/event/NSFW&CelebrityAdjustments）

**2025-07-07 旧Forgeなどが起動しなくなる
ライブラリの自動アップデートに旧Forge本体が追いついていないためと推測された。
https://fate.5ch.net/test/read.cgi/liveuranus/1751939332/68 に対処法が書き込まれた。
=|BOX|
68 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった 警備員[Lv.14] (ﾜｯﾁｮｲ 9fd0-d21E)[sage] 投稿日：2025/07/08(火) 14:31:59.38 ID:iIuykCfp0
前スレから長々とお目汚し申し訳ないで。ようやく解決したから、せめて後の人の役に立てればと解決策を書かせてもらいます
【環境】
旧forgeで特に環境も弄らず、モデルとLoraのみ入れ替える程度だったが7月7日午後以降にrun.batから起動すると
NumPy 2.2.6 as it may crash. To support both 1.x and 2.x〜のエラーが出てWebUIが起動しなくなる
【原因】
numpyとopencv-pythonの互換性の問題
run.batを叩くと自動でopencv-pythonとNumpyのアップデートが入るため、cmdでバージョン修正したり再インスコ（初期化）しても未解決
【対処】
cmdでvenvのactivateから「pip install numpy==1.24.4 opencv-python==4.8.1.78 --force-reinstall」を実行
さらに起動をrum.batからではなくwebui.batからにして、エディターで「set FORGE_SKIP_REQUIREMENTS=1」call直前に「set COMMANDLINE_ARGS=--skip-version-check」を追記
||=

**2025-07-01 NovelAI Diffusionで30回の無料体験がスタート
https://novelai.net/
NAIはこれまで課金しないと画像生成を試すことができなかったが、30回まで無料で画像を生成できるようになった。

**2025-06-27 NovelAI Diffusion 4.5にPotionが実装される
https://novelai.net/
NAI 4.5のポーション機能が公開された。入力画像の絵柄を抽出し適用できる。

**2025-06-27 FLUX.1 Kontext [dev]のモデルが公開される
https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev
5月30日に公開済みの「FLUX.1 Kontext」をローカルで試せるモデルが公開された。ComfyUIは[[即日対応>https://blog.comfy.org/p/flux1-kontext-dev-day-0-support]]。ComfyUIをアップデートするとテンプレートの「FLUX」にサンプルワークフローが配置される。

**2025-05-30 FLUX.1 Kontextが公開される
https://bfl.ai/models/flux-kontext
FLUX.1を開発したBlack Forest Labが「FLUX.1 Kontext」を公開した。入力画像をどう変化させるか自然言語で入力するとその通りになる。
モデルは後日公開されるとのこと。

**2025-05-30 NovelAI Diffusion V4.5 Fullがリリースされる
[[https://blog.novelai.net/制限なき創作へ-novelai-diffusion-v4-5-full登場-60f2f603a1e8>https://blog.novelai.net/%E5%88%B6%E9%99%90%E3%81%AA%E3%81%8D%E5%89%B5%E4%BD%9C%E3%81%B8-novelai-diffusion-v4-5-full%E7%99%BB%E5%A0%B4-60f2f603a1e8]]
品質の向上をうたっているほか、英語テキストを画像内に表示するプロンプトが簡易化されるなどの改良がほどこされている。

**2025-05-20 5月23日以降、Civitaiでの支払いにクレジットカードが使えなくなるとのアナウンス
https://civitai.com/articles/14945
運営はこれは一時的な措置であるとし、23日までに年間メンバーシップを契約するようすすめているほか、近日中に暗号通貨での支払いにも対応するとしている。

**2025-04-24 Civitaiの利用規約がより厳しくなる
https://civitai.com/articles/13632
たとえば禁止コンテンツとして新たに近親相姦、自傷行為、尿や吐瀉物、おむつなどを含む排泄物といった項目が加わった。厳格化されたものはほかにもあり、全体に不自由さを増した内容になっている。
新しい規約に違反していると判断されたコンテンツは非表示となり、30日後に削除される。

**2025-04-23 NVIDIA GeForce RTX 50x0に対応したPyTorch 2.7が正式にリリースされる
https://pytorch.org/blog/pytorch-2-7/

PyTorch 2.7はNVIDIAのBlackwellアーキテクチャに対応したバージョンで、GeForce RTX 50x0シリーズも含まれている。
これで50x0シリーズでの画像・動画生成や学習が問題なくできるようになった。はず。

**2025-04-19 Illustrious XL v2.0、ダウンロード可能に
https://tensor.art/models/840365567832646761
https://huggingface.co/OnomaAIResearch/Illustrious-XL-v2.0/tree/main

**2025-04-17 Illyasviel氏、FramePackを公開
https://github.com/lllyasviel/FramePack
ControlNetやForgeを開発したIllyasviel氏がi2v（image2video）ソフトウェアのFramePackを公開した。
6GB VRAMから利用できるとあり、これまでの動画生成AIと比較して格段に低スペックでの生成が可能。

**2025-04-13 reForgeの開発が終了
https://github.com/Panchovix/stable-diffusion-webui-reForge/discussions/354
実生活や仕事、健康の問題で十分な開発時間を確保できないためとのこと。

Zuntan03氏が開発している[[EasyReforge>https://github.com/Zuntan03/EasyReforge]]は「この前の大規模更新で少し前の安定気味バージョンでリビジョンを拡張機能も含めて固定済みやで」「またなんか新しい環境が出てくるまでNoobやIllustrious用の安定版環境としてご利用くださいやね」。
https://fate.5ch.net/test/read.cgi/liveuranus/1744454985/122

**2025-04-08 HiDream.ai、新しいアーキテクチャの画像生成AIモデル「HiDream-I1」を公開
https://github.com/HiDream-ai/HiDream-I1
https://huggingface.co/HiDream-ai
従来の画像生成AIモデルに多く採用されてきた拡散モデルに代わり、Sparse Diffusion Transformer（DiT）というアーキテクチャを採用。170億パラメータを擁し、Full、Dev、Fastの3種のモデルが公開された。VRAM12GB、メインメモリ64GBから動作可能とされている。出力された画像は商用利用が可能。
3種類のモデルはそれぞれ量子化版が公開されている。（[[Full>https://huggingface.co/city96/HiDream-I1-Full-gguf]]、[[Dev>https://huggingface.co/city96/HiDream-I1-Dev-gguf]]、[[Fast>https://huggingface.co/city96/HiDream-I1-Fast-gguf]]）

**2025-03-26 ChatGPTの画像生成がGPT-4oベースになる
従来のDALL-Eベースの画像生成と比較してプロンプトの理解力が格段に上がり、表現力も高まった。
「どんな画像もスタジオジブリ風にできる」と話題になり、利用者が増大した結果OpenAIのサム・アルトマンCEOは「GPUが溶ける」とSNSへ投稿、無料ユーザーへの開放を延期すると表明した。（4月初めには全無料ユーザーに開放された）

**2025-03-17 Illustrious XL 2.0が公開される
https://www.illustrious-xl.ai/model/4
https://tensor.art/models/840365567832646761/
当初はウェブサービス上のみでのリリースとし、のちにアーリーアクセス、オープンソースと進むロードマップが示された。

**2025-03-08 GeForce RTX50x0での画像生成AIの利用
RTX50x0シリーズは当初ComfyUIのみ利用できる状況だったが、CUDAの暫定版アップデートがリリースされた結果、生成、学習とも利用できるアプリケーションが増えてきた。
-生成：https://fate.5ch.net/test/read.cgi/liveuranus/1741351441/310 で「[[RTX5090で、StableDiffusion Automatic1111 を動かしてみた #automatic1111 - Qiita>>https://qiita.com/hgodai/items/f958b69216f86819c740]]（PyTorchをCUDA 12.8対応のnightly buildに入れ替える）」と「[[GeForce RTX 5090でStable Diffusion 環境構築のメモ｜suk1y4ki>>https://note.com/suk1y4ki/n/n8dc027298553]]（EasyReforgeを利用）」が紹介された。
-学習1：http://bbs.punipuni.eu/test/read.cgi/vaporeon/1739986291/656 で方法が紹介された。

**2025-03-04 Hakomikan氏、新しいLoRA学習の手法「ADDifT」の解説記事を公開
-[[交替直接差分学習法ADDifT(Alternating Direct Difference Training)の解説｜hakomikan>>https://note.com/hakomikan/n/n716397e39d56]]
6日には[[Traintrain>>https://github.com/hako-mikan/sd-webui-traintrain]]での学習方法を解説する記事（[[1>>https://note.com/hakomikan/n/n2a00c2bb39af]]）を公開した。

**2025-03-02 EasyWanVideoが公開される
https://github.com/Zuntan03/EasyWanVideo
Zuntan氏によるEasyシリーズで、WanVideoを使った動画生成の環境がセットアップされる。
メインメモリ32GBではスワップが発生しやすくSSDの寿命が短くなるとして、64GBが最低限ではという意見が多い。マザーボードの制限をチェックしつつ128GBやそれ以上にメモリを増設するユーザーが増えた。

**2025-03-01 NovelAI Diffusion v4が正式リリースされる
https://novelai.net/
公開直後の様子では、プロンプトの効き方がv3から変わり、思い通りの画像を出力できないと感じるユーザーが多い模様。SMEAやバイブストランスファーが実装されていないことも一因か。
**2025-02-20 NVIDIA GeForce RTX 5070Tiが発売される
5090/5080を買えた人がほとんどいない上4000シリーズも品薄な中、23時に発売開始。

**2025-02-11 Illustrious XL 1.0が公開される
https://civitai.com/models/1232765
当初はモデルをダウンロードできず、CivitaiやTensor.art、PixAIといったWebサービス上でのみ画像を生成できる形式だったが、多くの批判の声を受けてか翌12日には10ドル支払うとダウンロードできるようになった。

**2025-01-30 NVIDIA GeForce RTX 5090/5080が発売される
予約抽選サイトは混雑でほとんど閲覧できず、実店舗での抽選販売では大勢が殺到し店舗近隣の幼稚園に侵入する人が現れるなど混乱が見られた。
また初期出荷の台数はきわめて少なく、次期出荷は数か月後とみられる上にいくつかのメーカーは値上げを発表している。
なお、RTX5080及び5090は2025年2月13日時点でPytorchに対応するバージョンがないCUDA12.8以降にしか対応していないため、2025年2月13日時点現在ではEasyReforgeでの構築が不可能。
回避策・アップデートがあったら追記願います。
ComfyUIはhttps://github.com/comfyanonymous/ComfyUI/discussions/6643 から50x0対応版をダウンロードできる。

**2025-01-28 Animagine XL 4.0が公開
Hugging Face: https://huggingface.co/cagliostrolab/animagine-xl-4.0
ブログ: https://cagliostrolab.net/posts/animagine-xl-v4-release
ローカルでSDXLが普及するきっかけとなったAnimagine-XLの新バージョンがリリースされた。
データセットが前バージョンから大幅に拡張されており、2025年1月7日までのデータを学習しているとのこと。
エッチなのも対応。
プロンプト関連の変更として新たにスコアタグが追加された。
今後、V4の改良とSD3.5ベースのAnimaestroの開発を進めるとのこと。

**2025-01-10 動画生成の波
動画生成の流れが最近きている
[[lora>https://civitai.com/models/1094156/titty-drop-hunyuan-video-lora?modelVersionId=124322]]でこんなのが作れるで
[+]エロ注意、クリックで展開
[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/nmlNj47glR-s.gif)>https://image02.seesaawiki.jp/n/h/nai_ch/nmlNj47glR.gif]]
[END]

https://fate.5ch.net/test/read.cgi/liveuranus/1736004270/626

正直解説するほど詳しくないがとりあえず備忘録程度に情報をメモしとくで

・動画生成モデル[[HunyuanVideo>https://github.com/Tencent/HunyuanVideo]]の簡単インストーラー
[[EasyHunyuanVideo>https://github.com/Zuntan03/EasyHunyuanVideo]]

なんJNVA部★498 https://fate.5ch.net/test/read.cgi/liveuranus/1736173877/28
=|BOX|
28警備員[Lv.48][N武][N防] (ﾜｯﾁｮｲ abb2-bDSa)垢版 | 大砲2025/01/07(火) 00:09:53.83ID:hvUOYtbR020
https://github.com/Zuntan03/EasyHunyuanVideo
https://yyy.wpx.jp/EasyHunyuanVideo/Sample/ThisIsFine_Toga.mp4 (音注意)
サンイチ！師走は立て込んどったんやが正月休みでEasyHunyuanVideoを用意したで

FastVideo, SageAttention, TeaCacheの併用でGeforce RTX 3060 12GBでもそこそこ高速＆省VRAMや
日本語プロンプトの英訳・LLMやTIPOでのプロンプト補完（イマイチ）・自動＆手動モザイク・アップスケール・フレーム補間・MMAudio音声に対応してあるで

NSFWサンプルは追々追加予定や
||=

・HunyuanVideo用のLoRA学習スクリプト
[[musubi-tuner>https://github.com/kohya-ss/musubi-tuner]]

https://x.com/kohya_tech/status/1874057372609765615
[[&ref(https://image01.seesaawiki.jp/n/h/nai_ch/gYQ09Xg5D_-s.png)>https://image01.seesaawiki.jp/n/h/nai_ch/gYQ09Xg5D_.png]]

・有志の解説
[[HunyuanVideo用キャラクタLoRA作成の手順>https://rentry.co/howtousemusubituner]]

なんJNVA部★498 https://fate.5ch.net/test/read.cgi/liveuranus/1736173877/404
=|BOX|
404今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった 警備員[Lv.5][芽] (ﾜｯﾁｮｲ d3da-WhgO)垢版 | 大砲2025/01/07(火) 16:42:00.55ID:p/D/DW+T04
>>28より前の年明けからずっとHunyuanVideoをいじっていたので、Geforce 3060での
アニメキャラクタ学習LoRAの作り方に関してまとめた文書を作ったよ

rentry.co/howtousemusubituner

基本的にはmusubi-tunerのREADME.ja.mdそのままだけど、タグ付けや学習画像枚数等の
データセットの作成と学習設定に関してはこの設定でうまくいくはず
ダメだったらごめんね
||=

・musubi-tunerのGUI
[[Hunyuan Video Lora Trainning with GUI in Windows>https://civitai.com/articles/10335]]
**2025-01-08 パルリアス作者ニキ、店じまいを宣言
- 当該の書き込み：https://fate.5ch.net/test/read.cgi/liveuranus/1736173877/836
=|BOX|
836 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった ハンター[Lv.331][UR武][SR防][苗] (ｵｯﾍﾟｹ Sr4d-u+6e)[sage] 投稿日：2025/01/08(水) 17:33:04.31 ID:SXtJ11Ptr
>>830
ファー
速攻で転載されて草
まぁv5は正直失敗作やから転載されてもそこまでという感じではあるけど
ちな経過報告するといちおうシビタイに削除依頼は出したがそもそも返事ないな。ほったらかしやわ
それと本人がモデルをアップしてアーカイブ化してても転載はできてしまうようなので運営が対処する以外に対処法はなさそう
いちおう別モデルベースのv5亜種みたいなのは作ってたけどまた転載されそうで面倒くさそうやからパルパルは店じまいということで…すまんでみんな
||=

**2025-01-07 NVIDIAからGeForce RTX5000シリーズが発表される
Blackwell世代のGPUがNVIDIAから発表された。DLSS、Tensorコア、レイトレーシングコア、NVENC、NVDEC、メモリなどがそれぞれ新しい世代にバージョンアップしている。
https://www.nvidia.com/ja-jp/geforce/graphics-cards/50-series/
- GeForce RTX 5090…\393,800より、VRAM32GB、メモリ帯域幅1,792GB/sec
- GeForce RTX 5080…\198,800より、VRAM16GB、メモリ帯域幅960GB/sec
- GeForce RTX 5070 Ti…\148,800より、VRAM16GB、メモリ帯域幅896GB/sec
- GeForce RTX 5070…\108,800より、VRAM12GB、メモリ帯域幅672GB/sec
- （参考）GeForce RTX 4090…VRAM24GB、メモリ帯域幅1,008GB/sec
**2025-01-04 パルリアスv5が公開される
人気モデルのパルリアスにv5が登場、スレが大いに盛り上がった。
公開を告知する書き込み：https://fate.5ch.net/test/read.cgi/liveuranus/1735778359/544
公開場所のURL：https://huggingface.co/paruparu95483/paruparu_illustrious/tree/main
*2024年
**2024-12-28 スクリプト攻撃が行われる
数ヶ月ぶりにスクリプトによる攻撃が行われた。どんぐり大砲の有効化と、書き込み可能レベルを3に上げる対処が行われた。

**2024-12-22 NoobAI-XL 1.0(v-prediction版)が公開される
v-predictionとZero Terminal SNRを使用することで明暗と色の表現が改善したもの。
上記の技術については[[Models>Models]]を参照
- https://civitai.com/models/833294

**2024-12-21 NovelAI Anime Diffusion V4 &#8212; Curated Previewがリリースされる
https://blog.novelai.net/novelai-anime-diffusion-v4-curated-preview%E3%81%AE%E3%81%94%E7%B4%B9%E4%BB%8B-2549111172ae
マルチキャラクタープロンプト、アクションタグ、英語の自然言語理解の向上などが実装された。

**2024-12-09 外部記事による2024画像生成AIまとめ
外部記事 
[[新清士の「メタバース・プレゼンス」 第87回 画像生成AIの進化が早すぎる　2024年に起きたことまとめ>https://ascii.jp/elem/000/004/239/4239726/]]
[[2024年生成AIの進歩まとめ>https://zenn.dev/sakasegawa/articles/eb27e30085174f]]
スレとは関係ないが、2024年の画像生成AIに関する情報がコンパクトにまとめられているので、浦島が読むのにちょうど良い。
編注：ついこのまえ2023年のこの項目を追加したと思ったのに、もう一年経ってる。こわい

**2024-12-06 無断転載された画像を使わず学習されたモデル「Emi 3」が公開される
https://huggingface.co/aipicasso/emi-3
> Emi 3 (Ethereal master of illustration 3) は、 オプトアウト済みモデルStable Diffusion 3.5 Largeをベースに AI Picasso社が開発したAIアートに特化した画像生成AIです。 このモデルの特徴として、Danbooruなどにある無断転載画像を追加に学習していないことがあげられます。

**2024-12-03 Huggingfaceにアップロード容量の制限が設けられる
今まで容量無制限でモデルのアップロードが可能ということで多くのユーザーを集めていたHuggingFaceだったが、ついに容量制限がかけられた。
無課金ユーザーは500GB、課金ユーザーは1TBとのこと。
いつかこうなると身構えていたユーザーもいた一方、TB単位で有益なモデルをアップロードしていた複数のユーザーが上限にヒットするなど混乱も見られた。
(2024-12-11) その後、利用実態（upしたモデルが実際に使われているかなど）に合わせて追加ストレージ枠の付与などが行われつつ、現時点ではprivateリポジトリはfreeで100GB、proで1TB+従量課金、publicリポジトリはほぼ無制限、という形に[[収まった>https://huggingface.co/docs/hub/storage-limits]]
**2024-11-27 ComfyUIのデスクトップ版が一般公開される
クローズドベータテストが行われていたComfyUIのデスクトップアプリ版がベータテストを終え、[[一般公開された>https://blog.comfy.org/open-sourcing-v1-desktop/]]。
ダウンロードは https://github.com/Comfy-Org/desktop から

**2024-11-26 ControlNetと画像編集ソフトを使った透視メガネが流行する
着衣と脱衣の画像を用意して画像編集ソフトに読み込み、クリッピングマスクとメガネの枠を重ねて移動すると透視しているように見える手法が紹介された。
- 発端となった投稿　https://fate.5ch.net/test/read.cgi/liveuranus/1732613695/16
- メイキング解説　https://fate.5ch.net/test/read.cgi/liveuranus/1732613695/662
- ComfyUIのワークフロー　https://fate.5ch.net/test/read.cgi/liveuranus/1732613695/886
- 解説画像の紹介　https://fate.5ch.net/test/read.cgi/liveuranus/1732724442/126

**2024-11-24 最近Huggingfaceで公開されたモデル
https://fate.5ch.net/test/read.cgi/liveuranus/1732449618/116 をもとにしている。
※時限公開のモデルも含む。スレで要望すると再公開されることがある

-11/10 [[paruparu_illustrious>https://huggingface.co/paruparu95483/paruparu_illustrious/tree/main]]（https://fate.5ch.net/test/read.cgi/liveuranus/1731170779/530）
-11/14 [[Illustrious_Models_AsumaXL>https://huggingface.co/Qnuk/Illustrious_Models_AsumaXL/tree/main]]（https://fate.5ch.net/test/read.cgi/liveuranus/1731470180/548）
-11/23 [[NONAMEmix_v1>https://huggingface.co/Emanon14/NONAMEmix_v1]]（https://fate.5ch.net/test/read.cgi/liveuranus/1732317496/558）
-12/_2 [[HarmoniqMix_ePred_v1.x>https://huggingface.co/hybskgks28275/HarmoniqMix_ePred_v1.x]]（https://fate.5ch.net/test/read.cgi/liveuranus/1733042745/261）
-12/_5 [[momizi_Noob>https://huggingface.co/KKTT8823/momizi_Noob/tree/main]]（https://fate.5ch.net/test/read.cgi/liveuranus/1733367072/220）
-12/10 [[HarmoniqMix_vPred_v2.x>https://huggingface.co/hybskgks28275/HarmoniqMix_vPred_v2.x]]（https://fate.5ch.net/test/read.cgi/liveuranus/1733671394/639）
-12/14 [[NONAMEmix-Vpred>https://huggingface.co/Emanon14/NONAMEmix-Vpred]]（https://fate.5ch.net/test/read.cgi/liveuranus/1734063723/583）
**2024-11-16 EasyReforgeが公開される
- https://fate.5ch.net/test/read.cgi/liveuranus/1731593689/687
- https://github.com/Zuntan03/EasyReforge
「NoobAiのEps&V-PredをreForgeで簡単＆高速にお手軽生成する」プログラム。必要なモデルやデータをまとめてダウンロードするほか、便利な機能拡張も自動でインストールされる。

**2024-11-15 スレの勢いが非常に高まる
11月15日頃からスレへの書き込みの量が増えてくる。新しいモデルの公開が相次いだほかV-Pred、[[TIPO>https://github.com/KohakuBlueleaf/z-tipo-extension]]、DMD2、CAMEといった技術の話題、[[EasyReforge>https://github.com/Zuntan03/EasyReforge]]の公開、椅子談義などさまざまなトピックが入り乱れて流れが速くなった。

**2024-11-03 NoobAI 1.0が公開される
- https://civitai.com/models/833294
アーリーアクセス版、0.5、0.75が公開されていたNoobAIの完成版となる1.0が公開された。
今後はv-predictionバージョンや専用ControlNetを開発するとのこと。


** 2024-10-30 Stable Diffusion 3.5 Mediumが公開
リポジトリ: https://huggingface.co/stabilityai/stable-diffusion-3.5-medium
SD3.5のパラメータ数25億のMediumがリリースされた。
Largeと異なりMMDiT-Xアーキテクチャを採用しており、複数の解像度の対応と全体的な一貫性を改善しているとのこと。

** 2024-10-22 Stable Diffusion 3.5 Largeが公開
ブログ: https://ja.stability.ai/blog/introducing-stable-diffusion-3-5
SD3.0のいくつかの問題に対処し、品質が向上したSD3の新バージョン。
現時点でパラメータ数8BのLargeのみ公開。パラメータ数2.5BのMediumは10月29日公開予定。

**2024-10-11 negpipがFLUX.1に対応
ネガティブプロンプトより強力に要素を排除できるWebUI/Forge用拡張機能の「Negpip」がFLUX.1にも対応した。これにより、ネガティブプロンプトを使えないFLUX.1でも実質的にネガティブプロンプトの指定が可能になった。
現在Automatic1111 WebUIはFLUX.1を扱えないため、Forge（v2.0〜）にのみ恩恵がある。

- Negpipiのレポジトリ… https://github.com/hako-mikan/sd-webui-negpip （「拡張機能（Extensions）」タブ−「拡張機能リスト（Available）」タブ−「読込（Load from:）」ボタン−検索欄に「negpip」と入力すると拡張機能一覧が絞り込まれ、「インストール（Install）」ボタンからインストールできる）
- 技術解説…「NegPiPの仕組みとFLUX対応」 https://note.com/hakomikan/n/n19dfd2cfabbc

**2024-10-08 NoobAI-XLのアーリーアクセス版が公開される
- https://civitai.com/models/833294
[[Illustrious>illustrious_xl_01tips]]の派生モデル。キャラクターの表現などが強化されている。

**2024-09-30 Illustrious XL v0.1が正式に公開される
https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0
リークの影響で9月21日ごろからアーリーアクセス版として公開されていた。
SDXLモデルでイラストに非常に強い。
詳細は[[illustrious_xl_01tips]]に。
**2024-09-07 ebara_ponyのリポジトリが消滅
突如としてHugging Faceのアカウントごと消えた。これによりすべてのebara_ponyは入手できなくなった。
数日後にCivitaiで全バージョンが公開されたが、アップしたのが本人なのかは不明。（名前からして転載だとは思うが…）

**2024-08-23 NovelAI Diffusion v1が公開される
[[https://blog.novelai.net/novelai-diffusion-v1-weights-release-jp-01d7fbad6fd7]]
 モデルは、当初のCreativeML Open RAIL-Mライセンスとクリエイティブ・コモンズBY-NC-SA 4.0ライセンスの両方の条件を適用するデュアルライセンスに基づいて公開されます。これにより、上記条件のもとで適切に帰属され配布される限り、非商用目的での利用、再配布、二次的著作物の作成が可能です。

**2024-08-23 ebara_pony_3が公開される
%%tps://huggingface.co/tsukihara/xl_model%% ※リンク切れ
「最近使ってるやつ」「やっぱり眩しい。なんでやろな」「4thtail使ってるんで諸々はそっち見てもろて(https://civitai.com/models/282341/4th-tail-animehentai)」との作者コメント。

**2024-08-14 Grok-2がFLUX.1を採用する
X（旧Twitter）が提供するLLM、Grok-2にFLUX.1による画像生成が搭載された。
どのバージョンなのかは公表されていない。
https://x.ai/blog/grok-2


**2024-08-11 Forgeが大幅に機能強化される

https://github.com/lllyasviel/stable-diffusion-webui-forge

FLUX.1への対応などさまざまな機能が強化された。代わりに動作しなくなった拡張機能もある模様。
FLUX.1のcheckpointは[[flux1-schnell-bnb-nf4.safetensors>https://huggingface.co/silveroxides/flux1-nf4-weights/blob/main/flux1-schnell-bnb-nf4.safetensors]]の使用が推奨されているほか、[[flux1-dev-fp8.safetensors>https://huggingface.co/lllyasviel/flux1_dev/blob/main/flux1-dev-fp8.safetensors]]も使用できる。

**2024-08-01 Black Forest Labsにより画像生成AIモデル「FLUX.1」発表
Stable Diffusionの元開発者が設立したベンチャー企業Black Forest Labsが、画像生成AIモデル「FLUX.1」を発表した。
API経由での有料画像生成に加え、ライセンスにより使用可能範囲が分かれたモデルデータも同日に公開し、Huggingfaceからダウンロードできる。公開日時点ではComfyUIで画像生成が可能。
なお、パラメータ数が12Bもあるため推論には大容量のVRAM(12GB以上?)が必要。
https://blackforestlabs.ai/announcing-black-forest-labs/
https://huggingface.co/black-forest-labs
日本語での記事 https://ascii.jp/elem/000/004/213/4213683/
ComfyUIでの使用法(8/2追記) https://comfyanonymous.github.io/ComfyUI_examples/flux/
Zuntan03(各種easyインストーラの作者)によるインストール用バッチファイル(8/7追記) https://x.com/Zuntan03/status/1820046015023722617
詳細は[[FLUX1tips]]に。

**2024-07-24 Euler SMEAなどいくつかの新サンプラーが話題に挙がる
[[reForge>https://github.com/Panchovix/stable-diffusion-webui-reForge]]や、[[EasySdxlWebUi>https://github.com/Zuntan03/EasySdxlWebUi]]に採用された新サンプラーが話題に挙がっていた。
オリジナルA1111 WebUIやForge(ただしオリジナルA1111では出力結果がReForgeやForgeと変わってしまい綺麗ではない、またEuler SMEAのみADetailerに対応していない)で使用したい場合は、Extensionとして以下のリポジトリからインストールすると使用可能

https://github.com/licyk/advanced_euler_sampler_extension

**2024-07-23 CivitaiがSD3の禁止を解除
Civitaiはライセンスなどの懸念によりSD3のモデルやLoRAの公開を禁止としていたが、解決されたとして禁止を解除した。
だがライセンスを取得しない方針のためCivitai上ではSD3を使用しての生成はできない。
https://civitai.com/articles/6221/sd3-unbanned-community-decision-on-its-future-at-civitai

**2024-07-18 AI Reviewersが流行
https://ai-reviewers.onrender.com/

画像を読み込ませるとAIのキャラクターがその内容を審査し点数をつけてくれる。

**2024-07-09 Paints-UNDO公開
ControlNetやstable-diffusion-webui-forgeの作者lllyasvielにより、Paints-UNDOという完成絵からその画像の描画シーケンスを出力するモデルおよび、シーケンスを動画として保存するコードが公開された。
詳細はリポジトリ参照
https://github.com/lllyasviel/Paints-UNDO

READMEではAnacondaでのインストール方法が記載されているが、WindowsのPython3.10.XのCuda環境下で動かしたい場合の手順は以下の通り(3.11は確認していない、3.12はpytorchの対応状況の問題で十中八九2024/7/10現在は動かない)

インストールしたいディレクトリへ移動し
=|BOX|
git clone https://github.com/lllyasviel/Paints-UNDO.git
cd Paints-UNDO
python -m venv venv
.\venv\scripts\activate
pip install xformers
pip install -r requirements.txt
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu121
python gradio_app.py
||=

２回目以降起動したいときは
=|BOX|
.\venv\scripts\activate
python gradio_app.py
||=

動画を作成すると、最後にffprobeが見つからないというエラーが出るが、resultsディレクトリ内にmp4ファイルが生成されている。

**2024-07-08 PonyでのLoRA学習時スコアタグの使用について
PonyでLoRAを学習する際に、学習画像のタグにスコアタグ(score_9_upなど)を入れることで学習効率を上げる方法が話題に上る。
[[PonyDiffusionV6XLTips>PonyDiffusionV6XLTips#content_8_12]]へいくつかレスを抜粋した。

**2024-07-07 可能な限りA1111の変更点を取り込んだforgeのフォークが公開される
https://github.com/Panchovix/stable-diffusion-webui-reForge
[[I've forked Forge and updated (the most I could) to upstream dev A1111 changes!>https://www.reddit.com/r/StableDiffusion/comments/1dxbadd/ive_forked_forge_and_updated_the_most_i_could_to/]]（フォークしたPanchovix氏による詳細が記載されたredditスレッド）
> Forgeが5ヶ月間アップデートされなかった後、A1111からの重要なアップデートや小さなパフォーマンスアップデートがたくさん欠けていたので、必要であれば、より使いやすく、より時代に合うようにアップデートすべきだと判断しました。（DeepLによる翻訳）
とのことで、DoRAサポートやスケジューラの分離など、forgeの更新が停滞していた時期にA1111に入った大小の変更が適用されている（個人的にはavifのサポートが嬉しい）。ただしSD3対応などは含まれていない。導入方法などの詳細は上記redditを参照すると良いだろう。

**2024-07-06 Stability AIがSD3のライセンスを変更
https://stability.ai/news/license-update
日本語: https://ja.stability.ai/blog/license-update
Stability AIはSD3 Mediumを"Stability AI Community License"という新しいライセンスのもと公開することにした。
 Our new Community License is now free for research, non-commercial, and commercial use. You only need a paid Enterprise license if your yearly revenues exceed USD$1M and you use Stability AI models in commercial products or services. 
年間の収入が100万ドル(日本円で約1.5億円)未満であれば研究、非商用、商用問わず無料で使用できる。

また、SD3 Mediumで見られる特定の条件で人体が破綻する現象を対処するとのこと。

**2024-06-26 Open Model Initiativeが発足
画像・動画・音声生成のためのオープンライセンスAIモデルの開発を推進することを目的にしたプロジェクトであるOpen Model Initiativeが発足した。発足メンバーはInvoke、ComfyOrg、Civitai。LAIONもメンバーだったが参加しないことになった。
続報で新たなメンバーが発表され、その中にはPony Diffusionの開発者であるAstraliteHeart氏もいる。

発表：https://www.reddit.com/r/StableDiffusion/comments/1do5gvz/the_open_model_initiative_invoke_comfy_org/
続報：https://www.reddit.com/r/StableDiffusion/comments/1dp2as9/update_and_faq_on_the_open_model_initiative_your/

**2024-06-20 スレ発の手書きフォントが公開される
購入(500円)：https://tiananmen-square.booth.pm/items/5848321
現在はmegaのダウンロードリンクは削除されておりboothでの有料販売となっています。

https://fate.5ch.net/test/read.cgi/liveuranus/1718722445/774
=|BOX|
774: 警備員[Lv.42] (ﾜｯﾁｮｲ 1acc-Fyfa) sage 2024/06/20(木) 22:40:00.63 ID:1zaStuBA0 
https://mega.nz/file/gJ1DmS5b#s5FpmhxfKujG4ST8hKQ_hN8UTJGJfvuXybWoOXc9ufY

自作の手描き文字フォントを公開するで
インスコしたらフォント名は「そこになければない」で出てくるはずや
自分が使うために制作したフォントやからそう大したモンでもないからそこは堪忍やで
ひらがな、カタカナのみ対応
テンキーに「あ」「は」「ん」のバリエーション
+-*/にハート
小文字英aiueoに濁音つきのアイウエオ
https://i.imgur.com/ajoC51a.jpeg
||=
https://fate.5ch.net/test/read.cgi/liveuranus/1718722445/776
=|BOX|
776: 警備員[Lv.42] (ﾜｯﾁｮｲ 1acc-Fyfa) sage 2024/06/20(木) 22:44:28.07 ID:1zaStuBA0 
>>774
商用利用OKやから基本好きに使ってくれてええで。
フォント自体の再配布や販売のみ禁止でたのむで
このフォントが売りに出されるときはワイが売るときだけや
||=
https://fate.5ch.net/test/read.cgi/liveuranus/1718944727/158
=|BOX|
158: 警備員[Lv.43] (ﾜｯﾁｮｲ 1a56-Fyfa) sage 2024/06/21(金) 22:07:34.16 ID:iyTJupHe0 
https://i.imgur.com/iSzRGU4.jpeg

https://tiananmen-square.booth.pm/items/5848321

自作手描きフォント、
伸ばし棒とかハートマークとか縦書きで横になる文字をちょっと調整したから
改めておいておくで。

しばらくしたら有料にするかもしれんでそれより前にダウンロードしておいてな
||=

**2024-06-19 ComfyUI、独立した団体を設立すると宣言
当該ポスト：https://x.com/ComfyUI/status/1803109283263029616
公式サイト：https://www.comfy.org/

ComfyUIの作者であるcomfyanonymous氏はStabilityAIを退社、SwarmUIの作者のmcmonkey4eva氏などとともに「Comfy Org」を設立した。オープンソースのAIツールを発展させ民主化することを目標としている。
**2024-06-18 CivitaiでSD3モデルおよび派生データの公開が一時停止
SD3に関するライセンス(特に商用ライセンスの範囲)が不明瞭なことから、将来的なモデルの保全やライセンス料請求の有無などの安全を確認できるまで、
CivitaiでSD3に関するモデル及び派生データ(LoraやControlNetなどのSD3をベースにした学習結果も含む)の公開が一時的に停止された。
https://civitai.com/articles/5732
もしすでにSD3に関する学習を計画している人は、本項目記載時点においてCivitaiで公開できないので要注意

**2024-06-13 Ponyは7の前に6.9を作ることに
SD3をベースにPony Diffusion V7を作る予定だったが、
SD3の商用ライセンスが曖昧なことなどを理由に、SDXLがベースのV6.9を作ると発表した。
詳しくは　https://civitai.com/articles/5671/towards-pony-diffusion-v7-i-mean-v69
//6月13日時点の状況を説明したものであることに注意。

//Pony Diffusionの作者は情勢を考慮して、予定していたSD3での学習を取りやめ、改めてXLでの新バージョンを作ることを発表した。
//https://civitai.com/articles/5671/towards-pony-diffusion-v7-i-mean-v69

//%%これを機に、PixArt SigmaやLumina-T2Xなど他の画像AIモデルを活用する提案もなされている模様。%%
//%%-PixArt Sigma%%
//%%https://github.com/PixArt-alpha/PixArt-sigma%%
//%%-Lumina-T2X%%
//%%https://github.com/Alpha-VLLM/Lumina-T2X%%
//
**2024-06-12 Stable Diffusion 3が一般公開
リポジトリ: https://huggingface.co/stabilityai/stable-diffusion-3-medium
ブログ: https://ja.stability.ai/blog/stable-diffusion-3-medium
デモページ：https://huggingface.co/spaces/stabilityai/stable-diffusion-3-medium
StabilityAIが開発するStable Diffusionの最新版が公開された。今回公開されたのはパラメータ数20億のMedium。
従来のSDより破綻が減少し、プロンプトへの忠実度が改善した。また文字を正しく生成できるようになった。
現在対応しているWebUIはComfyUIと1111のwebui。またモデルのダウンロードにはHuggingfaceのユーザー登録が必要。

//性能について書かれていたがお気持ちだったので削除

-''現時点での最も簡単なローカル導入方法''
ディレクトリからsd3_medium_incl_clips_t5xxlfp8.safetensors（VRAM8GBモデル）をダウンロードし、ComfyUIのcheckpointに入れる。
「comfy_example_workflows」からサンプルワークフローの「sd3_medium_example_workflow_basic.json」をダウンロードし、ComfyUIで読み込む。
ワークフローの「TripleClipLoader」の接続を外し、「LoadCheckpoint」（モデル選択欄）から直接「ClipTextEncode」（プロンプト入力欄）にClipの出力を繋ぎなおす。
**2024-06-10 ComfyUIのカスタムノード「Comfy_LLMVISION」にキーロガーが仕込まれていたとの報告

詳細は[[画像生成ソフトウェア「ComfyUI」のノードにキーロガーが仕込まれていたことが発覚、クレジットカード情報やパスワードなど全ての入力が筒抜けに - GIGAZINE>https://gigazine.net/news/20240611-comfyui-llmvision-malware/]]などを参照のこと。

**2024-06-09 Forgeが実験的リポジトリに変更されるとのアナウンス

https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/801

（以下は機械翻訳、強調は引用者による）

====
フォージユーザーの皆さん、

[[今日、アップストリーム sd-webui>https://github.com/AUTOMATIC1111/stable-diffusion-webui]]の開発ブランチでは、パフォーマンスに関する多くの進捗が更新されました。以前のボトルネックの多くは解決されるはずです。[[ここ>https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/166]]で説明したように、大多数のユーザーにはアップストリーム webui に戻すことをお勧めします (webui の開発ブランチを直接使用するか、開発ブランチがメインにマージされるまで待機します)。

同時に、Forge の多くの機能 (unet-patcher や最新のメモリ管理など) は、現在の WebUI のエコシステムに実装するにはコストがかかりすぎると考えられています。

その後、Forge は、主に統合コストのかかる機能をテストするための実験的なリポジトリになります。Gradio 4 で実験し、LRU プロセス スケジューリングと pickle ベースのプロセス通信に基づく huggingface space のゼロ GPU メモリ管理のローカル GPU バージョンの実装を、次のバージョンの Forge に追加します。これにより、Forge に「Forge Space」(Gradio 4 SDK @spaces.GPU 名前空間に基づく) という新しいタブと、「LLM」という別のタブが追加されます。

''これらのアップデートにより、ほぼすべての拡張機能が壊れる可能性があるため、実稼働環境のすべてのユーザーには、日常使用ではアップストリームの WebUI に戻すことをお勧めします。''

gradio の LLM インターフェイスとストリーミング システム、イメージ エディターとディスプレイにおける最近の進歩、および Gradio SDK のゼロ GPU 計算管理システムのシームレスな統合に関して、アップストリームの検討や適応には Gradio 4 のフィードバックと拡張も必要であるため、少数のユーザーをここに残して Gradio 4 をテストするよう招待します。

最後に、''Forge ユーザーに今すぐファイルのバックアップを取ることを推奨します'' (または、可能であればアップストリームの WebUI に戻すだけです)。このアナウンスに気付かずに誤って Forge を更新した場合、このアナウンス前の最後のコミットは[[29be1da>https://github.com/lllyasviel/stable-diffusion-webui-forge/commit/29be1da7cf2b5dccfc70fbdd33eb35c56a31ffb7]]です。
====

**2024-06-06 シード値の固定とHires.fixやAdetailerのオンを連動させる拡張機能が公開される
https://github.com/Takenoko3333/sd-webui-reuse-seed-plus

開発のいきさつは以下。

[[なんJNVA部★402/260>https://fate.5ch.net/test/read.cgi/liveuranus/1717517250/260]]
=|BOX|
260 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ 6938-l7CW)[sage] 投稿日：2024/06/05(水) 18:28:30.55 ID:4POD0XU60
SDのWebUIでプロンプトいじりながら適当に出力して
良いSEED見つけたら固定してhires.FixとAdetailerのチェック入れてるんやが
毎回外したり付けたりSEED固定したりランダムにするのが面倒なんやが
ボタン一発でやる方法とかない？
||=

[[なんJNVA部★402/631>https://fate.5ch.net/test/read.cgi/liveuranus/1717517250/631]]
=|BOX|
631 名前： 警備員[Lv.30] (ﾜｯﾁｮｲ 4ac3-M/1B)[sage] 投稿日：2024/06/06(木) 15:44:42.87 ID:UNK+HALX0
>>382
できたで
https://github.com/Takenoko3333/sd-webui-reuse-seed-plus
ワンボタンでやりたかったけどHires.fixの挙動が複雑だったから
連動をチェックボタンで切り替える方式にした
詳しくはgithubの説明を読んでくれ
連動の組み合わせは多岐に渡るしワンボタン化等追々改修していく予定
リクエストがあればどうぞ
||=

続いて、[[生成ボタンを分割して&#127922;、&#9851;、+1ボタンを追加するJavaScript>https://seesaawiki.jp/nai_ch/d/%b5%a1%c7%bd%a4%c4%a4%ad%a4%ce%c0%b8%c0%ae%a5%dc%a5%bf%a5%f3%a4%f2%c4%c9%b2%c3%a4%b9%a4%eb%ca%fd%cb%a1]]を機能拡張化するリクエストが出された。

[[なんJNVA部★403/177>https://fate.5ch.net/test/read.cgi/liveuranus/1717745571/177]]
=|BOX|
177 名前：今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ 86a4-6Hk5)[] 投稿日：2024/06/07(金) 22:16:52.73 ID:vd08XaSL0
>>146
その勢いでこれも拡張機能にしてほしい
https://seesaawiki.jp/nai_ch/d/%b5%a1%c7%bd%a4%c4%a4%ad%a4%ce%c0%b8%c0%ae%a5%dc%a5%bf%a5%f3%a4%f2%c4%c9%b2%c3%a4%b9%a4%eb%ca%fd%cb%a1
ビッグウェーブが来ているわけじゃ全然ないけど
||=

[[なんJNVA部★403/523>https://fate.5ch.net/test/read.cgi/liveuranus/1717745571/523]]
=|BOX|
523 名前： 警備員[Lv.32] (ﾜｯﾁｮｲ 4ac3-M/1B)[sage] 投稿日：2024/06/08(土) 22:47:02.79 ID:t6FS3GUu0
sd-webui-reuse-seed-plus に機能を追加しました！（v0.2.0）
https://github.com/Takenoko3333/sd-webui-reuse-seed-plus
txt2img, img2img の画面に三つの機能付き生成ボタンを追加します。
Hires.fix のオン/オフに連動して他の機能のオン/オフを切り替えます。
https://files.catbox.moe/13c29a.png https://files.catbox.moe/pnm6wi.png

生成ボタンについて
リクエストに応じて過去スレで紹介されていたブックマークレットを改修して機能拡張に組み込みました。
||=
https://files.catbox.moe/13c29a.png https://files.catbox.moe/pnm6wi.png
**2024-06-05 謎漫画が流行する
Animagine3.1に現場猫LoRAを組み合わせ、コマ割りされたマンガのような画像を出力するのが流行。「謎漫画」と呼ばれた。
-現場猫LoRA https://civitai.com/models/350606/shigotonekogenbaneko-style-sdxl-or
--Pony用 https://civitai.com/models/502133/shigotonekogenbaneko-style-ponyor

[[なんJNVA部★402/252>https://fate.5ch.net/test/read.cgi/liveuranus/1717517250/252]]
====
252 名前： 警備員[Lv.34] (ﾜｯﾁｮｲ beee-WQ8n)[] 投稿日：2024/06/05(水) 17:54:13.15 ID:xEbGq8Wl0
謎まんが
&ref(https://files.catbox.moe/y8kymd.png,350) &ref(https://files.catbox.moe/7o22ay.png,350)

　>>115
そやでー、猫loraのウェイト上げると猫寄り、下げるとキャラ寄り
プロンプト入ってるからよかったら好きなキャラでどうぞやで
ワイこの2日、AIの狂気ネタにSAN値削られてゼロなんで
もうロリ幼女作成に戻るわ・・・
====

補助スクリプトや作り方など詳しい情報は[[謎漫画>nazomanga]]を参照のこと。
**2024-06-03 SD3のリリース日発表
%%https://x.com/StabilityAI/status/1797462536117444794%%
%%Stable Diffusion 3の一般公開が6月12日（米国時間）になることが発表された。%%
%%まずはパラメータ数が少ない軽量モデルをリリースし、次いで重量モデルもリリースしていく予定だという。%%
6/13追記：日本時間の6月12日午後10時ごろに一般公開された。

%%https://civitai.com/articles/5069%%
%%Pony Diffusionも次期バージョンのSD3ベースでの学習に向けて準備を進めているという。%%
6/13追記：ライセンスに不明な点が多いためSD3での学習は当分見送るらしい。
**2024-05-31 Omostが公開される

ControlNetやFooocus、Forgeの開発で知られるlllyasviel氏が対話型AIを用いて画像を生成する「Omost」を公開した。

https://github.com/lllyasviel/Omost

PCにインストールしなくても、huggingface上のデモページで試すこともできる。

https://huggingface.co/spaces/lllyasviel/Omost

**2024-05-31 画像からプロンプトを推測するツールなどが公開される

なんJNVA部★400 
https://fate.5ch.net/test/read.cgi/liveuranus/1716953974/544

-手持ちの画像からプロンプトを推測するツール https://huggingface.co/spaces/John6666/wd-tagger-transformers
-上のに加えてエロプロンプトを生成するツール https://huggingface.co/spaces/John6666/danbooru-tags-transformer-v2-with-wd-tagger
-普通のDanbooruタグをポニー用のe621タグに変換するツール https://huggingface.co/spaces/John6666/danbooru-to-e621

いずれもインストールは必要なく、huggingfaceのスペース上で利用できる。

「[[適当にパクって改造したもんなんで誰でも好きに適当にパクって改造したってやー>https://fate.5ch.net/test/read.cgi/liveuranus/1716953974/551]]」とのこと。

**2024-05-19 3x3x3mixXLが公開される
https://civitai.com/models/464044

Pony系列のモデルが弱いとされる背景の描き込みが強化されているのが特徴。

https://fate.5ch.net/test/read.cgi/liveuranus/1716088224/204

=|BOX|
3x3x3mixXL作成してみたンゴ
typeA~C混ぜてみたんやが正直色んな要素が薄まってごちゃまぜになっとるから却って使いにくいかもしれん…
あとマージを繰り返した代償か全身入る構図だと顔が崩れやすいのでADtailerでつかったほうがいいかもやで！
||=

**2024-05-12 ebara_pony_2が公開される
https://huggingface.co/tsukihara/xl_model

https://fate.5ch.net/test/read.cgi/liveuranus/1715346628/625

=|BOX|
625: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 6106-txKt) sage 2024/05/12(日) 17:25:40.46 ID:jCfcGQrA0 
https://files.catbox.moe/mil0up.jpgし
https://huggingface.co/tsukihara/xl_model
タレ目抑えたモデルわよ
ちょっとロリすぎるかもしれんけどまあええかで公開わよ
||=

変更点については「まぁ強いて言うなら構図…？わからんワイは雰囲気でマージしとる」「1.5のときみたいに「バージョンアップ！」って訳じゃなくて単に絵柄が違うって感じ」とも。（ https://fate.5ch.net/test/read.cgi/liveuranus/1715346628/642 ）

翌日2.1が公開された。「肌が流石に眩しすぎたので若干オリジナルponyに近くした。自分らで好きに調整してくんろ」とのこと。
**2024-05-08 URLを含む書き込みで「もう余所でやってください。」と言われるケースが続出

=||
一定の長さ以上の文章
URL
||=
だと「もう余所でやってください。」になり、
=||
URL
文章
||=
ならば書き込めるとの報告が相次いだ。

**2024-05-08 ic-lightが公開される

ControlNetやFooocus、Forgeの開発で知られるlllyasviel氏が画像のライティングを変更する[[ic-light>https://github.com/lllyasviel/IC-Light]]を公開した。

**2024-04-27 cnlllite-anystyleが流行する
4/22に公開された、画像の構図を維持したまま衣装やキャラなど他の要素を変更できるControlnetモデル、cnlllite-anystyleが流行した。
詳しくは[[ControlNet>ControlNet]]をご覧ください

**2024-04-23 Hyper-SD公開
https://hyper-sd.github.io/
LCMやSDXL-Lightningのような低STEPで生成を完了する技術に、新たな手法としてHyper-SDが公開された
上述の既存手法よりも生成物の精度が良いとされ、実際にスレ★386でも使用された画像が貼られているので参考にすると良い
https://fate.5ch.net/test/read.cgi/liveuranus/1713700458/

導入方法は、公式サイトからリンクされているHuggingFaceでLoRAとしてダウンロードできる
SD1.5用とSDXL用があるので、用途に合わせてダウンロードする
使用時は、LCM LoRAと同じようにプロンプト内で呼び出せば良い

設定例 Hyper-SDXL-8steps-lora.safetensorsの場合
ステップ:8　サンプリング:Euler a  SGM Uniform(Uniformでもいける)　CFG:Animagine系は1〜2、Pony系は3〜3.5くらい

※注意 SDXL用のsafetensorが誤ってSD1.5用として内部に記載されているため、WebUIデフォルト設定でSDXLモデルを読み込んでいるとLoRAリストに表示されない
　設定からExtra Networks(追加のネットワーク)ページにあるAlways show all networks on the Lora page(otherwise, those detected as for incompatible version of Stable Diffusion will be hidden)にチェックを入れると表示されるので、LoRAのスパナアイコンから設定をSDXLに変更すると良い

***2024/5/1追記 CFGスケール5〜8に対応したモデル公開
4/30に、CFGスケール5〜8に対応したモデルが公開された。これを使用すると、HyperSD使用時と不使用時でCFGスケールを調整する必要が無くなる。

**2024-04-18 Stable Diffusion 3のAPIが公開される
https://ja.stability.ai/blog/stable-diffusion-3-api
現時点では有料。
早速課金して試した人もいるが「あまりクオリティの向上は感じられない」とのこと。
ただし公開されたのは開発途上のモデルとの情報もあり、現時点でSD3の実力の明確な評価を下せる段階にはない。

**2024-04-16 Adobe Premiere ProへのSoraの実装が発表
https://news.adobe.com/news/news-details/2024/Adobe-previews-breakthrough-AI-innovations-to-advance-professional-video-workflows-within-Adobe-Premiere-Pro/
https://gigazine.net/news/20240416-adobe-premiere-pro-with-ai-firefly/
動画編集ソフト「Adobe Premiere Pro」に、「Sora」をはじめとする複数の動画生成AIモデルが2024年後半をめどに実装予定であることが発表された。
今後ますます一般人も高性能な動画AIを使えるようになっていくことが期待される。

**2024-04-12 なんJNVA部★382 どんぐりシステム有効化される
かねてよりスクリプト荒らしに見舞われていた5chで、その対策として開発されたどんぐりシステムが、本スレ382で強制有効化された。
ただし、これにより未対応ブラウザ民がスレに書き込めなくなる問題が発生するため、今後も有効化を続けるかどうかは議論が必要である。
どのくらい書き込めないユーザーがいるか把握のためにも、該当者はテンプレの避難所に報告してほしい。

**2024-03-23 Stability AIの主要メンバーが退社
https://stability.ai/news/stabilityai-announcement
CEOのEmad Mostaque氏をはじめとする従来のStability AIの開発メンバーの大部分が退社していることが明らかになった。
%%これによりSDのサポート体制やSD3のリリースに影響が生じるかどうかは現時点では不明。%%
SD3がオープンソースでリリースされることは確定している模様。
**2024-03-18 Animagine XL 3.1がリリース
https://huggingface.co/cagliostrolab/animagine-xl-3.1
https://cagliostrolab.net/posts/animagine-xl-v31-release
Linaqurf氏らがAnimagine XL 3.0の後継の「Animagine XL 3.1」を公開した。
3.0で出なかった多くのアニメキャラが出せるようになった。
Quality tagsの仕様が変更されたことに注意。Aesthetic Tagsも追加された。
-参考：[[animagine31tips]]
**2024-03-14 釈迦に説法構文

初出は以下のスレ

なんJNVA部★361
https://fate.5ch.net/test/read.cgi/liveuranus/1710310864/

581: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 12e8-xhpr) sage 2024/03/14(木) 09:20:02.25 ''&color(#ff0000){ID:QawQpn3/0}'' 
RTX 2000 Adaが販売されるらしいけどこのスレ的にはどうなんや
こいつもPCIe4x8らしいからRTX4060 16GBのちょっと上っていう感じ？

582: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 7e66-UCxz) sage 2024/03/14(木) 09:26:02.88 ID:Uav7afoj0 
＞＞581
最大消費電力が70WだからガチでAI以外での用途は絶望的だし恐らくパフォーマンスがいいわけでもない
24時間生成し続けるけど電気代が気になるって人じゃなきゃ価値無いんやないか

584: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 12e8-xhpr) sage 2024/03/14(木) 09:29:29.97 ''&color(#ff0000){ID:QawQpn3/0}''
＞＞582
見解サンガツや
つうことは学習ずっと回したい人とか二枚目三枚目を安く積み重ねたい人むけやろかこれ

587: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 2e3e-gl2Z) sage 2024/03/14(木) 09:40:29.78 ID:MzzNXCG/0 
＞＞584
ttps://i.imgur.com/O14NCsP.jpeg
端子構成がこんな感じなあたり、3~4枚の複数モニター環境構築したい人向けというか、それ以外の一般ユーザーにはただただ使いにくいグラボでしかないと思う

591: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 12e8-xhpr) sage 2024/03/14(木) 10:11:45.54 ''&color(#ff0000){ID:QawQpn3/0}''
＞＞587
&size(18){''んなことはわかってる釈迦に説法や''}
Kohakuニキなんかも3090を4積みとかやってるから、学習にマルチGPUって意味あるんかなと思って
推論の場合は別々のインスタンスになってしまうからあまり意味ないのはわかってんやけど

592: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ a2bb-On+R) sage 2024/03/14(木) 10:12:33.69 ID:jyi7Ntuv0 
＞＞591
お前が釈迦だったのか…

594: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 7ef3-OcrC) sage 2024/03/14(木) 10:14:22.42 ID:FJxL1hfC0 
釈迦に説法を自分側に使う人初めて見たわ


[[釈迦に説法とは>https://dictionary.goo.ne.jp/word/%E9%87%88%E8%BF%A6%E3%81%AB%E8%AA%AC%E6%B3%95/]]
質問の回答を貰っておきながら自分の事を釈迦と称し相手を窘める姿にスレ民の腹筋が悟りを開き、スレは一躍釈迦ブームとなった。
&size(9){ミームとして面白いのは確かだが、元ネタを知らないとただただ失礼なだけである。用法用量には注意しよう}

**2024-03-13 Animagineでも埋め込みタグらしき挙動が判明
Animagineでも、Ponyと同様にランダムな英数字3文字を入れることでスタイルが変化することが判明した。
そもそもXLの標準モデルに備わっている仕様に影響を受けた挙動なのではないかという推測もなされた。

**2024-03-12 本スレに激しいスクリプト爆撃
本スレ(というかなんU)に勢い順で埋め立てるスクリプトが発生し機能不全に陥っている。
以下の避難所に避難しよう。
メイン避難所: https://bbs.3chan.cc/test/read.cgi/liveuranus/1695016803/
サブ避難所: http://bbs.jpnkn.com/test/read.cgi/JNVA/1696574746/

**2024-03-12 Ponyに埋め込まれたタグの研究が盛んに
PonyDiffusionV6XLには、イラストレーターなどのタグが英数字3文字でひそかに埋め込まれていることが判明。なんJNVA部★356 https://fate.5ch.net/test/read.cgi/liveuranus/1710169059/ の中盤からこの話題が急激に増えスレが加速した。スレ終盤にはスクリプト荒らしが来襲しカオスに。
- 参考：[[PonyDiffusionV6XLTips]]
**2024-03-01 sd-forge-layerdiffusionが公開される
LayerDiffusionはControlNetを開発したメンバーが発表したもので、画像生成モデルが透過画像を生成できるようにしたものらしい。
- [[Layer Diffusionについて簡単に解説したツイート>https://twitter.com/sayhi2ai_jp/status/1763032942086099058]]
- [[Layer Diffusionの論文>https://arxiv.org/abs/2402.17113]]
このLayerDiffusionが使える環境がforge向けに公開された（[[sd-forge-layerdiffusion>https://github.com/layerdiffusion/sd-forge-layerdiffusion ]]）
スレ民が使った感想としては以下がよくまとまっているので引用する。
=|BOX|
0027 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ de28-9+AH)
2024/03/02(土) 18:57:42.58ID:g50+9iiw0
まだ試していない奴向けに

・Layer Diffusionは現状ゲームやまんがや雑コラの素材作り向け
・前景とか背景から生成させるのは言うほど解釈力高くない
　どういうのが合うのかとか考えず単純に雑コラしがち
・生成させる場所の指定とかできないので元々あったものを
　完全に隠す感じで生成しがち
・i2iはあと1週間くらいで来るらしい
||=
大きく環境が変化するまで時間はまだ掛かりそうだが、今後に期待したい。
**2024-02-23 sd-danbooru-tags-upsamplerが公開
https://github.com/p1atdev/sd-danbooru-tags-upsampler
LECOの作者であるp1atdev氏が入力されたプロンプトに続くdanbooruタグをLLMが生成するExtensionを公開した。
AIがいい感じにプロンプトを生成してくれるので、プロンプトが思いつかない時やガチャをしたいときに便利。

**2024-02-22 Stable Diffusion 3発表
https://stability.ai/news/stable-diffusion-3
日本語の記事: https://ja.stability.ai/blog/stable-diffusion-3
Stability AIにより、Stable Diffusionの次世代モデル「Stable Diffusion 3」が発表された。
従来のモデルよりもプロンプトの読解力や表現力が大幅に向上し、テキストも正確に出力できるとのこと。
OpenAIの「Sora」と同様の新たな拡散トランスフォーマー技術が使用されているという。
現時点では一般公開されておらず、今後の公開予定や要求スペックなどは不明。
%%Stable Cascadeとは何だったのか%%

**2024-02-22 NovelAIにバイブストランスファー機能が実装される

https://twitter.com/novelaiofficial/status/1760394681274245241

元絵の要素を持つ別の絵を出力する機能。精度の高さにスレが盛り上がる。
**2024-02-20 ComfyUIがStable Cascadeに対応
https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/
ComfyUIがStable Cascadeに対応したことが発表された。
CascadeのモデルをCheckpointフォルダに入れるだけで動作するとのこと。
本スレではVRAM8GBでも動作したことが報告されている。

**2024-02-17 pixivでのAI画像BAN報告相次ぐ
pixivにR18のAI画像を上げたところBANされたことが本スレで相次いで報告される。
利用規約で禁止されている実写ポルノ、他者の偽装、他サイトなどの誘導に引っかかっていると推測されているが詳細は不明。
%%今後はpixivにAI画像を上げるのは避けた方が良いだろう。%%
手描き絵師のBAN報告も多数あるため、最早pixiv運営にしか本当のところはわからない。

**2024-02-16 動画生成AI「Sora」発表
https://openai.com/sora
OpenAIにより動画生成AI「Sora」が発表された。
プロンプトから最長1分間の高解像度動画を生成可能であり、複雑なプロンプトにも対応する。
疑似的な物理シミュレーションが行われているとのことで、従来の生成AIから飛躍的に性能が向上したリアルな映像が話題となった。
なお現時点ではあくまでも技術発表でありモデルの一般公開は行われない。

**2024-02-13 Stable Cascade公開
https://ja.stability.ai/blog/stable-cascade
https://github.com/Stability-AI/StableCascade
Stability AIにより、新たな画像生成モデル「Stable Cascade」が公開された。
SDXLよりも短時間での生成が可能であり、さらにプロンプトの忠実度や画像の美学的品質も向上しているという。
ローカルで動かすにはデフォルトで20GBのVRAMを必要とするが、コードを改変することでより少ないVRAMで動作したとの報告もある。
https://note.com/hakomikan/n/n75f0ee78abf9

**2024-02-12 ZLUDAがリリース
RadeonでCUDAを動かせるようにするラッパーソフトウェアZLUDAがGitHubで突如リリースされた。
https://github.com/vosen/ZLUDA/
元々はAMDで開発していたがこれが流行ると益々CUDAでええやんとなってしまうためプロジェクトが没になり作者が公開するに至った（AMDは2023年10月にnod.ai SHARKを買収している）。
性能としては[[GeekbenchをOpenCL版で動かすよりもほとんど性能が上がる（最大75.34％アップ）>https://github.com/vosen/ZLUDA/raw/master/geekbench.svg]]など、ただ単にソフト互換性があるだけではなく、パフォーマンスメリットまである事が判明した。

2024年6月1日現在、[[Stable Diffusion WebUI AMDGPU（旧Stable Diffusion WebUI DirectML）>https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu]]の--use-zludaオプションや、[[ComfyUIのZLUDAフォーク版>https://github.com/patientx/ComfyUI-Zluda]]を使う事でRadeonでもStable Diffusion系を高速に扱う事が出来るようになっている。

**2024-02-06 stable-diffusion-webui-forgeリリース
ControlNetの作者lllyasvielによる、WebUIのリファクタリング版がリリースされた
https://github.com/lllyasviel/stable-diffusion-webui-forge
低VRAM環境での高速化や使用メモリ削減が見込めるものの、一部Extensionがまだ動かないらしいので上記Githubを要参照

Githubより
 オリジナルのWebUI（1024pxでのSDXL推論）と比較すると、以下のようなスピードアップが期待できます：
-8GB vramのような一般的なGPUを使用する場合、推論速度（it/s）が約30〜45%向上し、GPUメモリピーク（タスクマネージャ）が約700MBから1.3GBに減少し、最大拡散解像度（OOM：VRAM不足…Out Of Memoryしない）が約2倍から3倍に増加し、最大拡散バッチサイズ（OOMしない）が約4倍から6倍に増加します。
-6GB vramのような強力でないGPUを使用する場合、推論速度(it/s)は約60〜75%向上し、GPUメモリピーク(タスクマネージャ)は約800MBから1.5GBに減少し、最大拡散解像度(OOMしない)は約3倍、最大拡散バッチサイズ(OOMしない)は約4倍に増加します。
-24GBのvramを持つ4090のような強力なGPUを使用する場合、推論速度（it/s）が約3〜6%高速化し、GPUメモリピーク（タスクマネージャ）が約1GBから1.4GBに低下し、最大拡散解像度（OOMしない）が約1.6倍になり、最大拡散バッチサイズ（OOMしない）が約2倍になります。
-SDXLにControlNetを使用する場合、ControlNetの最大カウント数（OOMしない）は約2倍になり、SDXL+ControlNetの速度は約30〜45%速くなります。


NVAスレのみなさまの喜びの声
=|BOX|
なんJNVA部★328
 https://fate.5ch.net/test/read.cgi/liveuranus/1707027741/994
 994: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ b73c-jSnV) sage 2024/02/06(火) 13:01:10.84 ID:73PRlTFt0 
 A1111の方は最新やなく1.6.0やがForgeと比較したで
 環境は5900X, RTS4070tis (PL70%)
 魔人の1024x1024 step30を2倍にhiresした結果や
 A1111：https://litter.catbox.moe/xmggsd.png
 Forge：https://litter.catbox.moe/sozkxc.png
 
 使用メモリ量が4GB以上削減されとる上に速度も30秒以上改善されとる
 hiresも速くてこれはすごいわ
 動かん拡張があるらしいのがネックやが、正直適当にポン出しするならComfyUIよりこっちの方がええな
 https://litter.catbox.moe/nt6n0p.jpg

なんJNVA部★329 
 116: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ d7d4-KLri) sage 2024/02/06(火) 15:08:10.66 ID:+EIplyW30 
 4080 VRAM16GBでforgeお試し
 SDXL 1024*1536からの2倍hiresで2048x3072行けて感動した.
 ただhiresなしだとそこまで体感変わらないのと、hiresありでも12GBくらいしかVRAM使ってないのでそこは勿体ないかな. たぶん12GB勢でも2倍行ける
 lora-block-weightはエラー出ないけど効いてないみたいだわ

 132: 今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった(ﾜｯﾁｮｲ 9f2c-by7P) sage 2024/02/06(火) 15:29:23.02 ID:4ViKf5KT0 
 3060ti8Gでも832*1216のhires*2が2分でいけるね
 革命ですわ
||=

**2024-01-19 Pony Diffusion V6 XLが話題になる
https://civitai.com/models/257749/pony-diffusion-v6-xl
スレがAnimagine XL 3.0の話題で持ちきりになる中、数日前にCivitaiにアップロードされていたモデル。
かなり独特なクオリティタグとnegative promptの使用が必要で、上手くチューニングしないとバタ臭い絵が生成されるが、
ハマった場合の質の高さにスレは盛り上がった。特にNSFWが優秀。
loraの学習モデルとしても優秀で、Animagineよりも特殊性癖への理解が強い(小並)
クオリティタグ、negative promptはスレで共有された一例を以下に記すが、civitaiのサンプル等から各々探ってほしい。
そして良いものがあればスレで共有してほしい。

クオリティタグ一例
=|BOX|
0229今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ a7b0-OBZN)
2024/01/26(金) 11:50:33.13ID:HD6WR8TC0
ponyちゃん先頭にこれいれとけばええやろ感がすごい
score_9, score_8_up, score_7_up, BREAK source_anime, rating_explicit, best quality, masterpiece, uncensored, 1girl,
||=

negative prompt一例(姫騎士ニキ)

=|BOX|
0077今、天王星のwiki見てきたら軌道傾斜角(i) が0.774°だった (ﾜｯﾁｮｲ 5f14-zQB7)
2024/01/25(木) 22:47:04.32ID:qJvUoh9O0
>>75
キャラ設定用の奴を抜くと↓やね
Ponyは背景弱いしdepth of fieldとかのネガは抜いて背景ボヤかせたほうがええかもなぁという気もしているわ
censored, mosaic censoring, bar censor ,border, worst quality, low quality, simple background, white background, realistic, sketch ,muscle , normal quality, jpeg artifacts, depth of field, blurry, messy drawing, amateur drawing, lowres, bad anatomy, bad hands, text, error, missing fingers, fewer digits, extra digits,cropped , greyscale, monochrome, source_furry, source_pony, source_cartoon, comic ,source filmmaker,video ,3d
||=

参照：[[PonyDiffusionV6XLTips]]


**2024-01-11 Animagine XL 3.0が公開
https://huggingface.co/cagliostrolab/animagine-xl-3.0
https://cagliostrolab.net/posts/animagine-xl-v3-release/
Linaqurf氏らがSDXLベースのアニメモデル「Animagine XL 3.0」を公開した。
NovelAI V3に迫る性能を誇り、Quality TagsなどもありNAI3に近い感覚で使用できるかも。
これでも[[sd-scriptsの勾配が同期されない不具合で学習がうまくできてない可能性があり>https://cagliostrolab.net/posts/animagine-xl-v3-release#uncontrollable]]、今後の更なる進化に期待できる。

参照：[[AnimagineXL3.0tips]]















































































































