#contents
* 概要
Low-rank Adaptation for Fast Text-to-Image Diffusion Fine-tuning
Dreamboothで広まった学習法。小さくて速いやつ。''作成方法はいろいろある。''
[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/IgjGWbu1Yn.png,400)>https://image02.seesaawiki.jp/n/h/nai_ch/IgjGWbu1Yn.png]]
他の学習法とどう違うねん？　reddit民によればこんな感じのイメージらしい。
https://www.reddit.com/r/StableDiffusion/comments/10cgxrx/wellresearched_comparison_of_training_techniques/
VRAMが少なくても学習可能なkohya_ss版sd-scripts登場以来、sd-scriptsが主流となっている。
このページではsd-scripts関連の情報について雑に書いてある

*参考資料
LoRA Training Guide　https://rentry.org/lora_train
- 4chan有志によるLoRAトレーニング法ガイド（英語）
LoRA 学習メモ　https://rentry.co/i5ynb
- スレ住民によるLain・よしなが先生・野原ひろしLoRA作成者によるLoRAガイド（日本語）
ソウリンちゃんLoRAの作成記録 https://rentry.co/sourin_chan
- スレ住民によるマルゼン式(ふたば有志のタグ付け手法の1つ)で作成したLoRA作成記録（日本語）
Genshin Impact LoRA作成メモ https://rentry.org/genshin_lora
- スレ住民によるkohya-ss氏制作のSDスクリプト(https://github.com/kohya-ss/sd-scripts )で次のキャラのLoRAを作成した。ポップアップ版使用。（日本語）
https://rentry.org/lora-tag-faq
- lora training tagging faq（英語）
https://rentry.org/dsvqnd
- スレ住民によるキャラクター学習のタグ付け一例（日本語）
https://rentry.org/lora_namakubi
- スレ住民によるLoRAでのキャラ学習素材の検証
　
- クラウドGPUを使う場合はリンク先の下の方に Colab Instructions がある
- フォルダ命名方法に気をつけて、自前のファイルは半角スペース一切入れないようにすれば無料Colabでも回せる。頑張れ。

*他人の作ったモデルの導入
[[Loraの使用方法>#apply_lora]]だけやればOK

*インストール、初回セットアップ編
1. エクスプローラーを開き、適当なフォルダ内で右クリック→git bash hereでgitのターミナルを開き、以下のコマンドを実行する
> git clone https://github.com/kohya-ss/sd-scripts.git
2. https://github.com/derrian-distro/LoRA_Easy_Training_Scripts から~~ lora_train_popup.py~~ lora_train_command_line.py~~ run_popup.bat~~ run_command_line.bat~~をダウンロード~~注) 「リンク先をファイルに保存」 ではなく リンク先に飛んでコードの右上の RAW ボタンを押してメモ帳みたいなテキストばっかりの画面を出して 「名前をつけてページを保存」
あるいはCode→Download zipでダウンロードして解凍する(zipに入ってる.gitignore、LICENSE、README.mdは不要)

3. スクリプトを sd-scripts フォルダにコピー

4. README-ja.md に日本語の詳しい説明が書いてあるので読む
=|PERL|
 train_network_README-ja.md: LoRAの学習について
 train_db_README-ja.md:DreamBoothのガイドです。LoRA等の追加ネットワークの学習にも同じ手順を使います。
 fine_tune_README_ja.md:キャプションとか
||=
- 初回セットアップ
--Python初めての場合、PowerShell初めての場合
=|PERL|
PowerShellを管理者として開きます。
「Set-ExecutionPolicy Unrestricted」と入力し、Yと答えます。
管理者のPowerShellを閉じます。
||=
--sd-scripts フォルダで PowerShellかターミナルを開く (Shiftを押しながら右クリック)
--以下のコマンドを順番に入力する(コピペでOK)
=|PERL|
python -m venv venv
.\venv\Scripts\activate
 
pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116
pip install --upgrade -r requirements.txt
pip install -U -I --no-deps https://github.com/C43H66N12O12S2/stable-diffusion-webui/releases/download/f/xformers-0.0.14.dev0-cp310-cp310-win_amd64.whl

cp .\bitsandbytes_windows\*.dll .\venv\Lib\site-packages\bitsandbytes\
cp .\bitsandbytes_windows\cextension.py .\venv\Lib\site-packages\bitsandbytes\cextension.py
cp .\bitsandbytes_windows\main.py .\venv\Lib\site-packages\bitsandbytes\cuda_setup\main.py
 
accelerate config
||=
なお、python -m venv〜の行で「python」とだけ表示された場合、py -m venv〜のようにpythonをpyに変更してください。

--accelerate config のあとに質問が出るので以下のように答える
=|PERL|
- This machine
- No distributed training
- NO
- NO
- NO
- all
- fp16
||=
--初回セットアップ完了

*あかちゃんLoraインストーラー

あかちゃんインストーラーで1111を入れた人向けにPYTHONとGITのPATHをいじってあるやつ
start.batと同じフォルダに入れて実行してください

- コマンドライン用
-- https://github.com/aka7774/elemental_code/blob/main/tools/install_sd_scripts.bat
-- https://github.com/aka7774/elemental_code/blob/main/tools/run_sd_scripts.bat
- ダイアログ用(みかんせい)
-- https://github.com/aka7774/elemental_code/blob/main/tools/install_sd_scripts_easy_training.bat


*学習用画像を置くフォルダの配置
-作者の解説が詳しい [[https://note.com/kohya_ss/n/nba4eceaa4594>>https://note.com/kohya_ss/n/nba4eceaa4594]]

-フォルダの配置例:
[-]
※要するに<繰り返し回数>_<インスタンスプロンプト>にリネームした学習画像データのフォルダは直接指定しないでねって話
例えば↓こういうこと
&#10060;E:\kohya_ss\TrainDatas\001\img\40_kdy 1girl
&#128994;E:\kohya_ss\TrainDatas\001\img
間違うと画像が見つかりませんと怒られる

&ref(https://image02.seesaawiki.jp/n/h/nai_ch/8v9xToIuUR.png)
[END]
-同時に10まで概念を学習できるが、少なくとも1つはフォルダが必要。
-フォルダの名前は <繰り返し回数>_<インスタンスプロンプト>
--<繰り返し回数> 繰り返し回数×学習用画像の枚数を1セット(1 epoch)として学習する 
※注 学習用の画像が50枚ある場合、繰り返し回数を20 にすると 20 x 50 = 1000 ステップ学習する
--<インスタンスプロンプト> クラス 呼び出し用のキーワード クラスは''英単語にない意味のないワード''がよい 
-- 上記kohya氏のサンプルだと「20_sls frog」　脳死で真似するなら 繰り返し回数_意味のないワード WEBUIでプロンプトとして書きたい単語 で設定しておく
--キャプション ファイルは必須です。そうでない場合、LoRA は概念名をキャプションとして使用してトレーニングを行います。
--キャプションについては以下

*キャプション・タグを付ける
作者の詳しい画像付き説明 [[https://github.com/kohya-ss/sd-scripts/blob/main/fine_tune_README_ja.md>>https://github.com/kohya-ss/sd-scripts/blob/main/fine_tune_README_ja.md]]
自動でつけてくれる・・・のではなく一応コマンド打たないとダメらしい。詳しくは上記
**WD1.4 Taggerで作成
先に学習用画像を連番にリネームしておく (01.png, 02.png, ...など)
[+]画像
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/kbCJ6oEi6E.png)
[END]
Web UI に拡張機能 stable-diffusion-webui-wd14-tagger [[https://github.com/toriato/stable-diffusion-webui-wd14-tagger>>https://github.com/toriato/stable-diffusion-webui-wd14-tagger]]をインストール
「Tagger」タブの「Batch from directly」
-入力ファイル:学習用画像の入っているフォルダ
-Interrogator:wd-14convnext
-アンダースコアの代わりにスペースを使用する:オン
-括弧をエスケープする:オン
[+]画像
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/DGlOwfa65F.png)
[END]
Interrogateを押すと学習用画像のフォルダにタグの付いた .txt ファイルが生成される
[+]画像
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/vrFirugtW9.png)
[END]

**キャプションの細かい加工
BooruDatasetTagManager 
https://github.com/starik222/BooruDatasetTagManager 
学習用タグの入力を速く楽にするやつJPG対応版
https://fate.5ch.net/test/read.cgi/liveuranus/1674833233/669
https://uploader.cc/s/5da3211bjrywdkestr26wr4z8v0ch6n233k4aw4qhgj4iag6dh7x2vzyd00y3wws.zip
等のツールで余計なタグを削ったりこだわりのタグ追加をする

- タグは順序に影響を受けるので、一番最初に有効化したいタグを記述する
- taggerで生成したタグの順序のままでも良い。コマンドライン版（lora_train_command_line.py ）の場合、
>        self.shuffle_captions: bool = False  # OPTIONAL, False to ignore ~~
>        self.keep_tokens: Union[int, None] = None  # OPTIONAL, None to ignore ~~
の上の行は True にすればタグの順番は適当にシャッフルして学習する。同時に次の行を 1とか2に設定すれば先頭から指定した数のタグは重要視して残りをシャッフルするように出来る。

**キャプションの付け方・考え方の参考サイト
-[[lora training tagging faq>https://rentry.org/lora-tag-faq]]
英語サイトだがブラウザの翻訳で読もう
-[[キャラクター学習のタグ付け一例>https://rentry.org/dsvqnd]]
実例を挙げての解説

一言で言えば「呼び出しキーワード」＋「学習から外したいもの」をタグに書く

*そもそも学習用画像ってどうやって加工するの
本文で説明している kohya_ss 版のLoRAではトリミングはしなくていい(画像のサイズ別に学習が行われる)
背景の切り抜きは・・・画像の大きさが揃ってないとめんどくさいなどうしよう・・・

キャラの切り出しだけやったら3Dペイント(Win10なら標準、11では標準からリストラされたけどストアにおるで)のマジック選択でええ感じに切り抜きやすいからそこからgimpなりで微調整。
一枚一枚やんのめんどくさい言うんやったらABG_extension言うのが出たんでつこてみたらええんとちゃうかな…？しらんけど

ABG_extension
https://github.com/KutsuyaYuki/ABG_extension
WEBUI公式extension 背景を自動で除去します。アニメ画像用に微調整されたonnxモデルを使用。GPUで動作します。

katanuki
https://github.com/aka7774/sd_katanuki
WEBUI用exntension anime-segmentation を 1111 で使えるようにしたやつ。画像の背景を透過したり白背景にしたりマスク画像を出力する


*正則化画像
キャプションつけたらそのプロンプトで学習させるモデルを使って(適当なネガティブプロンプトをつけて)作成すればいい・・・のだが
詳しくはわからないので誰か書いてクレメンス

**透明のpngを正則化画像にする
Web UI に拡張機能をインストールする [[https://github.com/hunyaramoke/Generate-TransparentIMG>>https://github.com/hunyaramoke/Generate-TransparentIMG]]
Generate TransparentIMG タブで
出力フォルダ:正則化画像の保存先
number_of_generation:作成する枚数
を入力して実行
[+]画像
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/l8x2Fjrdz7.png)
[END]

*学習の手順
**Windowsの場合
***ポップアップ版を使う場合
+ run_popup.batを実行
+ ポップアップにパラメーターを入力する
+ 出来上がりを待つ

***コマンドライン版を使う場合
+ lora_train_command_line.py にパラメーターを書く
[[&ref(https://image01.seesaawiki.jp/n/h/nai_ch/C1tEUj_9N8-s.png)>https://image01.seesaawiki.jp/n/h/nai_ch/C1tEUj_9N8.png]]
+ run_command_line.batを実行
+ 出来上がりを待つ

**Linux(wslやクラウドGPUニキ)の場合

***ポップアップ版を使う場合
+ source venv/bin/activate と入力
+ accelerate launch --num_cpu_threads_per_process 12 lora_train_popup.py と入力
+ ポップアップにパラメーターを入力する
+ 出来上がりを待つ

***コマンドライン版を使う場合
+ lora_train_command_line.py にパラメーターを書く
+ source venv/bin/activate と入力
+ accelerate launch --num_cpu_threads_per_process 12 lora_train_command_line.py　と入力
+ 出来上がりを待つ

**Lora作成手順の画像 (ポップアップ版) 参考程度 (2023-1-16時点)
クリックして展開 アップデートなどで内容は変わる
わからんパラメータが出たらcancelを押しとけばデフォルト値が入る。抜けがあったらスレで質問よろ。
[+]
**ターミナルとかパワーシェルにコマンドを打つか、run_popup.batから実行する
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/yVzXCg9crC.png)
----
**設定ファイルを読み込む?
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/ceVWQWf9Uj.png)
----
**学習元のモデルを選ぶ
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/jxCNF4YB2L.png)
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/6tebwsnoiv.png)
----
**学習用画像のフォルダを選ぶ
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/QsMm7_wdmg.png)
数字_名前 フォルダが見えるように
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/BC_G2nQ6O4.png)
----
**出力先のフォルダを選ぶ
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/d_LHSt9yQv.png)
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/Pm3ilZIP1a.png)
----
**設定をjson形式で保存する?
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/1LwRQpGmTB.png)
----
**正則化画像のあるフォルダを選ぶ 使わないときは「いいえ」
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/KXO6r5NWEn.png)
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/e99bPUOmNk.png)
数字_名前 フォルダが見えるように
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/OYsxnrbqxq.png)
----
**学習を再開する?
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/7Vg8xAPetT.png)
----
**バッチサイズ:一度に何枚処理するか つよつよGPU以外なら1で
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/xcTV3i_Lbh.png)
**何エポック学習させるか: 1エポックは 繰り返し回数(フォルダの先頭の数字)×学習用画像の枚数 ステップ
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/DWVNJ2DpMd.png)
**dimサイズ: みんな128をつかっとるらしい
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/I75XLmK3_t.png)
**アルファ: dimサイズと同じがいいらしい
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/vZVRRTw9ES.png)
**学習の解像度: 512で。RTX4090か超強クラウドGPUなら 768 もいける
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/ttb3qyi0Ya.png)
----
**学習率(Learning Rate): 1e-4 (= 0.0001) これより上げることはあんまりない。 5e-5 (=0.00005)くらいでもいいかも
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/DkV4RQ4ZnK.png)
**スケジューラー: cosine_with_restarts で(よく分からんのでいじらない) 学習率を途中で上げ下げするやり方
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/0jBUxX8eVo.png)
**エポック単位でセーブする?: 2エポック以上学習させるなら
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/M6Jh5Uc7cL.png)
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/ZCqzxdoZWw.png)
----
**キャプションをシャッフルする?: する
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/IEAf9r1tqK.png)
**キャプションの最初のトークンを保持する?: 
キャプションを付けた場合フォルダ名のインスタンスプロンプトが無効になる~~のでキャプションファイルの先頭にインスタンスプロンプトを自分で書く必要がある。~~作者のnoteによると「数値を指定するとキャプションの先頭から、指定した数だけのトークン（カンマ区切りの文字列）をシャッフルせず固定します。」~~キャプションの先頭からカンマ区切りで判定されるので 「zkz, 1girl, condom, ass, solo, black panties, one side up,」なら1でおk
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/kMrIwfMsJE.png)
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/SKOgINqr6w.png)
**warmup ratio 使う?: 学習の最初だけ学習率を下げる機能
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/WaHG0v8I5O.png)
----
**学習の様子 縦横の比率は自動で振り分けしてくれる
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/9VizQs0l1c.png)
**出来上がり
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/y3w3sgkzGd.png)
last.safetensors というファイルができる
このスクリプトではログは一切残らないのでわかりやすい名前にリネームしておく
追加学習するときはこのファイルを指定する
[END]
動画(2023-01-30) すぐにアプデで役に立たなくなるが一応
字幕がめんどいのでそのうちテキストで書く・・・とおもう
わからんパラメータは キャンセルでデフォルト値が入る
[+]
&video(https://image02.seesaawiki.jp/n/h/nai_ch/Kr6H7y5ZXq.webm)&video(https://image01.seesaawiki.jp/n/h/nai_ch/ypwjUxQC6D.webm)
[END]
ポップアップの質問と答えの例
[+]
|英文|訳|バッチファイルのデフォルト値|コメント|
|Do you want to load a json config file?|jsonファイルから前の設定読み込む?||1回設定セーブしとかないとダメ|
|Select your base model|学習元のモデルを選ぶ|||
|Select your image folder|学習用画像のフォルダを選ぶ||数字が先頭についているフォルダの上|
|Select your output folder|(loraの)出力先のフォルダを選ぶ|||
|Do you want to save a json of your configuration?|jsonファイルに設定を保存する?|||
|How many workers do you want? 〜||8|よくわからん|
|Do you want to use regularisation images?|正則化画像を使う?|||
|Select your regularisation folder|正則化画像のフォルダを選ぶ||数字が先頭についているフォルダの上|
|Do you want to continue from an earlier version?|前回のつづきから学習する?||学習を中断した場合続きから再開できる|
|How large is your batch size going to be|バッチサイズをいくつにする?|1|VRAMに余裕があれば2〜8|
|How many epochs do you want?|何エポック学習する?|1|多くすると学習回数が増える|
|What is the dim size you want to use?|loraのランク(network dim)をいくつにする?|128|数が多いほど表現力は増すが時間、メモリ、ファイルサイズも増える 4〜128|
|What Alpha do you want?|alpha値をいくつにする?|network dimと同じ|alpha値を1にした場合学習率をあげたほうがいいらしい|
|How large of a resolution do you want to train at?|学習の解像度をいくつにする?|512|768や1024も指定できるがmax_bucket_resolutionも書き換え必要|
|What learning rate do you want to use?|学習率をいくつにする?|1e-4|alpha値を1にした場合1e-3くらいにあげたほうがいい|
|Do you want to set the text_encoder_lr?|テキストエンコーダの学習率を設定する?||参考値 5e-5|
|Do you want to set the unet_lr?|U-Netの学習率を設定する?||参考値 1e-3|
|Which scheduler do you want?|学習率のスケジューラーをどうする?|cosine_with_restarts|よくわからん"linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"|
|How many times do you want cosine to restart?||1|よくわからん|
|What power do you want to set your polynomial to?||1|よくわからん|
|do you want to save intermediate epochs?|途中のエポックでセーブする?|||
|How often do you want to save epochs?|何エポックごとにセーブする?|1||
|Do you want to shuffle captions?|キャプションをシャッフルする?|||
|Do you want to keep some tokens at the front of your captions?|キャプションの先頭からいくつをシャッフルしないで残す|1|手動でキャプションの先頭に単語を追加した場合その分を残す|
|Do you want to have a warmup ratio?|ウォームアップレシオを使う?||学習率を最初小さくする機能|
|What is the ratio of steps to use as warmup||0.05|学習率を最初からどれくらいのあいだ小さくしておくか 10%とか5%とか|
||エポック毎に出力ファイルの名前を変える?|||
|What do you want your output name to be?|出力ファイルの名前|省略時はオリジナルと一緒||
[END]

*GUI版
lora_train_command_line.py のパラメータ記入の補助ツール
GradioベースのGUI [[https://github.com/bmaltais/kohya_ss>>https://github.com/bmaltais/kohya_ss]]
「Tools」タブにフォルダ配置補助機能がある。
スクリプト版のパラメータの一部は設定出来ないかも？

*WebUIエクステンション版
ddPn08ニキが作ってくれた中身はkohya版 sd-scripts WebUIがでたで。
- エクステンションとしても使えるけどモデル分のVRAM余分に食うからエクステンションで使う場合[[空モデル>https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/908#issuecomment-1256198421]]読み込ましやとのことや
- 使い方は本人のnoteでもぐぐって調べるんやで。検索もでけへんやつはこのWikiにはおらんやろ。
- WebUI割としょっちゅう壊れることやしこいつは単独起動もできるから単独で入れたほうがええんとちゃうかな…？
-- https://github.com/ddPn08/kohya-sd-scripts-webui

*Loraの使用方法&aname(apply_lora)
**使い方その1 WebUIに拡張機能をインストールして使う
-「拡張機能」タブの「URLからインストール」に https://github.com/kohya-ss/sd-webui-additional-networks を入力してインストール )~~
H:\stablediffusion\stable-diffusion-webui\extensions\sd-webui-additional-networks\models\lora フォルダに 出来上がった .pt や .safetensorsをコピーする
(Web UI の 「設定」> 「Additional Nerwork」タブでフォルダの場所を追加出来る)
「txt2img」や「img2img」の画面の左下の方に「Additional Networks ▼」が追加されているので~~Enable を押してmodelを選びmerge倍率をweightのスライダーで調整する

**使い方その2 WebUIの本体機能のみで使う
-H:\stablediffusion\stable-diffusion-webui\models\lora に拾った .pt や .safetensorsをコピーする
「txt2img」や「img2img」の「生成」ボタンの下の花札みたいなマーク(&#127924;)を押すと
Texutual Inversion, Hypernetworks, Lora の3つのタブが出るので Lora を選択して
一覧から選ぶと <lora:ファイル名:倍率>みたいなタグがプロンプトに追加される
最新のLora(0.4.0)で作ったやつも使える






