#contents
* 概要
Low-rank Adaptation for Fast Text-to-Image Diffusion Fine-tuning
簡単に言えば「省メモリで高速に学習できて容量も小さくて済む追加学習法」。''作成方法はいろいろある。''

[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/IgjGWbu1Yn.png,400)>https://image02.seesaawiki.jp/n/h/nai_ch/IgjGWbu1Yn.png]]
他の学習法とどう違うねん？　reddit民によればこんな感じのイメージらしい。
https://www.reddit.com/r/StableDiffusion/comments/10cgxrx/wellresearched_comparison_of_training_techniques/
kohya_ss版sd-scriptsの登場以来、sd-scripts及びそれの派生ツールが人気となっている。
このページではsd-scripts関連の情報について雑に書いてある

*公式情報

**sd-scripts (kohya)
一番はじめは作者が詳しく書いてくれている公式READMEを見よう！話はそれからだ！

- ★公式導入ガイド：sd-scripts/README-ja.md at main &#183; kohya-ss/sd-scripts | https://github.com/kohya-ss/sd-scripts/blob/main/README-ja.md
- ★公式LoRAガイド：sd-scripts/train_network_README-ja.md at main &#183; kohya-ss/sd-scripts | https://github.com/kohya-ss/sd-scripts/blob/main/train_network_README-ja.md
- 公式タグ付けガイド：sd-scripts/fine_tune_README_ja.md at main &#183; kohya-ss/sd-scripts | https://github.com/kohya-ss/sd-scripts/blob/main/fine_tune_README_ja.md
- 公式DreamBoothガイド：sd-scripts/train_db_README-ja.md at main &#183; kohya-ss/sd-scripts | https://github.com/kohya-ss/sd-scripts/blob/main/train_db_README-ja.md



*&aname(loraguide){参考資料・スレ住民による学習ガイド}
LoRA Training Guide　https://rentry.org/lora_train
- 4chan有志によるLoRAトレーニング法ガイド（英語）

LoRA 学習メモ　https://rentry.org/i5ynb
- スレ住民によるLain・よしなが先生・野原ひろしLoRA作成者によるLoRAガイド（日本語）~~更新：2023-02-09｜低リソース学習(NIKKE)、低dim学習(ゆるキャン 犬山あおい)などを追加しました。

ソウリンちゃんLoRAの作成記録 https://rentry.org/sourin_chan
- スレ住民によるマルゼン式(ふたば有志のタグ付け手法の1つ)で作成したLoRA作成記録（日本語）

原神LoRA作成メモ・検証 https://rentry.org/genshin_lora
- スレ住民によるkohya-ss氏制作のSDスクリプト(https://github.com/kohya-ss/sd-scripts )で次のキャラのLoRAを作成した。ポップアップ版使用。（日本語）
-- 02/10:繰り返し数の検証結果を追加。

https://rentry.org/lora-tag-faq
- lora training tagging faq（英語）

https://rentry.org/dsvqnd
- スレ住民によるキャラクター学習のタグ付け一例（日本語）

https://rentry.org/lora_namakubi
- スレ住民によるLoRAでのキャラ学習素材の検証

あかちゃんLoRAノートブック [[kohya_train_network_simple]]
- 全然スレに書き込めないけどけなげに頑張っている
- クラウドGPUを使う場合はリンク先の下の方に Colab Instructions がある
- フォルダ命名方法に気をつけて、自前のファイルは半角スペース一切入れないようにすれば無料Colabでも回せる。頑張れ。

*他人の作ったモデルを使いたい。
最新版のWEBUIが既に使用可能な状態ならセットアップ不要→[[LoRAの使用方法>#apply_lora]]へ

*インストール、初回セットアップ編
**1.LoRA_Easy_Training_Scripts Installers
-https://github.com/derrian-distro/LoRA_Easy_Training_Scripts/
下記の学習の手順ので使うEasyTrainScriptsの人が作った簡易インストールスクリプト
画面右の Releases の下の Installers をクリック > 下にスクロールして install_sd_scripts_v3.bat をダウンロードする
右クリックして 管理者として実行すると
sd-scripts本体とEasy_Train_Scriptsの両方をインストールして、インストール後の初期設定までやってくれる。
うまくいかなかったら [[Gitをインストール>>https://seesaawiki.jp/nai_ch/d/%a5%ed%a1%bc%a5%ab%a5%eb%a4%ce%c6%b3%c6%fe%ca%fd%cb%a1#content_2_2]] してリトライ
わからないとき用画像↓
[+]
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/D_lYBs46Kx.png)
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/lKDWlTHI_G.png)
&video(https://image01.seesaawiki.jp/n/h/nai_ch/9crBKdm8fu.webm)
[END]
**2.あかちゃんLoraインストーラー

あかちゃんインストーラーで1111を入れた人向けにPYTHONとGITのPATHをいじってあるやつ
start.batと同じフォルダに入れて実行してください

- コマンドライン用
-- https://github.com/aka7774/elemental_code/blob/main/tools/install_sd_scripts.bat
-- https://github.com/aka7774/elemental_code/blob/main/tools/run_sd_scripts.bat
- ダイアログ用(みかんせい)
-- https://github.com/aka7774/elemental_code/blob/main/tools/install_sd_scripts_easy_training.bat

**3.GUI
GUIといっても作者のsd-scriptsにパラメータを渡すだけや。性能は変わらん。一部パラメータ非対応のこともある。
[+]
-bmaltais版 GUI
GradioベースのGUI [[https://github.com/bmaltais/kohya_ss>>https://github.com/bmaltais/kohya_ss]]
「Tools」タブにフォルダ配置補助機能がある。
スクリプト版のパラメータの一部は設定出来ないかも？
LoRA_Easy_Training_Scripts にインストールスクリプトがある。

-ddPn08版 GUI - AUTOMATIC1111 SD WebUI エクステンション対応版
WebUIのエクステンションに対応。スタンドアロンで動かすと上記のbmaltais版と似たような感じ
- エクステンションとしても使えるけどモデル分のVRAM余分に食うからエクステンションで使う場合[[空モデル>https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/908#issuecomment-1256198421]]読み込ましやとのことや
- 使い方は本人のnoteでもぐぐって調べるんやで。検索もでけへんやつはこのWikiにはおらんやろ。
- WebUI割としょっちゅう壊れることやしこいつは単独起動もできるから単独で入れたほうがええんとちゃうかな…？
-- https://github.com/ddPn08/kohya-sd-scripts-webui
[END]
**4.その他補助スクリプト
としあきbatや4chan製のスクリプトがある
kohya-ss/sd-scripts を自分でインストールできるなら

*学習用画像を置くフォルダの配置
-作者の解説が詳しい [[https://note.com/kohya_ss/n/nba4eceaa4594>>https://note.com/kohya_ss/n/nba4eceaa4594]]

-フォルダの配置例:
[-]
※要するに<繰り返し回数>_<インスタンスプロンプト>にリネームした学習画像データのフォルダは直接指定しないでねって話
例えば↓こういうこと
&#10060;E:\kohya_ss\TrainDatas\001\img\40_kdy 1girl
&#128994;E:\kohya_ss\TrainDatas\001\img
間違うと画像が見つかりませんと怒られる

&ref(https://image02.seesaawiki.jp/n/h/nai_ch/8v9xToIuUR.png)
[END]
-同時に10まで概念を学習できるが、少なくとも1つはフォルダが必要。
-フォルダの名前は <繰り返し回数>_<インスタンスプロンプト>
--<繰り返し回数> 繰り返し回数×学習用画像の枚数を1セット(1 epoch)として学習する 
※注 学習用の画像が50枚ある場合、繰り返し回数を20 にすると 20 x 50 = 1000 ステップ学習する
--<インスタンスプロンプト> クラス 呼び出し用のキーワード クラスは''英単語にない意味のないワード''がよい 
-- 上記kohya氏のサンプルだと「20_sls frog」　脳死で真似するなら 繰り返し回数_意味のないワード WEBUIでプロンプトとして書きたい単語 で設定しておく
--キャプション ファイルは必須です。そうでない場合、LoRA は概念名をキャプションとして使用してトレーニングを行います。
--キャプションについては以下

*キャプション・タグを付ける
- 作者の詳しい画像付き説明 [[https://github.com/kohya-ss/sd-scripts/blob/main/fine_tune_README_ja.md>>https://github.com/kohya-ss/sd-scripts/blob/main/fine_tune_README_ja.md]]
- 学習用の素材画像それぞれに内容を説明するテキストファイルを作る。このテキストファイルには画像生成時のプロンプトと同じようにタグを記載する。
- テキストエディターやメモ帳で１つずつ作っても良いのだが、WD1.4Tagger等のツールを使えば一気に自動生成できて捗る

**WD1.4 Taggerで作成
先に学習用画像を連番にリネームしておく (01.png, 02.png, ...など)
[+]画像
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/kbCJ6oEi6E.png)
[END]
Web UI に拡張機能 stable-diffusion-webui-wd14-tagger [[https://github.com/toriato/stable-diffusion-webui-wd14-tagger>>https://github.com/toriato/stable-diffusion-webui-wd14-tagger]]をインストール
「Tagger」タブの「Batch from directly」
-入力ファイル:学習用画像の入っているフォルダ
-Interrogator:wd-14convnext
-アンダースコアの代わりにスペースを使用する:オン
-括弧をエスケープする:オン
[+]画像
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/DGlOwfa65F.png)
[END]
Interrogateを押すと学習用画像のフォルダにタグの付いた .txt ファイルが生成される
[+]画像
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/vrFirugtW9.png)
[END]

**キャプション・タグの編集
- タグは順序に影響を受けるので、一番最初に有効化したいタグを記述する
- WD1.4Tagger等で自動生成したファイルには不要なタグが含まれたり誤認識されたタグが記載されたりするので編集する。

- BooruDatasetTagManager https://github.com/starik222/BooruDatasetTagManager 
- 学習用タグの入力を速く楽にするやつ →[[ローカルの「ツール」]] https://uploader.cc/s/rdw0k6qd2766czgdwwwjtn2xtmhiay6c1ky0s7dui4o5yaz0pkgfesef18n9nngm.zip
等の便利なツールを使えば捗る。必要なタグを追加、不要なタグの削除、順序の入れ替え等の編集をやる

- taggerで生成したタグの順序のままでも構わないが、重要なタグだけ各ファイルの先頭の方に記載する。例えばコマンドライン版（lora_train_command_line.py ）の場合、
>        self.shuffle_captions: bool = True  # OPTIONAL, False to ignore ~~
>        self.keep_tokens: Union[int, None] = 3  # OPTIONAL, None to ignore ~~
上記のように設定すれば先頭から3つのタグは順序固定として残りはタグの適当にシャッフルして学習できる。

**キャプションの付け方・考え方の参考サイト
-[[lora training tagging faq>https://rentry.org/lora-tag-faq]]
英語サイトだがブラウザの翻訳で読もう
-[[キャラクター学習のタグ付け一例>https://rentry.org/dsvqnd]]
実例を挙げての解説

一言で言えば「呼び出しキーワード」＋「学習から外したいもの」をタグに書く

*そもそも学習用画像ってどうやって加工するの
- 本文で説明している kohya_ss 版のLoRAではトリミングはしなくていい(画像のサイズ別に学習が行われる)
- 背景の切り抜きは・・・画像の大きさが揃ってないとめんどくさいなどうしよう・・・
- キャラの切り出しだけやったら3Dペイント(Win10なら標準、11では標準からリストラされたけどストアにおるで)のマジック選択でええ感じに切り抜きやすいからそこからgimpなりで微調整。
- 一枚一枚やんのめんどくさい言うんやったらABG_extension言うのが出たんでつこてみたらええんとちゃうかな…？しらんけど

ABG_extension
https://github.com/KutsuyaYuki/ABG_extension
WEBUI公式extension 背景を自動で除去します。アニメ画像用に微調整されたonnxモデルを使用。GPUで動作します。

katanuki
https://github.com/aka7774/sd_katanuki
WEBUI用exntension anime-segmentation を 1111 で使えるようにしたやつ。画像の背景を透過したり白背景にしたりマスク画像を出力する


*正則化画像
- ChatGPTたん曰く「過学習を抑えるためのもの」
- キャプションつけたらそのプロンプトで学習させるモデルを使って(適当なネガティブプロンプトをつけて)作成すればいい・・・のだが詳しくはわからないので誰か書いてクレメンス
- 間違っとる可能性大なのやが、例えばAIちゃんが知らない「鳥獣戯画のカエルちゃん」のイメージを教えるとする。学習用画像には「鳥獣戯画のカエルちゃん」画像を用意する。正則化画像にはありふれた「蛙の画像」を用意する。これでAIちゃんには「鳥獣戯画のカエルちゃん覚えようね！でも正則化画像フォルダにある普通の蛙とかは違うやつやから覚えなくていいよ」という感じで伝わる。イメージを覚えてもらうのに言葉では説明しづらいから画像で説明する感じ？多分。知らんけど。
- 他所のノートブックを利用しているので確かな事は言えないが、正則化画像を同じような画像で学習させすぎると正則化画像につけたクラストークンで正則化画像の内容を生成するようになる。これは上の「普通の蛙は覚えなくていいよ」というよりも、単に「学習画像と正則画像を二つとも学習する」という挙動のように思われる。
- 正則化画像は必須ではないので用意しなくても学習はできる。とりあえず一度学習動かしてみたいとかなら用意しなくてもいい。透明正則化も効果は不明瞭（良い影響があるとしても悪影響がないとも言えない）なので面倒ならやらなくてもいい。


**透明のpngを正則化画像にする
Web UI に拡張機能をインストールする [[https://github.com/hunyaramoke/Generate-TransparentIMG>>https://github.com/hunyaramoke/Generate-TransparentIMG]]
Generate TransparentIMG タブで
出力フォルダ:正則化画像の保存先
number_of_generation:作成する枚数
を入力して実行
[+]画像
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/l8x2Fjrdz7.png)
[END]

*学習の手順
**Windowsの場合
***ポップアップ版を使う場合
+ run_popup.batを実行
+ ポップアップにパラメーターを入力する
+ 出来上がりを待つ

***コマンドライン版を使う場合
1. lora_train_command_line.py にパラメーターを書く
設定を書き込むのはlora_train_command_line.pyの最初の方あたり。学習ベースになるモデル、学習素材フォルダの場所、出力先は必ず設定する。わからんところはそのままにしとく。
記法は以下を参考に、文字列(str)は r"c:\hogehoge"　のように入力、数値(float,int)はそのまま数値を入力、Falseとなっている部分はTrueで有効になる。
以下lora_train_command_line.py冒頭あたりの設定部分の雑な日本語訳
[+]
#include(lora_train_command_line.py)
[END]
2. run_command_line.batを実行
3. 出来上がりを待つ

**Linux(wslやクラウドGPUニキ)の場合

***ポップアップ版を使う場合
+ source venv/bin/activate と入力
+ accelerate launch --num_cpu_threads_per_process 12 lora_train_popup.py と入力
+ ポップアップにパラメーターを入力する
+ 出来上がりを待つ

***コマンドライン版を使う場合
+ lora_train_command_line.py にパラメーターを書く
+ source venv/bin/activate と入力
+ accelerate launch --num_cpu_threads_per_process 12 lora_train_command_line.py　と入力
+ 出来上がりを待つ

**Lora作成手順の画像 (ポップアップ版) 参考程度 (2023-2-21時点)
クリックして展開 アップデートなどで内容は変わる
わからんパラメータが出たらcancelを押しとけばデフォルト値が入る。
[+]
**ターミナルとかパワーシェルにコマンドを打つか、run_popup.batから実行する
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/yVzXCg9crC.png)
----
**設定ファイルを読み込む? (前と同じ設定を使いたければ次でjsonファイルを読み込む)
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/ceVWQWf9Uj.png)
----
**学習元のモデルを選ぶ
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/jxCNF4YB2L.png)
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/6tebwsnoiv.png)
----
**学習用画像のフォルダを選ぶ
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/QsMm7_wdmg.png)
数字_名前 フォルダが見えるように
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/BC_G2nQ6O4.png)
----
**出力先のフォルダを選ぶ
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/d_LHSt9yQv.png)
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/Pm3ilZIP1a.png)
----
**設定をjson形式で保存する? 保存先フォルダを選ぶ
----
**省メモリモード使う? VRAM8GB未満とか1024で学習したいなら「はい」
**optimizerどれにする? デフォルトは8bit_adam 詳しくは作者README
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/YMGOPgwZyO.png)
Stable Diffusion V2のモデルで学習する? 「いいえ」
実写(っぽい)モデルで学習する? 実写風モデルなら「はい」アニメ風モデルなら「いいえ」
----
**正則化画像のあるフォルダを選ぶ 使わないときは「いいえ」
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/KXO6r5NWEn.png)
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/e99bPUOmNk.png)
数字_名前 フォルダが見えるように
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/OYsxnrbqxq.png)
----
**学習を再開する? (以前の続きをやるときはsafetensorファイルなどを次で読み込む)
**学習画像を左右反転して2倍に水増しする? 髪の毛の分け目とかオッドアイが逆になってもいいなら「はい」
----
**バッチサイズ:一度に何枚処理するか VRAM12Gなら4〜6くらいいける(解像度512に限る)で、動かんかったら1で
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/O0bJN0I8s4.png)
**何エポック学習させるか: 1エポックは 繰り返し回数(フォルダの先頭の数字)×学習用画像の枚数 ステップ
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/DWVNJ2DpMd.png)
**dimサイズ: ケモナーは128推奨 デフォルト値は32
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/I75XLmK3_t.png)
**アルファ: dimサイズの半分がデフォルト値
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/vZVRRTw9ES.png)
**学習の解像度: 512が速い, 768ならRTX3060やColabで10000ステップ4~5時間コース
----
**学習率(Learning Rate): 1e-4 (= 0.0001)くらいで。alphaを1にした場合dimの分学習率が割られるらしいので上げ目にする
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/DkV4RQ4ZnK.png)
**テキストエンコーダの学習率:よくわからんときはキャンセルで。学習率の50分の1くらいがいいって言うとる海外ニキもおる
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/I__fvgugVG.png)
**U-Netの学習率:よくわからんときはキャンセルで。
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/I3USsDCepb.png)
この辺の3つの学習率が秘伝のタレ的な事になっとるかも? [[参考資料・スレ住民による学習ガイド>#loraguide]]
----
**スケジューラー: cosine_with_restarts 学習率を途中で上げ下げするやり方。詳しくはぐぐって。
[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/xtBYW757rL-s.png)>https://image02.seesaawiki.jp/n/h/nai_ch/xtBYW757rL.png]]
**この後にcosine with restartの回数を聞かれたりする
**エポック単位でセーブする?: 2エポック以上学習させるなら
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/M6Jh5Uc7cL.png)
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/ZCqzxdoZWw.png)
----
**キャプションをシャッフルする?: する
**キャプションの最初のトークンを保持する?: 
キャプションを付けた場合フォルダ名のインスタンスプロンプトが無効になる~~のでキャプションファイルの先頭にインスタンスプロンプトを自分で書く必要がある。~~作者のnoteによると「数値を指定するとキャプションの先頭から、指定した数だけのトークン（カンマ区切りの文字列）をシャッフルせず固定します。」~~キャプションの先頭からカンマ区切りで判定されるので 「zkz, 1girl, condom, ass, solo, black panties, one side up,」なら1でおk
&ref(https://image02.seesaawiki.jp/n/h/nai_ch/kMrIwfMsJE.png)
**warmup ratio 使う?: 学習の最初だけ学習率をあげる機能
----
**出来上がりのloraファイルの名前変える? 設定しない場合 last.safetensors
[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/6BKI5GGw1y-s.png)>https://image02.seesaawiki.jp/n/h/nai_ch/6BKI5GGw1y.png]]
**メタデータを埋め込む? Addtional Networksで読めるメモを書いてもいい
[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/HtWSYSwelC-s.png)>https://image02.seesaawiki.jp/n/h/nai_ch/HtWSYSwelC.png]]
**U-netかテキストエンコーダどっちか片方だけ学習する? 上級者向けなので「いいえ」
[[&ref(https://image02.seesaawiki.jp/n/h/nai_ch/ehZbMERXmn-s.png)>https://image02.seesaawiki.jp/n/h/nai_ch/ehZbMERXmn.png]]
----
**学習に使ったタグを全部まとめてtxtファイルに保存する? するなら保存場所を選ぶ
**タグの並べ替えする? アルファベット順 書いてある順
**キャプションをわざと抜く? 詳しくは作者README
**Noise offset入れる? よくわかりません デフォルト値は0.1
**画像の拡大をやめる? 小さな画像を無理やり拡大してガビガビにならんようにする
----
**次の学習も仕込む? このあと一連の手順を追記して別の学習を予約できる

----
**学習の様子 縦横の比率は自動で振り分けしてくれる
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/9VizQs0l1c.png)
**出来上がり
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/y3w3sgkzGd.png)
last.safetensors というファイルができる
追加学習するときはこのファイルを指定する
[END]
動画(2023-01-30) すぐにアプデで役に立たなくなるが一応
字幕がめんどいのでそのうちテキストで書く・・・とおもう
わからんパラメータは キャンセルでデフォルト値が入る
[+]
&video(https://image02.seesaawiki.jp/n/h/nai_ch/Kr6H7y5ZXq.webm)&video(https://image01.seesaawiki.jp/n/h/nai_ch/ypwjUxQC6D.webm)
[END]
研究心旺盛ニキはコマンドラインの訳を読むとええで [[lora_train_command_line.py>lora_train_command_line.py]]
//コマンドライン版の説明が詳しいのでコメントアウトしました
//ポップアップの質問と答えの例
//[+]
//|英文|訳|バッチファイルのデフォルト値|コメント|
//|Do you want to load a json config file?|jsonファイルから前の設定読み込む?||1回設定セーブしとかないとダメ|
//|Select your base model|学習元のモデルを選ぶ|||
//|Select your image folder|学習用画像のフォルダを選ぶ||数字が先頭についているフォルダの上|
//|Select your output folder|(loraの)出力先のフォルダを選ぶ|||
//|Do you want to save a json of your configuration?|jsonファイルに設定を保存する?|||
//|How many workers do you want? 〜||8|よくわからん|
//|Do you want to use regularisation images?|正則化画像を使う?|||
//|Select your regularisation folder|正則化画像のフォルダを選ぶ||数字が先頭についているフォルダの上|
//|Do you want to continue from an earlier version?|前回のつづきから学習する?||学習を中断した場合続きから再開できる|
//|How large is your batch size going to be|バッチサイズをいくつにする?|1|VRAMに余裕があれば2〜8|
//|How many epochs do you want?|何エポック学習する?|1|多くすると学習回数が増える|
//|What is the dim size you want to use?|loraのランク(network dim)をいくつにする?|128|数が多いほど表現力は増すが時間、メモリ、ファイルサイズも増える 4〜128|
//|What Alpha do you want?|alpha値をいくつにする?|network dimと同じ|alpha値を1にした場合学習率をあげたほうがいいらしい|
//|How large of a resolution do you want to train at?|学習の解像度をいくつにする?|512|768や1024も指定できるがmax_bucket_resolutionも書き換え必要|
//|What learning rate do you want to use?|学習率をいくつにする?|1e-4|alpha値を1にした場合1e-3くらいにあげたほうがいい|
//|Do you want to set the text_encoder_lr?|テキストエンコーダの学習率を設定する?||参考値 5e-5|
//|Do you want to set the unet_lr?|U-Netの学習率を設定する?||参考値 1e-3|
//|Which scheduler do you want?|学習率のスケジューラーをどうする?|cosine_with_restarts|よくわからん"linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"|
//|How many times do you want cosine to restart?||1|よくわからん|
//|What power do you want to set your polynomial to?||1|よくわからん|
//|do you want to save intermediate epochs?|途中のエポックでセーブする?|||
//|How often do you want to save epochs?|何エポックごとにセーブする?|1||
//|Do you want to shuffle captions?|キャプションをシャッフルする?|||
//|Do you want to keep some tokens at the front of your captions?|キャプションの先頭からいくつをシャッフルしないで残す|1|手動でキャプションの先頭に単語を追加した場合その分を残す|
//|Do you want to have a warmup ratio?|ウォームアップレシオを使う?||学習率を最初小さくする機能|
//|What is the ratio of steps to use as warmup||0.05|学習率を最初からどれくらいのあいだ小さくしておくか 10%とか5%とか|
//||エポック毎に出力ファイルの名前を変える?|||
//|What do you want your output name to be?|出力ファイルの名前|省略時はオリジナルと一緒||
//[END]

*Loraの使用方法&aname(apply_lora)
**使い方その1 WebUIに拡張機能をインストールして使う
-「拡張機能」タブの「URLからインストール」に https://github.com/kohya-ss/sd-webui-additional-networks を入力してインストール )~~
stable-diffusion-webui\extensions\sd-webui-additional-networks\models\lora フォルダに 出来上がった .pt や .safetensorsをコピーする
(Web UI の 「設定」> 「Additional Nerwork」タブでフォルダの場所を追加出来る)
「txt2img」や「img2img」の画面の左下の方に「Additional Networks ▼」が追加されているので~~Enable を押してmodelを選びmerge倍率をweightのスライダーで調整する
[+]わからんとき用画像
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/xl2vcs_kBK.png)
[END]
**使い方その2 WebUIの本体機能のみで使う
-stable-diffusion-webui\models\lora に拾った .pt や .safetensorsをコピーする
「txt2img」や「img2img」の「生成」ボタンの下の花札みたいなマーク(&#127924;)を押すと
Texutual Inversion, Hypernetworks, Lora の3つのタブが出るので Lora を選択して
一覧から選ぶと <lora:ファイル名:倍率>みたいなタグがプロンプトに追加される
むかーしに作られたloraは動かんことがある
[+]わからんとき用画像
&ref(https://image01.seesaawiki.jp/n/h/nai_ch/Gje_zP3vzL.png)
[END]
WebUIや拡張機能の更新で調子悪くてもどっちかでは動くはず
**注意点やで
- 基本的にLoraは元々「DreamBoothみたいに学習した差分ファイルをモデルにマージするための差分パッチみたいなもんとして使う」事が前提で作られとるから、今の個別適用は元々の設計と違う使い方なんや、なんで色々制限事項がある。
-- Loraは''原則「作ったモデルと同じ系統(SD-v1.x系 or SD-v2.x)」でしか適用できへん''で。要するにAnyとかで作ったLoraはWD1.4以降とかには使われへんし、その逆もしかりや。
--- よく似た使い方するHyperNetworkは系統またいでも一応反映はされとるみたいやで？しらんけど。
-- また、Loraを複数1倍で重ねて使うと絵が崩壊しやすくなる。適用したい階層が違う場合、階層適用出来るエクステンションとかでずらしたらええんとちゃうかなしらんけど。
-- 先にも書いた通り基本的に差分パッチみたいなもんやからモデルごとに最適な倍率はちゃうかったりするで。あっちのモデルでは1倍でちょうどよかったんがこっちのモデルでは絵が崩壊するとかも普通にあるで。倍率は適度に変えや。
-- 基本的に配布されとるんはkohya氏による拡張版Loraやけど元々の実装版のLoraもDreamBoothエクステンションとかで作れたりするから作った際にはごっちゃにせんようにな？
---拡張機能の方はkohya氏による拡張版Loraのみが対応や。本体機能の方は元々の実装版でも行けるんとちゃうかな？しらんけど。

