* とある技術部の記録
画像貼れないのでログのコピペだけ。
[+]
意図的に過学習気味DB。一応データセットに酷似していないかは目視で確認したので大丈夫なハズ
データセットは顔15全身25の40枚、20000stepの1.06e-6です

目標を上から
・過学習で完璧に同じものにならない
・コイルをコイルとして出す
・髪の毛の色を一致させる
・髪の毛のリボンの色
・服の色(斜めになってて上が黄色下が黒)
・模様の正確性

でした。模様以外はおおむね成功ですかね&#129300;
DBに限らず追加学習全般で「過学習気味にするのが用途として良い」と言われているのはこのことなんだろうなって

上のDBを「一つの成功例」って表記しているのが「キャラDB、NSFW無し、ポーズほぼ固定」でのものですし

顔髪が再現できてある程度コスプレ、シチュに耐えれば成功だなと思ってます

20枚、20000step、7.2E-07、Apply horizontal Flip無でやったのですけど10000stepだと複雑な服装を再現しづらいけど20000なら高打率で再現したうえでマスピ塗りも脱却できますね。ちょっと制御効きづらいけど
左右反転無しで画像の500〜1000?倍のstep組むのがいいかもしれないけど学習元枚数が100枚とかになってくるとどうなるか不明 

・全身で使えるものとバストアップで使えるものの選別
・Photoshopでちまちまアルファ抜き
・512*512に加工(+白背景にする)

フォトショが断然精度高いんでしたっけ透過させるの、持ってないし妥協してanime-segmentation使ってます
最終的に精度良いのはPhotoshopな気がしますね……PhotoshopでさえAI切り抜きが失敗するのでそれ以外のが精度高いってのはなかなかなさそう

正規化画像があると学習中はその都度正規化のクラス画像との比較が行われて
キャラの持つ際立った特徴を覚えていく
これによって精度の向上に加えて過学習や発散が発生しにくい、とされている

ただ、単に1girlとかpersonみたいなclass wordと同一のプロンプトで用意しても、
こんな感じにそもそも細部の特徴を読み取れないものが多くて
「正規化画像では髪色はこうで、服の模様はこうで..キャラはこれと違ってこうだから...」と学習に寄与する確率が下がる(予想)
だから質の良いセットを用意しない限り、経験上はほぼ無意味か、精度が低下するまである

多分理想としては正規化画像と学習用キャラ画像ともに「顔の細部が見られるもの多め、背景を透過」でやると効率的なんだろうね 

チャレンジの題材として良い気がしてきましたね？
・コイルをコイルとして認識するか
・コイルの精度
・特徴的な洋服の再現度
を確かめられる気がします&#129300;
あとはかわいいからモチベも保てる(重要)

Any+(NAInsfw-NAIsfw) * 0.4（これは別にNAI単体でもAnything単体でもいいんじゃない？）
pndm
10000steps
データセット……白背景顔アップ50枚、白背景全身かバストアップ(画像によりけり)50枚の100枚
正則化画像なし
解像度512
LR1e-6(算出学習率じゃなくて1e-6で良くない？ってなったので1e-6に最近してる)
念のため1000step毎にckpt吐き出し

Don't Cache Latentsオン
Use 8bit Adamオン
Gradient Checkpointingオン
Mixed Precisionをnoからfp16
Apply Horizontal Flipをオフ

でした 

stepは正直一概に言えないかなって最近なってます。コイルと服装の再現に多くのstepがいるだけで本来ならもう少し少なくてもよさそうですね。
ほらこう……シンプルなのだと4000で過学習とかになりそうな予感

顔アップとバストアップってそれぞれ別の画像です？同じ画像で顔だけアップと全体とで2枚作ったりとかしない感じ？
今回は目的として「過学習気味になった時に特定の画像に依らないように」ってのがあったので100枚全部バラバラです

画像加工お役立ち情報(多分)なんですが、縦長の画像を512にするときに一枚目みたいにまっすぐ切れるようなトリミングはお勧めしません。二枚目みたいにすることがお勧めです。
なんでかというと「左右に余白のある画像」として認識しちゃってこんな風に余白を埋めてくることがあるんですよね。体感ですが
あとfull body入れた場合は枠いっぱいではあるけど指定なしの時よかフレームアウトしなくはなってます。真ん中に綺麗に立たせてるので

それにしてもはDBのベンチマークとして滅茶苦茶優秀ですね
左右非対称カラーのデザインと頭のコイルという学習無しでは再現しづらい部分があって
うまくいってないとコイル部分が雑になるからぱっと見で学習精度がわかるし
なによりかわいい(重要) 

ポーズや恰好含めてこの印象のキャラですしね&#129395; 自分も透過綺麗なデータセット作らなきゃ…

これ服装がラバースーツっぽいのevt-v2のせいな気がしてきましたね？Anythingに戻したほうが良さげな気がします
そしてevt-v2はちょいちょいブラックアウトします(evt-v2以外で発生したことは無い)

これは10000stepですが10000stepだとそもそも学習が中途半端だしなぁ
20000stepもやると服と一体で覚えてますね
やっぱりbodypaintは過学習あるあるですよね…
再現度MAXなのも過学習一歩手前だから難しいところ

4000stepくらいのモデルだと衣装をucに突っ込むと割と脱いでくれました
の服装は英単語で定義するのがむずいですね……
DBでもちゃんと特徴をプロンプトで指示するのは効果ありそうですね

4000stepだとそもそものが再現できないんですよね……コイルと服と髪の毛の色がやばいですし
個人的には塗りのマスピ感って(に限らず)1e-6の2000stepの段階で大体消えると思ってるんですよね。そっからは細部を詰めていく印象です
設定も書くか
20000steps
顔15枚バストアップか全身25枚(画像によって良い感じに調整)合計40枚
0.00000108(1.08e-6)
Don't Cache Latents
Use 8bit Adam
Gradient Checkpointing
Apply Horizontal Flipをオフ 

1.08e-6はほんとは30枚2000stepsの算出学習率なんだけど変え忘れました
けど結果的に1e-6でいいんじゃ……？ってなってますデータセットの枚数に限らず
Apply Horizontal Flipの無効化は左右反転したらコイルの色まざるじゃんね？ってことでオフにしました。規定値ではオンです

デフォルトでApply Horizontal FlipONなの今日一番のショック……
(これは可能性の話ですが、データセットの枚数って勝手にフリップしていたので2倍で計算しなきゃいけなかったり)
Joe版で反転画像入れると顔崩れやすくて以降つかわないようにしてたのに&#128557;
1epochあたりのsteps数も変わってきますね…

個人的にも今のところ上手く行ってるデータセットは顔アップorバストアップ+全身か上下2分割なのでやっぱりこの辺りが安定な気がしますねー
そうしたら次はデータセットの数を増やして特定の絵により過ぎない(SNSに上げたときに特定の誰かのと似すぎていると言われない)のを作ることですかね。いうて今も要素の継ぎ足しで完璧に同じにはなっていませんが 

多重詠唱の効果ありますねこれ
できちゃった。昨日できなかった騎乗位カラオケ概念
[END]


* とある個人の雑記
ステータスの設定とかの解説はここ
[+]
Dreamboothとはなんか凄い技術で好きなキャラとか物を正確かつ綺麗に再現できるようになるかもしれんものや

要求
12GB以上のVRAM
※最新バージョンの1111では12GBでは足りん模様・・・使いたい場合はバージョンを下げよう
正直12GBではかなりギリギリやから作業中は動画再生や無駄なアプリを起動するのはご法度や
また無駄なプロセスが残っていても弾かれることがあるからトレーニングをやる前には再起動を勧めるで
12GBならxformersのONも忘れずに、これがあればデュアルモニタでも400MBは余裕ができるから少しならブラウジングもできる
※最新バージョンなら設定項目にxformersの有無が移動してる※
無い場合30MBぐらいしかVRAM残らないから文字通り何もできんで

導入
まずwebui.batで起動(オプションが邪魔する場合があるからな)
次にExtensionsのAvailableのLoard fromをポチる
リストがｽﾞﾗｯと出るのでDreamboothと書かれたやつをインストールや
インストールできたら再起動するとタブの中にDreamboothというのが出来る
更にパワーシェルとかで
pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116
を入力してpytorchとtorchvisionを更新して揃えといてくれ
※paperspaceやとインストールに失敗するという報告が上がっとるのでオプションに--enable-insecure-extension-accessを付けて起動してくれ

使い方

この説明はハッシュモデル725d85ca5485246a430d2f31f624646d061e8104を基準とした古い説明や
新しいバージョンの説明は下の方にいってくれ
もしバージョンを合わせたい場合stable-diffusion-webui/extensions/sd_dreambooth_extension/で右クリック→git bash hereを選択しgit reset --hard 725d85ca5485246a430d2f31f624646d061e8104と入力すると該当バージョンに変更できる

Create Model
まずCreate Modelというのでトレーニングさせるモノを作る
HNで言うところのCreate hypernetwaorkと似たようなもんやな
nameは好きな名前を入力してImport Model from Huggingface Hubを無視して次はSource Checkpoint
Source Checkpointではベースとなるモデルを選択するんやけどマージモデルでもOKや
とりあえず愛用しているモデルかキャラになにをさせたいかでベースを選ぶ感じでええと思う
次にScheduler、ここはデフォルトで選択されてるddimのままでOKや
選択完了後Createを押したら30秒〜1分ぐらいで作成完了する
作成が完了したらCreateModelの少し上のModelタブに作成したモデルがセットされているか確認してくれ

Train Model
ここからはトレーニングの内容を入力していく
PersonとObject/Styleのプリセットがあるけどここでは基本キャラ再現を考えて書いとるからpersonを押すとええ

Use Concepts List
OFFで

Instance prompt
ここは学習させたものを呼び出すためのプロンプトを設定する
とりあえず　学習対象の名前/半角スペース/適当な言葉(学習対象の名前を反転させたものが覚えやすくてオススメや)　を入れるとええ
※学習対象の名前が長過ぎる場合は簡潔に分かりやすい名前にしといてくれ
適当な言葉にする理由はClass Promptで

Dataset Directory
学習させるための画像が入ったファイルを指定するところや
512*512の大きさで用意しよう
オススメ枚数は5〜10枚

「キャラを学習させるための画像で大切なことは？」
とにかく質。少ない枚数でやるならとにかく質。
あとはキャラ学習なら背景や無駄な物(例えば花びらや置物や文字)すら強烈に覚えてしまうから丁寧に不純物を取り除いたり背景を白色にするのが大事や
不純物や文字の除去に関してはlama-cleanerとかいう便利なものがあるから検索してみてくれ

「選んではいけない画像とかある？」
強烈に学習する関係上ドアップの顔画像や真後ろからの画像は特定の場面で邪魔になることが多い
できればアップの画像でも胸辺りまでが写ってる画像が好ましい
横からの姿の画像を入れる場合でも1枚だけ、とかならいっそ抜いた方がええな
from sideと入れると同じような画像が生成され続けるとかいう可能性があるからできれば複数枚用意したい
また体だけ、見切れてる画像、なんかも強烈に覚えるから絶対にNGや
割合にするとfull body3枚、胸の辺りから上が2枚とか
full body3枚、胸の辺りから上が3枚、横顔(右)が2枚、横顔(左)が2枚とかやな

Class Prompt
正則化画像(後で説明する)の学習結果を呼び出すためのプロンプトを設定する場所や
ここではInstance promptで付けた適当な名前の部分を入力してくれ

「なるほど分からん」
例にすると

Instance prompt
nanU Unan

Class Prompt
Unan

みたいな感じに設定するとええ
もし設定するpromptが他のpromptとバッティングする場合は適当な言葉に変えてくれ

「適当な言葉にする理由は？」
一部ではInstance promptの前半を無意味な言葉に、Instance promptの後半とClass Promptの部分を(女の子を学習させる場合)girlにする等があるが上の方法と比べて何か利点があるとかは確認できなかった
なら学習したキャラとは全く似てないキャラが保存される言葉だからなるべく無関係な言葉にしたいよねという理由
ここを仮にgirlにした場合、ふとgirlを使用したい場面が出た時に困ってしまう

「Instance promptを2語にする意味は？」
nanU UnanのnanUの部分に絵柄がUnanの部分に意味が付与される
nanU Unanで呼び出すと絵柄+意味で強力に呼び出せるけどUnanが邪魔をして○○が命令しても出てこない！といったことが発生する
その場合Unanを切り離してnanUのみにすると命令が上手くいくが1語だと切り離しができないため汎用性が落ちる
また1語の場合2語の時と比べて何故か学習精度が落ちる(なんJNVA部★107>>236参照)
有識者の視点からするとありえんぐらい間違ったことを言ってるが実際に起きる挙動を説明するとこんな感じや・・・

Classification Dataset Directory
正則化画像が入ったファイルを指定するところや

「正則化画像とは？」
正則化というのは簡単に説明すると過学習を抑えてデータに汎用性を持たせることや
つまるところそれをさせるための画像で正則化画像や

「正則化画像というのはどういうものを用意すればいいの？あと何枚いる？」
真っ透明な512*512の画像を学習させるための画像の10倍の枚数用意する。
真っ透明な512*512の画像を学習させるための画像の10倍の枚数用意する。(例：学習させるための画像が5枚→透明な512*512画像が50枚)
よく分からんけどワイにも分からん
なんかあったらスレに検証結果書いてくれ...
ttps://i.imgur.com/8d6VTjm.png
真っ透明な512*512の画像のURLを一応貼っておく

[[https://image02.seesaawiki.jp/n/h/nai_ch/brdyJ_m5mJ.png]]
ここまでの流れでこんな感じの入力になってるはずや

Training Steps
文字通りトレーニングさせるステップ数を設定するところやな
枚数によるが10枚でも12000ステップもあれば過剰かもしれん
5枚なら7000もあれば過剰かもしれん

Total Number of Class/Reg Images
用意した正則化画像と同じ枚数でいい(例えばClassification Dataset Directoryで指定したファイルの中身が50枚なら50を入力や)
正則化画像より上の数にすることで正則化画像のフォルダに追加で画像生成を行う(いらない)
Classification Image Negative Prompt：とりあえず汎用ネガでええ
Classification CFG Scale：12でええんとちゃう？
Classification Steps：28でええんとちゃう？

[[https://image02.seesaawiki.jp/n/h/nai_ch/2TWUL3uVkh.png]]
こんな感じの入力になっとるやろか？
Total Number of Class/Reg Imagesの数値は本当に注意や
必ずClassification Dataset Directoryで指定したファイルの中身の枚数と一致させてな

Resolution
ここは学習画像と大きさを合わせるところやな512でOKや
クソバカアホデカVRAMグラボあるならデカい学習画像や正則化画像用意してここも合わせてデカくしてもええかもしれん？

Pretrained VAE Name or Path
何も入れんでええ

Learning Rate
0.000001でOKやこれ以上大きいと汎用性に問題が出るらしい
object/styleのプリセットやと0.000002になるが0.000001のがええ

Scale Learning Rate
ステップが進む毎に自動でLearning Rateを下げてloss値を綺麗に落としてくれる機能や
これがないと過学習に突っ込みやすいからONでええよ

Warmup Steps
本番前に準備運動をさせることができる
学習の初動は無茶苦茶な学習をするからそれを回避するための機能やな
デフォ値の16で十分やからそれでOKや

Learning Rate Scheduler
よく理解できとらんがデフォのpolynomialでOK

Save Checkpoint Frequency
モデルデータをどれぐらいの間隔で保存するかの部分や
モデルデータは一個2GBと巨大なデータやから50とかに設定して10000ステップ走らせると400GBもHDD/SSDを使う
Hypernetworksと違って変化が繊細なわけではないから細かくみたいと思っても500ステップで十分やで

Save Preview(s) Frequency
プレビューをどれぐらいの間隔で作成するかの部分や
VRAM12GBやとここを設定すると落ちるから0推奨や
ちなみにクソデカVRAMでここを設定する場合、Number of Samples to Generateには超絶ウルトラGOD注意や
ここを例えば5000とかに設定するとプレビュー作成地点に到達する毎に5000枚プレビューを作成しようとする(絶望)
作られたものは stable-diffusion-webui/models/dreambooth/ファイル名/samples/ に保存されるで

[[https://image01.seesaawiki.jp/n/h/nai_ch/jkrcx6ViW4.png]]
こんな感じになっとるはずや

Advanced
専門的なことが分かるならここで色々設定ができるがよく分からん人用にもAuto-Adjust(WIP)というのが用意されてる
とりあえずそれを押して終わりと思わせてTotal Number of Class/Reg Imagesの数値が0にされるので戻すのを忘れずに
ワイは何も分からん
Use 8bit Adam：品質を下げる代わりにVRAM消費を抑えるらしい3060とかなら残念ながら必須やな
Train EMA：消費VRAMを上げる代わりに品質を向上させるらしい3090とか用やな
Apply Horizontal Flip：左右を反転させて水増しすることができる、左右が大事なキャラは素材数が半減するがOFFにする方が無難や
これぐらいの認識や

[[https://image01.seesaawiki.jp/n/h/nai_ch/7AZPoIuvLi.png]]
参考画像や

ここまで設定したらあとはオレンジのTrainを押して開始や

「中断と再開ってどうなってんの？」
Cancelを押すことでその地点でセーブ、ファイルの作成、プレビュー(stable-diffusion-webui/models/dreambooth/ファイル名/samples/にできる)の作成を行って終了することができる
作ったモデルを消さない限りセットし直してトレーニングを開始すると前回終了した地点から『設定したステップ分』再開、進行される(HNとは違う)
セーブされる間隔の設定も『一度中断すると終了した地点が基準になる』(ここもHNとは違う)
もし新たにやり直したい場合は別名のものを作成してセットするか
同名のものを作りたい場合、元のファイル(stable-diffusion-webui/models/dreambooth/ファイル名)を削除(当然そこまで進行してたものは失われる)して作り直す必要がある
HNと違ってファイル名は後から変えても一切問題ないため(HNは内部の名前が作成時のものになる)SSD/HDDの容量が気にならないなら別名のものを作る方がええかもな

「セーブされたファイルが見当たらんのやけど？」
Stable-diffusion-webui\models\Stable-diffusionのところ(モデルデータがあるところ)に保存されるから無いならなんかおかしい

「できたモデルデータをセットしたけどどうやって使うねん」
Instance promptで設定した言葉の意味が変化してるからそれを入力してやれば呼び出すことができる
え？じゃあClass Promptとかどう使うん？ってなるがClass Promptをネガにいれるという使い方もできる
入れる方がいいの？入れない方がいいの？となるがハッキリいって学習結果によってよりけりや
入れた方がいい完成品もあったり入れない方がいい完成品もあったりしてまだここらへんは研究が進んでないな
当然Instance promptを強調したり学習対象の名前を強調しても調整することができるで
もし上記の呼び出し方でもダメな場合　学習対象の名前/半角スペース/適当な名前　の学習対象の名前の部分のみで呼び出したりネガにClass Promptを入れたり色々してみてくれ
それでもダメならダメや

[[https://image02.seesaawiki.jp/n/h/nai_ch/XTUa8JgVxv.png]]
nanU Unan で作った場合の呼び出し方の例や

「どれぐらいで完成と判断すればええ？」
とりあえずInstance prompt, 1girl(1boy), solo, アスカテストの品質ネガでちょっとだけ過学習やな・・・って思うのをピックアップ
そのあとInstance prompt, 1girl(1boy), solo, 好みの服, 好みの場所, の指定で出して過学習気味になってなかったら完成や

↑は古いバージョンの解説やったから↓で新たなバージョンの説明を追記するわ

※※※11月17日以降のバージョンではモデル作成に必要なVRAMが激増しています※※※
3060等ギリギリでやってるニキはanythingとかがデカい方のを使ってると作成に失敗するから注意してな
その場合小さい方を拾ってきてマージとかも作り直してくれ(面倒ならバージョン戻すんやな・・・)
当然アプデ前に作成したモデルはアプデ後再トレーニング不可になるからそこも注意や
3090とかクソアホバカデカVRAMグラボの場合はfixが沢山されとるから最新バージョン使う方がええと思うで

まずmodelの横にあるHalfはOFFで

Intervals
Training Steps：上記と同じやな
Training Epochs：ここはエポック数を決めるところや(1エポック＝学習のために用意した画像の枚数or正則化画像の枚数の多い方)
Save Checkpoint Frequency：上記と同じやな。モデルデータをどれぐらいの間隔で保存するかの部分や
Save Preview(s) Frequency：上記と同じやなプレビューをどれぐらいの間隔で作成するかの部分や

Learning Rate
Learning Rate：上記と指定数値が違っとる現状ここは0.000001に戻した方がええ
Scale Learning Rate：上記と同じやな。ONでええよ
Learning Rate Scheduler：上記と指定が違っとる戻すのが無難。デフォのpolynomialでOK
Learning Rate Warmup Steps：0に設定されとるがとりあえず15ぐらいを入れるとええ

Instance Image Processing
Resolution：上記と同じやな。512でOKや
Center Crop：文字通り画像がデカい場合中央基準で画像を切り取ってしまうんやまず512*512で素材は揃えてるはずやからOFFや
Apply Horizontal Flip：上記と同じや(advancedの場所に書いとる)。画像反転させるかどうか
Pretrained VAE Name or Path：上記と同じで何も入れんでええ
Use Concepts List：ここも何も入れんでええで

Directories
Dataset Directory：学習させる用の画像が入ったファイルを指定する
Classification Dataset Directory：正則化画像が入ったファイルを指定する

Prompts
Existing Prompt Contents：今まで通りならデフォのままでええな

「いやどういうものなの？」
Dataset DirectoryやClassification Dataset Directoryに画像ファイルと同名のtxtファイル(HNでよくあるタグ付けみたいな感じ)を入れて[filewords]を使って呼び出し方を変化させることができる
・・・んやけどルールが厳密にあってかなりめんどいうえに正直説明すらもワイの脳みそじゃ上手く伝えられん
詳しく知りたい！という場合にはStable Diffusion のファインチューンの Tipsと検索してdskjalというところのdreamboothの解説のところを読んでみてくれ

Instance prompt：上記と同じやな
Class Prompt：上記と同じやな
Sample Image Prompt：プレビューを生成しない場合空白でOKや
Instance Token：今まで通りなら無記入でかまわん[filewords]を使用しない場合入力しても特に意味は発生せん
Class Token：今まで通りなら無記入でかまわん[filewords]を使用しない場合入力しても特に意味は発生せん

Class Images
Total Number of Class/Reg Images：上記と同じやな。用意した正則化画像と同じ枚数でいい

Advanced：(WIP)を押してもまだ少し弄る必要があるで

Tuning
Use 8bit Adam：上記と同じや
Mixed Precision：fp16でOKや
Memory Attention：xformersを選択や
Train EMA：上記と同じや

Gradients
gradient checkpointing：速度が低下するがVRAMを抑えることができるらしい3090とかならOFFにできるで
[END]


*学習レポート置き場
学習の流れや結果を置く場所や
[+]

花月その1
DBモデルハッシュ：725d85ca5485246a430d2f31f624646d061e8104
学習対象：花月(アズールレーン)
使用素材：公式絵師のpixivからゲーム内のデフォルトの衣装を着ている画像を9枚、水着衣装を1枚使用
加工：大きい白画像を用意し絵をそのまま貼り付け、白い縁が出来るのを無視し絵の全体が見えるように四角状に切り取り
　　　その後anime-remove-backgroundのローカルで切り抜き、切り抜きが上手くいかなかったものはGIMPで自力切り抜き、花びらや傘の棒部分の不純物が存在したためそれをlama-cleanerを活用し除去
　　　水着衣装のみ普段とは違う衣装のため帽子や青いリボン等は除去
　　　加工が一通り終わった後全ての画像で512*512に縮小したものを用意、その後学習素材を水増しするため加工が一通り終わった素材を活用し全身気味の画像を活用しportrait気味の画像を4枚、ドアップ画像を1枚、cowboy shot気味の画像を3枚作成
加工後素材詳細：合計18枚、全身正面画像が3枚、cowboy shot気味の正面画像が8枚、portrait気味の正面画像が4枚、ドアップ正面画像が1枚、全身背面画像が1枚、cowboy shot気味の背面画像が1枚、その内白い縁ができた学習素材が6枚
正則化画像：一度下記のベースモデルを使用したDBを活用し、極端に似ている(ﾊﾟｯと見で花月と判断できるぐらいの)絵を学習画像の6倍枚数用意
ベースモデル：NAI5、any2.7、gape2、SD(1.4)0.3の割合のものを使用
LR等のステータス設定：LR0.000001、Scale Learning RateON、8000Step、Apply Horizontal FlipON、Use 8bit AdamON、Train EMAOFF
安定した呼び出し方：Instance promptの学習対象の名前のみ
結果：ﾊﾟｯと見の出来は良好だが尻尾、頭後ろにある少しだけ見える赤リボンの再現が甘い、全身表示にしても艤装及び傘の再現はサッパリだった
　　　素材の中にドアップの画像と背面の画像が混じっていたため横長に出力するとまともな画像が一切生成されなかったり唐突に背面の絵が混じる等問題が発生した
　　　白い縁ができた学習素材が6枚存在したが白い縁が生成される、キャラの左右が見切れる等の問題は生じなかった

花月その2
DBモデルハッシュ：725d85ca5485246a430d2f31f624646d061e8104
学習対象：花月(アズールレーン)
使用素材：花月その1の学習画像からドアップ正面画像が1枚、全身背面画像が1枚、cowboy shot気味の背面画像が1枚を除いた合計15枚を使用
加工：花月その1の学習画像を流用したため省略
加工後素材詳細：同じく省略
正則化画像：masterpiece,best qualty,1girl,solo,loli,green eyes,pink hair,fox girl,fox ears,fox tail,animal ear fluff,animal ears,(red hairband:1.2),pink kimono,red hakama,(white background:1.5),(simple background:1.5),bow head,hair bow
　　　　　　ネガ：lowres, bad anatomy,bad hands,text,error,missing fingers,extra digit,fewer digits,cropped,worst quality,low quality,normal quality,jpeg artifacts,signature,watermark,blurry
　　　　　　で作成した様々な角度、アップ具合のピンク色の狐娘の画像を6倍枚数用意、使用モデルはベースモデル：NAI7、any3の割合のものと同じ
ベースモデル：NAI7、any3の割合のものを使用
LR等のステータス設定：LR0.000001、Scale Learning RateON、7000Step、Apply Horizontal FlipON、Use 8bit AdamON、Train EMAOFF
安定した呼び出し方：Instance prompt+Class promptネガ
結果：その1とほぼ同等の出来でより汎用性が高めなものに仕上がった(細かく言うと髪飾りの再現性が上昇、傘の再現性が更に低下、上の花月もだがApply Horizontal FlipONなので頭飾りの左右が無茶苦茶)
　　　こちらは絵を横長に出力をしても問題は発生しなかった
　　　絵はなんJNVA部★102の>>28に投稿

ナンジャモその1
DBモデルハッシュ：725d85ca5485246a430d2f31f624646d061e8104
学習対象：ナンジャモ(ポケモン)
使用素材：pixivからそこそこ〜綺麗な絵を15枚使用
加工：大きい白画像を用意し絵をそのまま貼り付け、白い縁が出来るのを無視し絵の全体が見えるように四角状に切り取り
　　　その後anime-remove-backgroundのローカルで切り抜き、切り抜きが上手くいかなかったものはGIMPで自力切り抜き、電撃や文字等の不純物が存在したためそれをlama-cleanerを活用し除去
　　　加工が一通り終わった後全ての画像を512*512に縮小、cowboy shot気味やportrait気味にすることは一切していない
加工後素材詳細：使用素材から変わらず合計15枚、縦に長い画像を白背景に貼り付け四角く縮小しているため左右に白い帯有り
正則化画像：一度DBを通し、そのモデルを使用し髪の色、コイルの色配置が正しいナンジャモの絵を出力
　　　　　　見た目のよさや服の色、アングル等は度外視し学習画像の8倍枚数を用意した
ベースモデル：NAI5、any2.7、gape2、SD(1.4)0.3の割合のものを使用
LR等のステータス設定：LR0.000001、Scale Learning RateON、9500Step、Apply Horizontal FlipON、Use 8bit AdamON、Train EMAOFF
安定した呼び出し方：Instance prompt+Class promptネガ、Instance promptの学習対象の名前のみ
結果：構造が複雑なのに素材の絵柄が一切統一されておらずApply Horizontal FlipONのため見た目はいいものができたが左右がぐっちゃぐちゃ
　　　またコイルが省略されている素材絵が多いためここの再現も正直甘く、別の服を着せるとお団子ヘアーになることがあった(その場合呼び出し方を変えて回避可能ではあった)
　　　汎用性は中の下と言った感じでややポーズが固く、他の服を着せた後コイルを呼び出すのに苦労をした
　　　用意した学習画像に反して左右に白い帯がある絵が量産されるといった現象は発生しなかった
　　　絵はなんJNVA部★102の>>801、なんJNVA部★103の>>39に投稿

ナンジャモその2
DBモデルハッシュ：725d85ca5485246a430d2f31f624646d061e8104
学習対象：ナンジャモ(ポケモン)
使用素材：上のナンジャモその1の素材からコイルの形状がまともなものを3枚選択
加工：上のナンジャモその1の流用なので省略
加工後素材詳細：流用なので省略
正則化画像：全面透過処理がされた512*512サイズの画像を学習画像の10倍枚数用意
ベースモデル：NAI5、any2.7、gape2、SD(1.4)0.3の割合のものを使用
LR等のステータス設定：LR0.000001、Scale Learning RateON、3000Step、Apply Horizontal FlipOFF、Use 8bit AdamON、Train EMAOFF
安定した呼び出し方：Instance prompt
結果：全体の再現性は5割程度といった代物でイマイチな出来だった
　　　ただし正則化画像無し他条件はこれと同じで作成したものより精度はかなり高く、他のプロンプトと組み合わせた時の劣化も若干抑えれていた
　　　絵はなんJNVA部★105の>>806に投稿

学習対象：ヒーロー♀(世界樹の迷宮X)
DBモデルハッシュ：725d85ca5485246a430d2f31f624646d061e8104
使用素材：公式のアートミュージアム本に掲載されている公式絵3枚(全身1枚、上半身2枚)を使用
加工：白画像を用意し全身絵を貼り付け絵の全体が見えるように四角く切り取り512*512に縮小、該当キャラクター以外は白に塗りつぶし消去
　　　胸より上の絵は胴より下の部分が無いため、胴が無いキャラと誤認されないように調整し貼り付けて四角く切り取り512*512に
加工後素材詳細：使用素材から変わらず合計3枚
正則化画像：全面透過処理がされた512*512サイズの画像を学習画像の10倍枚数用意
ベースモデル：NAI5、any2.7、gape2、SD(1.4)0.3の割合のものを使用
LR等のステータス設定：LR0.000001、Scale Learning RateON、3000Step、Apply Horizontal FlipON、Use 8bit AdamON、Train EMAOFF
安定した呼び出し方：Instance prompt
結果：服の再現性は7割、顔回りの再現性は8割、塗りの再現性は8割程度でDBの苦手な目の再現性はイマイチだった
　　　ただし汎用性が極端に高く、他のプロンプトと組み合わせても劣化が少ない、呼び出し強調をすると素直に再現性が上がる、横顔を指定すると綺麗に構造を補完したものを出すといった代物だった
　　　同条件、正則化画像無しのものも作成したがこちらの方が明確に出来がよかった
　　　絵はなんJNVA部★105の>>720に投稿