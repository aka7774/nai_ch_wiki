NovelAI V4・V4.5での追加要素の概要。
V3までの内容は[[NovelAI V3の概要]]を参照。
[[公式ドキュメントはこちら>https://docs.novelai.net/image/basics.html]]

#contents 

* 複数キャラプロンプト
V4から、キャラごとにプロンプトを設定することができるようになった。
これまでは、例えば青髪と赤髪の2人の女キャラを出力したい場合、2girls, blue hair, red hair, と指定はできるが、1キャラでツートンカラーになったりと、正確な制御が難しかった。
V4からはベースプロンプトに2girls, と書き、キャラごとにプロンプトを分けることで、より意図通りに生成しやすくなった。
キャラの位置を指定する機能もあるが、character 1から順番に左から配置されるバイアスが強い模様。

** ||で指定
キャラプロンプトは1キャラずつ別パネルで指定する必要があるが、簡略記法として |と| で囲む記法が存在する。
例えば、通常はベースプロンプトに2girls, キャラプロンプト2つに "girl, kirisame marisa, " と "girl, hakurei reimu, " のように指定するが、
ベースプロンプトに "2girls, |kirisame marisa,| hakurei reimu, " と指定することもできる。
ただし、キャラごとのネガティブプロンプトが使えなくなるので、あくまで簡略記法。

* 自然言語対応の強化
Text EncoderがCLIPからT5に変更されたことで、自然言語プロンプトへの応答力が飛躍的に向上した。
たとえば「青い机」を出すなど、後述の数値で強調指定と併用することで、「danbooruにはタグはないが、どうしても入れたい要素」を抜けなく指定することができる確率が高まった。
一方で、nsfwの特殊性癖など、そもそも内部表現として元から持ってないであろう要素は、いくら自然言語指定しても苦しい場合も少なくないので万能ではない。

* アクションタグ
source#XXX, target#XXX, mutual#XXX, を使い分けることで、行動の主体、行動の対象、相互の行動（ハグなど）、を指定しやすくなった。
例えば"grabbing another's breasts"をしたい場合、"source#grabbing another's breasts"が揉む側、"target#grabbing another's breasts"が揉まれる側となりやすい。
これにより受け攻めの固定がやりやすくなった（100%ではないのであくまでなりやすいだけ）

* ポーション（旧Vibe Transfer）
V3まではVibe Transferと呼ばれていた、参照画像を渡す機能がポーションと名前変更された。
新しい画像を渡すとき、画像の情報を中間表現に変換するために1枚につき2anlas消費する。
このanlas消費は初回のみだが、パラメータを変更した場合は再変換のため再度anlasが必要になる。
また、変換したポーションはダウンロードして保存・共有ができる。

* ケモナーモデルと統合
V4 Furryどこいった？ となるところだが、V4からdanbooruとe621がまとめて学習されるようになった模様。
e621スタイルに寄せたい場合、"fur dataset"をプロンプトの最初に入れることで、e621寄りになる。
（のちのアプデで、プロンプト欄の左の&#127800;(Anime)マークをクリックすると&#128062;(Furry)マークになり、上述と全く同じ効果が得られるようになったので、いまfur datasetを文字で指定しなくてもいい）

** anime dataset?
このタグの類推から、 "anime dataset"とプロンプトを入れれば、アニメ向けの品質向上に使えるのではないかと試みた動きがあったが、公式にそのようなタグの存在は確認されていない。((良くなったことを報告するユーザーもいるが、効果を感じないユーザーもいる。x/y plotのような具体的な比較対照は行われておらず、トークンの一部である"anime"が反応した結果か (もしそうなら"anime coloring"のほうがタグとして適切) 、他のプロンプトなど特定の状況で偶然好みに合うだけだったという以外に理由付けは与えられていない))
同様に、 "curated dataset" "nai diffusion v4 dataset" などのプロンプトを試すユーザーもいるが、どれも公式なタグではなく、プラシーボ以上の効果は証明されていない。

*** 結局、公式なdatasetタグは？
V4.5時点でfur datasetとbackground datasetの2種のみ。
V4のプレビュー時に、テスターの生成画像 ((https://blog.novelai.net/release-novelai-anime-diffusion-v4-curated-preview-en-ca4b0b11e671 の下から4段目、カラフルなインクが背景にある画像)) に残されてたプロンプトの中に、draw datasetが含まれていたが、これまで公式はこのプロンプトに言及していない。
本リリースには含まれないプレビュー時のみの機能か、テスターの思いつきの実験あたりか。

* プロンプトランダマイザー || ||
NAI版Dynamic Prompts。 "|| ||"(縦棒2本で囲む)ことで使用可能。
例えば、立っているか座っているかのどちらかをランダムに生成したい場合、 "||standing|sitting||, "と指定することで実現可能。
メタデータ付きの画像のインポート時には、"Actual Prompt"を選択すると抽選結果のみインポートできる。オフにすると抽選前の元の状態でインポートされる。
* 数値で強調指定
NAI版negpip。
今までは{}（1.05倍）か[]（1.05で割る）の組み合わせしかなかったが、数値を直接指定することができるようになった（併用可）。
これはマイナスの数値も指定可能で、例えば今まで「目を大きく開ける」という指定はdanbooruタグになかったためできなかったが ((half-closed eyesタグはあるが、文字通り半分しか開いてくれない)) 、 -1::closed eyes::, と指定することで、無指定のまま目が閉じられるケースを回避することが可能になった。

ただし、なんでもかんでも大きい数字にすると画像が崩壊する確率が高まる。
基本強調は使わず、どうしても達成したい部分だけ強調するのが近道。

* 特殊タグの調整
** top aesthetic → masterpiece
本来masterpieceタグは廃止されていたのだが、効果が無いにもかかわらずmasterpieceタグをプロンプトに含めるユーザーが後を絶たないため、
ユーザー側に寄り添う形で、逆にtop aestheticタグを廃止し、masterpieceタグにその役割を戻すことになった。

** location
「indoorsでもoutdoorsでもいいので、とにかくなんか背景描いて！」というときに使える"location"タグが導入された

** background dataset
「写真風で、人間の存在しない、風景・動物・物体が主役のイラスト」のためのタグ。





