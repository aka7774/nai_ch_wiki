* Animaについて
https://huggingface.co/circlestone-labs/Anima
アニメイラストに特化したMMDiTモデルで、NVIDIAのCosmos-Predict2がベースである。
まだ開発中だが、すでにSDXLのIllustrious-XLを全面的に上回っているように感じる。

パラメータ数は2Bで、VRAM8GBで快適に動作する(だが計算はSDXLより二倍遅い)。

現時点で512x512で学習したプレビュー版であり、1024x1024で学習するリリース版は開発中。

* SDXLに対するAnimaの強みは？
要約すると
- 水平線やフェンスがずれたり曲がったりといった破綻が少ない。
- 色綺麗だし明暗の表現がいい。Noob v-predより良い。
- 細部の描写が良く目などが潰れにくい。
- 自然言語による位置などの具体的な指示が可能。
- メモリ使用量がSDXLより若干少ない？

*** 拡散モデル
SDXLは畳み込みニューラルネットワークがベースのU-Netアーキテクチャだが、これは現在主流のTransformerベースのDiffusion Transformer(DiT)を採用する。
DiTは水平線や物体の構造の一貫性維持が比較的得意で破綻が少ない。
*** TE
Text EncoderはQwen3-0.6BでSDXLのCLIP-L+Gより軽量で高性能であり、位置や文字などの具体的な情報を解釈できる。
*** VAE
16チャネルのQwen3のものを使用し、色精度とディティールがとても良い。かさついた質感がない。preview版は学習解像度512x512であるにもかかわらず目がほとんど崩れない。
*** その他
メモリ使用量がSDXLより若干少ない。

** 欠点
- DiTであるが故に計算が遅い。大体SDXLの二倍の時間がかかる。
- 対応UIが少ない。A1111系は非対応。
- 知識やLoRAなどの資産が少ない。もちろんSDXLとの互換性はない。
- 2026-02-08時点でプレビュー版である。

* 対応UI
現時点でComfyUIのみ。

* 使用方法(ComfyUI)
Hugging Faceリポジトリから次のファイルをDLして配置する。
ComfyUI/models/diffusion_modelsにanima-preview.safetensors
ComfyUI/models/text_encodersにqwen_3_06b_base.safetensors
ComfyUI/models/vaeにqwen_image_vae.safetensors

ComfyUIのテンプレートにAnimaがあるのでそこから生成を始めるといい。

* 推奨生成パラメータ
- 解像度: 画素数が1024x1024や832x1216などの104万画素に近似する値
- Steps: 30-50(実際には20ステップで十分)
- Guidance Scale: 4-5

* プロンプト
プロンプトはDanbooruタグと自然言語(英語)の両方が使える。位置指定や文字描写などの具体的な命令もOKだが大型モデルほど得意ではない。

タグは次の並びで学習している。これに従う必要はない(だが推奨)。
 quality/meta/year/safety tags, 1girl/1boy/1other etc, character, series, artist, general tags

** 特殊タグ
品質タグや年代タグなど
*** 品質タグ
- 人間によるスコアベース
 masterpiece, best quality, good quality, normal quality, low quality, worst quality

- PonyV7のaesthetic modelベース
score_1〜score_9。Illustriousでいうaestheticタグに相当する？
高いスコアほど絵が美しくなるが、画風がSDXLのマージモデルのようなマスピ絵に近づく。
*** 年代タグ
 newest, recent, mid, early, old
またはyear 2020のように西暦で指定する。
*** レーティングタグ
左から順にDanbooruのgeneral, sensitive, questionable, explicitにあたる。
 safe, sensitive, nsfw, explicit
*** アーティストタグ
"@big chungus"のように@を名前の頭につける。

** 強度指定
Text EncoderはSD1/SDXLで使用されるCLIPではなくQwen3(0.6B)というLLMだが、機能する。
しかし、SDXLほど効果は強くなく、15倍前後まで強くできる。大体70倍を超えると完全に壊れる。

* ComfyUIでFP16で動作させる方法
読み込んだ拡散モデルをModelComputeDtypeノード(dtypeをfp16にする)を介して使用する。
bf16が使えるグラボでもfp16 accumulationで高速化できるメリットがあるかも。
fp16パッチのスクリプトは不要になった。ComfyUIにfp16対応が実装された。

* 学習
diffusion-pipeまたはsd-scriptsのsd3ブランチでできる。
なお、fp16ではオーバーフローによるNaN演算で動作しないのでbf16(NVIDIAであればAmpere以降が対応)必須となる。
https://github.com/bluvoll/diffusion-pipe/tree/main
https://github.com/kohya-ss/sd-scripts/tree/sd3

* ライセンス
CircleStoneLabsの独自ライセンス。独自と聞いて身構えるかもしれないが寛容なので安心しよう。
有料の生成サービスやモデルの販売などモデル自体の商用利用は禁止だが、出力は商用利用ができる。
モデルの使用は、違法または悪意のある目的を除き自由。

* トラブルシューティング

** 画風が安定しない
ベースモデルで多様性が高いため仕様である。
画風を安定させるならアーティストタグを使うのが手っ取り早い。
あるいは画風LoRAを作って適用する。学習は素直で、作ったLoRAを適用すればネガティブ無しでも画風が安定する。

** 背景が単調
短いプロンプトでは単調になりがち。
ベースモデルで多様性が高い上Text Encoderが賢いLLMのため、書いていないものは生成しない傾向が強い。
Danbooruタグに加えて自然言語(英語)で具体的に指示することをお勧めする。

** クロップされた画像が出る
Discrete Flow Shiftの値が小さすぎることが原因の一つ。 
ComfyUIでModelSamplingAuraFlowノードを使用するなら、shift値はAnimaの初期値の3前後を推奨する。3でもたまに出るけど…

* 派生モデル
*** AnimaYume
https://civitai.com/models/2385278
preview版を1024pxでFine-Tuningしたもの。指の本数の誤りや構図の破綻が減少して扱いやすい。

* Anima関連のツール類

** Animaのスタイルエクスプローラ
https://thetacursed.github.io/Anima-Style-Explorer/
1,000人近くの絵師のスタイルが収録されている。


